# Hybrid deep learning models for traffic prediction in large-scale road networks

å¤§è§„æ¨¡é“è·¯ç½‘ç»œäº¤é€šé¢„æµ‹çš„æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹

## æ‘˜è¦

*Traffic prediction is an important component in Intelligent Transportation Systems(ITSs) for enabling advanced transportation management and services to address worsening traffic congestion problems. The methodology for traffic prediction has evolved significantly over the past decades from simple statistical models to recent complex integration of different deep learning models. In this paper, we focus on evaluating recent hybrid deep learning models in the task of traffic prediction. To this end, we first conducted a review and taxonomize the reviewed models based on their feature extraction methods. We analyze their constituent modules and architectural designs. We select ten models representative of different architectural choices from our taxonomy and conducted a performance comparison study. For this, we reconstruct the selected models and performed a series of comparative experiments under identical conditions with three well-known real-world datasets collected from large-scale road networks. We discuss the findings and insights based on our results, highlighting the differences in the achieved prediction accuracy by models with different design decisions.*

äº¤é€šé¢„æµ‹æ˜¯æ™ºèƒ½äº¤é€šç³»ç»Ÿï¼ˆITSï¼‰ä¸­çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œå¯é€šè¿‡å…ˆè¿›çš„äº¤é€šç®¡ç†å’ŒæœåŠ¡æ¥è§£å†³æ—¥ç›Šä¸¥é‡çš„äº¤é€šæ‹¥å µé—®é¢˜ã€‚äº¤é€šé¢„æµ‹çš„æ–¹æ³•å­¦åœ¨è¿‡å»å‡ åå¹´ä¸­å‘ç”Ÿäº†æ˜¾è‘—å˜åŒ–ï¼Œä»ç®€å•çš„ç»Ÿè®¡æ¨¡å‹æ¼”å˜ä¸ºæœ€è¿‘é›†æˆä¸åŒæ·±åº¦å­¦ä¹ æ¨¡å‹çš„å¤æ‚æ¨¡å‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä¸“æ³¨äºè¯„ä¼°æœ€è¿‘åœ¨äº¤é€šé¢„æµ‹ä»»åŠ¡ä¸­ä½¿ç”¨çš„æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆè¿›è¡Œäº†ä¸€é¡¹ç»¼è¿°ï¼Œå¹¶æ ¹æ®å®ƒä»¬çš„ç‰¹å¾æå–æ–¹æ³•å¯¹æ‰€å®¡æŸ¥çš„æ¨¡å‹è¿›è¡Œäº†åˆ†ç±»ã€‚æˆ‘ä»¬åˆ†æäº†å®ƒä»¬çš„ç»„æˆæ¨¡å—å’Œæ¶æ„è®¾è®¡ã€‚æˆ‘ä»¬ä»æˆ‘ä»¬çš„åˆ†ç±»æ³•ä¸­é€‰æ‹©äº†åç§ä»£è¡¨ä¸åŒæ¶æ„é€‰æ‹©çš„æ¨¡å‹ï¼Œå¹¶è¿›è¡Œäº†æ€§èƒ½æ¯”è¾ƒç ”ç©¶ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é‡å»ºäº†æ‰€é€‰çš„æ¨¡å‹ï¼Œå¹¶åœ¨ä¸æ¥è‡ªå¤§è§„æ¨¡é“è·¯ç½‘ç»œçš„ä¸‰ä¸ªçŸ¥åçœŸå®ä¸–ç•Œæ•°æ®é›†ç›¸åŒçš„æ¡ä»¶ä¸‹æ‰§è¡Œäº†ä¸€ç³»åˆ—æ¯”è¾ƒå®éªŒã€‚æˆ‘ä»¬æ ¹æ®ç»“æœè®¨è®ºäº†å‘ç°å’Œè§è§£ï¼Œçªå‡ºäº†å…·æœ‰ä¸åŒè®¾è®¡å†³ç­–çš„æ¨¡å‹æ‰€è¾¾åˆ°çš„é¢„æµ‹å‡†ç¡®åº¦çš„å·®å¼‚ã€‚



## ä¸€ã€ä»‹ç»

*United Nations reported that currently more than half of worldâ€™s population lives in urban area and this is projected to increase to 68% by 2050 [1]. Rapid urbanization has left many countries facing various challenges in meeting the need of increasing urban citizens and sustainable development. Transportation is one such challenge. For instance, Inrix reported on average, a driver lost 134 and 133 h in Bucharest and Bogota each year due to traffic congestion [2]. Intelligent Transportation Systems (ITSs), as an integrated transportation management system, are proposed to arrest the exacerbating traffic situations. ITSs rely on accurate traffic prediction to enable services such as Advanced Traveler Information System (ATIS) to improve traffic conditions [3].*

*One of the earliest work on traffic prediction published in 1979 [4] proposed to apply Auto-Regressive Moving Average (ARMA) for shortterm traffic flow prediction. Since then, many work ensued and the prediction methodology has evolved over time. In this paper, we broadly synthesize the evolution of traffic prediction methodologies into three main stages. In the first (early) stage, statistical methods such as ARMA and its variants [5,6] are proposed with the problem modeled as a pure time series process. These methods are commonly used in small and relatively simple traffic systems. They are not capable of handling traffic data with high dimensions and non-linear relationships.*

è”åˆå›½æŠ¥å‘Šç§°ï¼Œç›®å‰è¶…è¿‡ä¸€åŠçš„å…¨çƒäººå£å±…ä½åœ¨åŸå¸‚åœ°åŒºï¼Œé¢„è®¡åˆ°2050å¹´å°†å¢åŠ åˆ°68% [1]ã€‚å¿«é€ŸåŸå¸‚åŒ–ä½¿è®¸å¤šå›½å®¶é¢ä¸´æ»¡è¶³ä¸æ–­å¢é•¿çš„åŸå¸‚å±…æ°‘å’Œå¯æŒç»­å‘å±•éœ€æ±‚çš„å„ç§æŒ‘æˆ˜ï¼Œå…¶ä¸­äº¤é€šæ˜¯ä¸€ä¸ªé‡è¦æŒ‘æˆ˜ã€‚ä¾‹å¦‚ï¼ŒInrixæŠ¥å‘Šç§°ï¼Œç”±äºäº¤é€šæ‹¥å µï¼Œå¸æœºæ¯å¹´åœ¨å¸ƒåŠ å‹’æ–¯ç‰¹å’Œæ³¢å“¥å¤§å¹³å‡å¤±å»134å’Œ133å°æ—¶ [2]ã€‚æ™ºèƒ½äº¤é€šç³»ç»Ÿï¼ˆITSï¼‰ä½œä¸ºç»¼åˆäº¤é€šç®¡ç†ç³»ç»Ÿï¼Œè¢«æå‡ºç”¨æ¥ç¼“è§£ä¸æ–­æ¶åŒ–çš„äº¤é€šçŠ¶å†µã€‚ITSä¾èµ–äºå‡†ç¡®çš„äº¤é€šé¢„æµ‹ï¼Œä»¥å®ç°è¯¸å¦‚é«˜çº§æ—…è¡Œè€…ä¿¡æ¯ç³»ç»Ÿï¼ˆATISï¼‰ç­‰æœåŠ¡ï¼Œä»¥æ”¹å–„äº¤é€šçŠ¶å†µ[3]ã€‚

å…³äºäº¤é€šé¢„æµ‹çš„æœ€æ—©ç ”ç©¶ä¹‹ä¸€å‘è¡¨äº1979å¹´[4]ï¼Œæå‡ºåº”ç”¨è‡ªå›å½’æ»‘åŠ¨å¹³å‡ï¼ˆARMAï¼‰è¿›è¡ŒçŸ­æœŸäº¤é€šæµé¢„æµ‹ã€‚æ­¤åï¼Œè®¸å¤šå·¥ä½œé™†ç»­å‡ºç°ï¼Œé¢„æµ‹æ–¹æ³•éšæ—¶é—´æ¼”å˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¹¿æ³›æ€»ç»“äº†äº¤é€šé¢„æµ‹æ–¹æ³•çš„æ¼”å˜ï¼Œåˆ’åˆ†ä¸ºä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚åœ¨ç¬¬ä¸€ï¼ˆæ—©æœŸï¼‰é˜¶æ®µï¼Œæå‡ºäº†ç»Ÿè®¡æ–¹æ³•ï¼Œå¦‚ARMAåŠå…¶å˜ç§[5,6]ï¼Œé—®é¢˜è¢«å»ºæ¨¡ä¸ºçº¯ç²¹çš„æ—¶é—´åºåˆ—è¿‡ç¨‹ã€‚è¿™äº›æ–¹æ³•é€šå¸¸ç”¨äºå°å‹å’Œç›¸å¯¹ç®€å•çš„äº¤é€šç³»ç»Ÿã€‚å®ƒä»¬æ— æ³•å¤„ç†é«˜ç»´åº¦å’Œéçº¿æ€§å…³ç³»çš„äº¤é€šæ•°æ®ã€‚

*The second stage emerged following the popularity of machine learning models in various fields such as pattern recognition [7,8], image classification [9,10] and natural language processing [11,12]. Machine learning models with non-linear kernels and activation functions such as Support Vector Regression (SVR) [13], ğ¾-Nearest Neighbors (KNN) [14], Artificial Neural Network (ANN) [15] and Bayesian Networks [16] were then used for solving traffic prediction problem. These models mostly treat traffic prediction as multiple classification problem. Following new sensor technologies allowing collection of richer traffic data, [17] found that road traffic has complex spatialâ€“ temporal correlation and these machine learning models are shallow and inadequate for analyzing such spatialâ€“temporal relationships.*

ç¬¬äºŒé˜¶æ®µå‡ºç°åœ¨æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨å„ä¸ªé¢†åŸŸçš„æ™®åŠï¼Œå¦‚æ¨¡å¼è¯†åˆ«[7,8]ã€å›¾åƒåˆ†ç±»[9,10]å’Œè‡ªç„¶è¯­è¨€å¤„ç†[11,12]ã€‚

å…·æœ‰éçº¿æ€§æ ¸å’Œæ¿€æ´»å‡½æ•°çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œä¾‹å¦‚æ”¯æŒå‘é‡å›å½’ï¼ˆSVRï¼‰[13]ã€ğ¾-æœ€è¿‘é‚»ï¼ˆKNNï¼‰[14]ã€äººå·¥ç¥ç»ç½‘ç»œï¼ˆANNï¼‰[15]å’Œè´å¶æ–¯ç½‘ç»œ[16]ï¼Œéšåè¢«ç”¨äºè§£å†³äº¤é€šé¢„æµ‹é—®é¢˜ã€‚

è¿™äº›æ¨¡å‹å¤§å¤šå°†äº¤é€šé¢„æµ‹è§†ä¸ºå¤šåˆ†ç±»é—®é¢˜ã€‚éšç€æ–°çš„ä¼ æ„Ÿå™¨æŠ€æœ¯å…è®¸æ”¶é›†æ›´ä¸°å¯Œçš„äº¤é€šæ•°æ®ï¼Œ[17]å‘ç°é“è·¯äº¤é€šå…·æœ‰å¤æ‚çš„æ—¶ç©ºç›¸å…³æ€§ï¼Œè€Œè¿™äº›æœºå™¨å­¦ä¹ æ¨¡å‹å¯¹äºåˆ†æè¿™ç§æ—¶ç©ºå…³ç³»æ¥è¯´æ˜¾å¾—è¾ƒä¸ºè‚¤æµ…å’Œä¸è¶³å¤Ÿã€‚

*Then, the third stage emerged where deep learning models are applied for solving traffic prediction problems. With increasing computational resource and the development of sophisticated deep learning models, the focus of the problem has also shifted from predicting traffic states at specific road station/segment to large-scale road networks. Expanding the scope of predictions to the entire road network has made the problem more challenging since network-wide traffic data has much more complicated spatialâ€“temporal relationship [18]. Initial deep learning models such as Recurrent Neural Networks (RNN) and its variants (Long-Short Term Memory (LSTM) and Gated Recurrent Unit (GRU)) [19], Convolutional Neural Network (CNN) [20], and Graph Convolutional Neural Network (GCN) [21], are unable to fully analyze such spatialâ€“temporal dependencies of traffic data hidden in large-scale road networks.*

æ¥ç€ï¼Œç¬¬ä¸‰é˜¶æ®µå‡ºç°ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹è¢«åº”ç”¨äºè§£å†³äº¤é€šé¢„æµ‹é—®é¢˜ã€‚éšç€è®¡ç®—èµ„æºçš„å¢åŠ å’Œå¤æ‚æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å‘å±•ï¼Œé—®é¢˜çš„é‡ç‚¹ä¹Ÿä»åœ¨ç‰¹å®šé“è·¯ç«™ç‚¹/æ®µä¸Šé¢„æµ‹äº¤é€šçŠ¶æ€è½¬ç§»åˆ°äº†å¤§è§„æ¨¡é“è·¯ç½‘ç»œã€‚

å°†é¢„æµ‹èŒƒå›´æ‰©å¤§åˆ°æ•´ä¸ªé“è·¯ç½‘ç»œä½¿é—®é¢˜å˜å¾—æ›´åŠ å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºæ•´ä¸ªç½‘ç»œèŒƒå›´å†…çš„äº¤é€šæ•°æ®å…·æœ‰æ›´ä¸ºå¤æ‚çš„æ—¶ç©ºå…³ç³»[18]ã€‚æœ€åˆçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¦‚å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰åŠå…¶å˜ç§ï¼ˆé•¿çŸ­æ—¶è®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰å’Œé—¨æ§å¾ªç¯å•å…ƒï¼ˆGRUï¼‰ï¼‰[19]ã€å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰[20]å’Œå›¾å·ç§¯ç¥ç»ç½‘ç»œï¼ˆGCNï¼‰[21]ï¼Œæ— æ³•å……åˆ†åˆ†æéšè—åœ¨å¤§è§„æ¨¡é“è·¯ç½‘ç»œä¸­çš„äº¤é€šæ•°æ®çš„è¿™ç§æ—¶ç©ºä¾èµ–å…³ç³»ã€‚

*Following the above, the evolution of the methodology continues with hybrid deep learning models1 emerging in the latest literature.*

*These models are constructed by combining several deep learning models to further improve prediction accuracy. In this paper, we focus on the performance of these latest hybrid deep learning models rather than the entire evolution of the traffic prediction methodology. We point interested readers to existing surveys on previous evolution. For instance, [22â€“24] reviewed models focusing on addressing short-term traffic prediction only. On the other hand, [25â€“27] targeted more classical approaches including statistical-based and machine learning (ML)-based models while [24,28,29] focused on deep learning models.*

*We also note another work [30] which reviewed traffic prediction from the perspective of smart cities and highlighted existing traffic data sources and data models for fusing traffic data in ITSs. Furthermore, [31] explored and explained different GCNs, including graph convolutional and graph attention networks, for solving various traffic prediction problems (i.e., road traffic flow and speed predictions, network-wide traffic flow and speed predictions, and traffic demand prediction) in detail. Meanwhile, [32] surveyed and categorized deep learning models for urban traffic prediction into three: grid-based, graph-based, and multivariate time-series models. The authors provided benchmarks to evaluate the performances of the selected models.*

*We have adopted a different approach and focused on hybrid deep learning models. We create a different taxonomy (see Section 3 and further analyze and evaluate representative models of different category of our taxonomy in terms of architecture designs, Mathematical foundations and performances.*

ç»§ä¸Šè¿°è¿‡ç¨‹ä¹‹åï¼Œæ–¹æ³•å­¦çš„æ¼”å˜åœ¨æœ€æ–°çš„æ–‡çŒ®ä¸­ç»§ç»­å‡ºç°äº†æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚

è¿™äº›æ¨¡å‹é€šè¿‡ç»“åˆå‡ ä¸ªæ·±åº¦å­¦ä¹ æ¨¡å‹æ¥è¿›ä¸€æ­¥æé«˜é¢„æµ‹å‡†ç¡®æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å…³æ³¨è¿™äº›æœ€æ–°æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½ï¼Œè€Œä¸æ˜¯æ•´ä¸ªäº¤é€šé¢„æµ‹æ–¹æ³•å­¦çš„æ¼”å˜ã€‚æˆ‘ä»¬å°†å¯¹å…ˆå‰æ¼”å˜çš„ç›¸å…³å†…å®¹æ„Ÿå…´è¶£çš„è¯»è€…æŒ‡å‘ç°æœ‰çš„è°ƒæŸ¥ã€‚ä¾‹å¦‚ï¼Œ[22â€“24]å®¡æŸ¥äº†ä¸“æ³¨äºè§£å†³çŸ­æœŸäº¤é€šé¢„æµ‹çš„æ¨¡å‹ã€‚å¦ä¸€æ–¹é¢ï¼Œ[25â€“27]é’ˆå¯¹æ›´ç»å…¸çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬åŸºäºç»Ÿè®¡å’ŒåŸºäºæœºå™¨å­¦ä¹ ï¼ˆMLï¼‰çš„æ¨¡å‹ï¼Œè€Œ[24,28,29]åˆ™ä¸“æ³¨äºæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚

æˆ‘ä»¬è¿˜æ³¨æ„åˆ°å¦ä¸€é¡¹å·¥ä½œ[30]ä»æ™ºèƒ½åŸå¸‚çš„è§’åº¦å®¡æŸ¥äº†äº¤é€šé¢„æµ‹ï¼Œå¹¶çªå‡ºæ˜¾ç¤ºäº†ç°æœ‰çš„äº¤é€šæ•°æ®æ¥æºå’Œåœ¨ITSä¸­èåˆäº¤é€šæ•°æ®çš„æ•°æ®æ¨¡å‹ã€‚æ­¤å¤–ï¼Œ[31]è¯¦ç»†æ¢è®¨å’Œè§£é‡Šäº†ä¸åŒçš„å›¾ç¥ç»ç½‘ç»œï¼ŒåŒ…æ‹¬å›¾å·ç§¯ç½‘ç»œå’Œå›¾æ³¨æ„ç½‘ç»œï¼Œç”¨äºè§£å†³å„ç§äº¤é€šé¢„æµ‹é—®é¢˜ï¼ˆå³é“è·¯äº¤é€šæµå’Œé€Ÿåº¦é¢„æµ‹ï¼Œå…¨ç½‘ç»œäº¤é€šæµå’Œé€Ÿåº¦é¢„æµ‹ä»¥åŠäº¤é€šéœ€æ±‚é¢„æµ‹ï¼‰ã€‚åŒæ—¶ï¼Œ[32]å¯¹åŸå¸‚äº¤é€šé¢„æµ‹çš„æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œäº†è°ƒæŸ¥å’Œåˆ†ç±»ï¼Œåˆ†ä¸ºåŸºäºç½‘æ ¼çš„ã€åŸºäºå›¾çš„å’Œå¤šå˜é‡æ—¶é—´åºåˆ—æ¨¡å‹ã€‚ä½œè€…æä¾›äº†ç”¨äºè¯„ä¼°æ‰€é€‰æ¨¡å‹æ€§èƒ½çš„åŸºå‡†ã€‚

æˆ‘ä»¬é‡‡ç”¨äº†ä¸åŒçš„æ–¹æ³•ï¼Œä¸“æ³¨äºæ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªä¸åŒçš„åˆ†ç±»æ³•ï¼ˆå‚è§ç¬¬3èŠ‚ï¼‰ï¼Œå¹¶æ ¹æ®ä½“ç³»ç»“æ„è®¾è®¡ã€æ•°å­¦åŸºç¡€å’Œæ€§èƒ½å¯¹æˆ‘ä»¬åˆ†ç±»æ³•ä¸­ä¸åŒç±»åˆ«çš„ä»£è¡¨æ€§æ¨¡å‹è¿›è¡Œäº†è¿›ä¸€æ­¥çš„åˆ†æå’Œè¯„ä¼°ã€‚

Our work here then are twofold, a specific targeted review of the hybrid deep learning models and a comprehensive performance comparison study. The main contributions of this work are summarized as follows: 

+ We review and taxonomize hybrid deep learning models for traffic prediction in the literature.

+ We analyze the common architectural choices and the constituent sub-models of these hybrid models based on mathematical theories. Ten representative models are then selected for the model architecture analysis in detail based on our taxonomy.

+ We conduct extensive comparative experiments on the selected models. The evaluation results presented in the literature use different settings and datasets. It is then difficult to compare their performance under common conditions. As such, we reconstruct the models and compare their performance fairly under identical experiment setup and datasets. In our experiments, we use datasets with different traffic profiles including both frequent and infrequent congestion from real road networks. We consider both short- and long-term traffic prediction tasks.

+ Furthermore, to facilitate future research, we also collected and summarized publicly available traffic datasets frequently used in the literature

æˆ‘ä»¬åœ¨è¿™é‡Œçš„å·¥ä½œæœ‰ä¸¤ä¸ªæ–¹é¢ï¼Œä¸€æ˜¯å¯¹æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹çš„å…·ä½“æœ‰é’ˆå¯¹æ€§çš„å®¡æŸ¥ï¼ŒäºŒæ˜¯ä¸€é¡¹å…¨é¢çš„æ€§èƒ½æ¯”è¾ƒç ”ç©¶ã€‚è¿™é¡¹å·¥ä½œçš„ä¸»è¦è´¡çŒ®æ€»ç»“å¦‚ä¸‹ï¼š

- æˆ‘ä»¬å›é¡¾å’Œåˆ†ç±»æ–‡çŒ®ä¸­ç”¨äºäº¤é€šé¢„æµ‹çš„æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚
- æˆ‘ä»¬åŸºäºæ•°å­¦ç†è®ºåˆ†æäº†è¿™äº›æ··åˆæ¨¡å‹çš„å¸¸è§æ¶æ„é€‰æ‹©å’Œç»„æˆå­æ¨¡å‹ã€‚ç„¶åï¼Œæˆ‘ä»¬æ ¹æ®æˆ‘ä»¬çš„åˆ†ç±»æ³•è¯¦ç»†é€‰æ‹©äº†åä¸ªä»£è¡¨æ€§æ¨¡å‹è¿›è¡Œæ¨¡å‹æ¶æ„åˆ†æã€‚
- æˆ‘ä»¬å¯¹æ‰€é€‰çš„æ¨¡å‹è¿›è¡Œäº†å¹¿æ³›çš„æ¯”è¾ƒå®éªŒã€‚æ–‡çŒ®ä¸­å‘ˆç°çš„è¯„ä¼°ç»“æœä½¿ç”¨äº†ä¸åŒçš„è®¾ç½®å’Œæ•°æ®é›†ã€‚å› æ­¤ï¼Œå¾ˆéš¾åœ¨ç›¸åŒçš„æ¡ä»¶ä¸‹æ¯”è¾ƒå®ƒä»¬çš„æ€§èƒ½ã€‚å› æ­¤ï¼Œåœ¨ç›¸åŒçš„å®éªŒè®¾ç½®å’Œæ•°æ®é›†ä¸‹ï¼Œæˆ‘ä»¬é‡å»ºäº†æ¨¡å‹å¹¶å…¬å¹³æ¯”è¾ƒå®ƒä»¬çš„æ€§èƒ½ã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†åŒ…æ‹¬çœŸå®é“è·¯ç½‘ç»œä¸­çš„é¢‘ç¹å’Œä¸é¢‘ç¹æ‹¥å µåœ¨å†…çš„ä¸åŒäº¤é€šé…ç½®æ–‡ä»¶çš„æ•°æ®é›†ã€‚æˆ‘ä»¬è€ƒè™‘äº†çŸ­æœŸå’Œé•¿æœŸçš„äº¤é€šé¢„æµ‹ä»»åŠ¡ã€‚
- æ­¤å¤–ï¼Œä¸ºäº†ä¿ƒè¿›æœªæ¥çš„ç ”ç©¶ï¼Œæˆ‘ä»¬è¿˜æ”¶é›†å¹¶æ€»ç»“äº†æ–‡çŒ®ä¸­ç»å¸¸ä½¿ç”¨çš„å…¬å¼€äº¤é€šæ•°æ®é›†ã€‚

*The rest of this paper is organized as follows. First, in Section 2, we present a generalized traffic prediction problem formulation based on existing work. Next, in Section 3, we review the latest hybrid deep learning models from recent literature and create a taxonomy with three main types of models: (1) CNN-based models, (2) GCNbased models and (3) transformer-based models. In this section, we discuss the evolution of traffic prediction models from CNN-based models to GCN-based models. In Section 4, we synthesize the common main modules exploited in recent hybrid deep learning models and review the fundamentals of these modules individually. Then, we select ten representative hybrid deep learning models for deep architecture analysis in Section 5. Section 6 summarizes commonly used public data sources for traffic prediction to help researchers further develop more valuable works while Section 7 presents our comparative performance evaluation experiments in which we reconstructed the selected models and evaluate them under equal conditions using three large traffic datasets from real-world road networks. Finally, we conclude our work and discuss future challenges of traffic prediction problem on large-scale road networks in Section 8.*

æœ¬æ–‡çš„å…¶ä½™éƒ¨åˆ†å®‰æ’å¦‚ä¸‹ã€‚é¦–å…ˆï¼Œåœ¨ç¬¬2èŠ‚ä¸­ï¼Œæˆ‘ä»¬åŸºäºç°æœ‰å·¥ä½œæå‡ºäº†ä¸€ä¸ªæ¦‚æ‹¬çš„äº¤é€šé¢„æµ‹é—®é¢˜è¡¨è¿°ã€‚æ¥ä¸‹æ¥ï¼Œåœ¨ç¬¬3èŠ‚ä¸­ï¼Œæˆ‘ä»¬å›é¡¾äº†æœ€æ–°çš„æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¹¶åˆ›å»ºäº†ä¸€ä¸ªåŒ…æ‹¬ä¸‰ç§ä¸»è¦ç±»å‹çš„æ¨¡å‹çš„åˆ†ç±»æ³•ï¼šï¼ˆ1ï¼‰åŸºäºCNNçš„æ¨¡å‹ï¼Œï¼ˆ2ï¼‰åŸºäºGCNçš„æ¨¡å‹å’Œï¼ˆ3ï¼‰åŸºäºtransformerçš„æ¨¡å‹ã€‚åœ¨è¿™ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†äº¤é€šé¢„æµ‹æ¨¡å‹ä»åŸºäºCNNçš„æ¨¡å‹åˆ°åŸºäºGCNçš„æ¨¡å‹çš„æ¼”å˜ã€‚åœ¨ç¬¬4èŠ‚ä¸­ï¼Œæˆ‘ä»¬ç»¼åˆäº†æœ€è¿‘æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­åˆ©ç”¨çš„å¸¸è§ä¸»è¦æ¨¡å—ï¼Œå¹¶é€ä¸ªå›é¡¾äº†è¿™äº›æ¨¡å—çš„åŸºç¡€çŸ¥è¯†ã€‚ç„¶åï¼Œåœ¨ç¬¬5èŠ‚ä¸­ï¼Œæˆ‘ä»¬é€‰æ‹©äº†åä¸ªä»£è¡¨æ€§çš„æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œæ·±åº¦æ¶æ„åˆ†æã€‚ç¬¬6èŠ‚æ€»ç»“äº†äº¤é€šé¢„æµ‹ä¸­å¸¸ç”¨çš„å…¬å…±æ•°æ®æ¥æºï¼Œä»¥å¸®åŠ©ç ”ç©¶äººå‘˜è¿›ä¸€æ­¥å¼€å‘æ›´æœ‰ä»·å€¼çš„ä½œå“ï¼Œè€Œç¬¬7èŠ‚åˆ™å‘ˆç°äº†æˆ‘ä»¬çš„æ¯”è¾ƒæ€§èƒ½è¯„ä¼°å®éªŒï¼Œåœ¨è¿™äº›å®éªŒä¸­ï¼Œæˆ‘ä»¬é‡å»ºäº†æ‰€é€‰çš„æ¨¡å‹ï¼Œå¹¶åœ¨ç›¸åŒçš„æ¡ä»¶ä¸‹ä½¿ç”¨æ¥è‡ªçœŸå®é“è·¯ç½‘ç»œçš„ä¸‰ä¸ªå¤§å‹äº¤é€šæ•°æ®é›†å¯¹å®ƒä»¬è¿›è¡Œè¯„ä¼°ã€‚æœ€åï¼Œåœ¨ç¬¬8èŠ‚ä¸­ï¼Œæˆ‘ä»¬æ€»ç»“äº†æˆ‘ä»¬çš„å·¥ä½œå¹¶è®¨è®ºäº†æœªæ¥åœ¨å¤§è§„æ¨¡é“è·¯ç½‘ç»œä¸Šè¿›è¡Œäº¤é€šé¢„æµ‹é—®é¢˜çš„æŒ‘æˆ˜ã€‚





## ä¸‰ã€åˆ†ç±»

*We present a summary of the hybrid deep learning models in Table 1 according to their main constituent models and further segregated chronologically by year of publication. We also show the prediction task (either predicting traffic flow, speed and/or occupancy), the prediction horizon considered and the dataset(s) used in these works. From our review as well as insights from [18,39â€“41], existing hybrid deep learning models commonly consist of two main modules, respectively for analyzing spatial and temporal dependencies. Furthermore, these models commonly contain CNN or GCN for spatial dependency analysis and LSTM or GRU for temporal dependency analysis. To facilitate the building of the taxonomy, we further define the following:*

æˆ‘ä»¬æ ¹æ®ä¸»è¦ç»„æˆæ¨¡å‹ä»¥åŠæŒ‰å‡ºç‰ˆå¹´ä»½çš„å…ˆåé¡ºåºï¼Œåœ¨è¡¨æ ¼1ä¸­æ€»ç»“äº†æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†è¿™äº›å·¥ä½œä¸­è€ƒè™‘çš„é¢„æµ‹ä»»åŠ¡ï¼ˆæ˜¯å¦é¢„æµ‹äº¤é€šæµã€é€Ÿåº¦å’Œ/æˆ–å ç”¨ï¼‰ï¼Œè€ƒè™‘çš„é¢„æµ‹æ—¶æ®µä»¥åŠä½¿ç”¨çš„æ•°æ®é›†ã€‚æ ¹æ®æˆ‘ä»¬çš„å®¡é˜…ä»¥åŠæ¥è‡ª[18,39â€“41]çš„è§è§£ï¼Œç°æœ‰çš„æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹é€šå¸¸åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼Œåˆ†åˆ«ç”¨äºåˆ†æç©ºé—´å’Œæ—¶é—´ä¾èµ–æ€§ã€‚æ­¤å¤–ï¼Œè¿™äº›æ¨¡å‹é€šå¸¸åŒ…å«ç”¨äºç©ºé—´ä¾èµ–æ€§åˆ†æçš„CNNæˆ–GCNä»¥åŠç”¨äºæ—¶é—´ä¾èµ–æ€§åˆ†æçš„LSTMæˆ–GRUã€‚ä¸ºäº†ä¾¿äºå»ºç«‹åˆ†ç±»æ³•ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å®šä¹‰å¦‚ä¸‹ï¼š

Definition 1 (Fixed Spatialâ€“Temporal Feature). The fixed spatialâ€“ temporal feature does not consider the different influences of:

+ different road segments on the targeted road segment in space domain, and 

+ different previous time intervals on the targeted time interval in time domain.

å®šä¹‰1ï¼ˆå›ºå®šæ—¶ç©ºç‰¹å¾ï¼‰ã€‚å›ºå®šæ—¶ç©ºç‰¹å¾ä¸è€ƒè™‘ä»¥ä¸‹å› ç´ çš„ä¸åŒå½±å“ï¼š

+ ç©ºé—´åŸŸå†…ä¸åŒé“è·¯æ®µå¯¹ç›®æ ‡é“è·¯æ®µçš„å½±å“

+ æ—¶é—´åŸŸå†…ä¸åŒå…ˆå‰æ—¶é—´é—´éš”å¯¹ç›®æ ‡æ—¶é—´é—´éš”çš„å½±å“ã€‚

Definition 2 (Dynamic Spatialâ€“Temporal Feature). The dynamic spatialâ€“ temporal feature considers both

+ the different road segmentsâ€™ contributions to the targeted road segment in space domain, and/or 

+ the different contributions of previous time intervals to the targeted time interval in time domain.

å®šä¹‰2ï¼ˆåŠ¨æ€æ—¶ç©ºç‰¹å¾ï¼‰ã€‚åŠ¨æ€æ—¶ç©ºç‰¹å¾è€ƒè™‘ä»¥ä¸‹ä¸¤ä¸ªæ–¹é¢ï¼š 

+ ç©ºé—´åŸŸå†…ä¸åŒé“è·¯æ®µå¯¹ç›®æ ‡é“è·¯æ®µçš„å½±å“
+ æ—¶é—´åŸŸå†…ä¸åŒå…ˆå‰æ—¶é—´é—´éš”å¯¹ç›®æ ‡æ—¶é—´é—´éš”çš„å½±å“ã€‚

*From the above, we first classify the reviewed models into three categories based on the technologies used for analyzing spatial dependencies: (1) CNN-based models, (2) GCN-based models, and (3) transformer-based models. We then further segregate them based on Definitions 1 and 2. Our taxonomy is shown in Fig. 1. In the following, we detail our taxonomy.*

ä»ä¸Šé¢çš„å†…å®¹ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆæ ¹æ®ç”¨äºåˆ†æç©ºé—´ä¾èµ–æ€§çš„æŠ€æœ¯å°†ç ”ç©¶è¿‡çš„æ¨¡å‹åˆ†ä¸ºä¸‰ç±»ï¼š

ï¼ˆ1ï¼‰åŸºäºCNNçš„æ¨¡å‹

ï¼ˆ2ï¼‰åŸºäºGCNçš„æ¨¡å‹

ï¼ˆ3ï¼‰åŸºäºtransformerçš„æ¨¡å‹

ç„¶åï¼Œæˆ‘ä»¬æ ¹æ®å®šä¹‰1å’Œå®šä¹‰2è¿›ä¸€æ­¥å°†å®ƒä»¬åˆ†å¼€ã€‚æˆ‘ä»¬çš„åˆ†ç±»æ³•å¦‚å›¾1æ‰€ç¤ºã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è¯¦ç»†è¯´æ˜æˆ‘ä»¬çš„åˆ†ç±»æ³•ã€‚

### 3.1 åŸºäºCNNçš„æ¨¡å‹

*The CNN model has been applied in different fields including sentence classification [72], image classification [73], video classification [74] and human action recognition [75]. It extracts local spatial features via its convolutional kernels. CNN was introduced into traffic prediction solutions specifically for processing spatial correlation [76].*

*For example, [77] exploited CNN to predict traffic speed on largescale road networks by representing traffic data as images. However, since CNN focuses on extracting spatial feature, [77] has neglected the importance of temporal features. As such, to supplement CNN, LSTM and GRU are often combined with CNN to form hybrid deep learning models for extracting temporal features (cf. Table 1). These CNN-based hybrid models can be further divided into two main approaches as follows:*

å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å·²ç»åº”ç”¨äºä¸åŒçš„é¢†åŸŸï¼ŒåŒ…æ‹¬å¥å­åˆ†ç±»[72]ã€å›¾åƒåˆ†ç±»[73]ã€è§†é¢‘åˆ†ç±»[74]å’Œäººä½“åŠ¨ä½œè¯†åˆ«[75]ã€‚å®ƒé€šè¿‡å·ç§¯æ ¸æå–å±€éƒ¨ç©ºé—´ç‰¹å¾ã€‚CNNè¢«å¼•å…¥äº¤é€šé¢„æµ‹è§£å†³æ–¹æ¡ˆä¸­ï¼Œç‰¹åˆ«æ˜¯ç”¨äºå¤„ç†ç©ºé—´ç›¸å…³æ€§[76]ã€‚

ä¾‹å¦‚ï¼Œ[77]åˆ©ç”¨CNNé¢„æµ‹å¤§è§„æ¨¡é“è·¯ç½‘ç»œä¸Šçš„äº¤é€šé€Ÿåº¦ï¼Œå°†äº¤é€šæ•°æ®è¡¨ç¤ºä¸ºå›¾åƒã€‚ç„¶è€Œï¼Œç”±äºCNNä¸“æ³¨äºæå–ç©ºé—´ç‰¹å¾ï¼Œ[77]å¿½è§†äº†æ—¶é—´ç‰¹å¾çš„é‡è¦æ€§ã€‚å› æ­¤ï¼Œä¸ºäº†è¡¥å……CNNï¼Œé€šå¸¸å°†LSTMå’ŒGRUä¸CNNç»“åˆå½¢æˆæ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹ä»¥æå–æ—¶é—´ç‰¹å¾ï¼ˆå‚è§è¡¨1ï¼‰ã€‚è¿™äº›åŸºäºCNNçš„æ··åˆæ¨¡å‹å¯ä»¥è¿›ä¸€æ­¥åˆ†ä¸ºä¸¤ç§ä¸»è¦æ–¹æ³•ï¼š

#### 3.1.1 å›ºå®šæ—¶ç©ºç‰¹å¾çš„æ¨¡å‹

*CNN-based hybrid deep learning models based on fixed spatialâ€“ temporal feature modeling consider the spatialâ€“temporal dependencies of traffic data being fixed via sharing of parameters. Hence, the traffic states of different neighboring road segments in the space domain are considered to have the same effect on the traffic state of the targeted road segment while, in time domain, traffic data in different previous time intervals also affect traffic state in the future time interval in the same level.*

åŸºäºå›ºå®šæ—¶ç©ºç‰¹å¾å»ºæ¨¡çš„åŸºäºCNNçš„æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹é€šè¿‡å‚æ•°å…±äº«è€ƒè™‘äº¤é€šæ•°æ®çš„æ—¶ç©ºä¾èµ–å…³ç³»æ˜¯å›ºå®šçš„ã€‚å› æ­¤ï¼Œåœ¨ç©ºé—´åŸŸå†…ï¼Œä¸åŒç›¸é‚»é“è·¯æ®µçš„äº¤é€šçŠ¶æ€è¢«è®¤ä¸ºå¯¹ç›®æ ‡é“è·¯æ®µçš„äº¤é€šçŠ¶æ€æœ‰ç›¸åŒçš„å½±å“ï¼Œè€Œåœ¨æ—¶é—´åŸŸå†…ï¼Œä¸åŒçš„å…ˆå‰æ—¶é—´é—´éš”çš„äº¤é€šæ•°æ®ä¹Ÿä»¥ç›¸åŒçº§åˆ«å½±å“æœªæ¥æ—¶é—´é—´éš”å†…çš„äº¤é€šçŠ¶æ€ã€‚

*In terms of extracting fixed spatialâ€“temporal features for traffic prediction, [42] used a 1D CNN and two LSTMs to build a hybrid deep learning model named CLTFP. The 1D CNN is used to extract inner spatial dependencies of the road network. One LSTM is used to capture short-term temporal features from previous hours while the other LSTM is utilized to extract periodic features from past days and weeks. The spatial, short-term temporal and periodic features are fused into a feature vector and then sent to a regression layer to perform predicting. Two similar models (named TreNet and U-Net) were developed by [50,57], respectively. Compared to [42,50,57] that extract spatial and temporal features using CNN and LSTM, respectively, [43] combined CNN and LSTM to generate a Conv-LSTM module for spatialâ€“temporal feature modeling and also adopt a Bi-LSTM to analyze periodical features from historical traffic data. Considering the influence of external factors on traffic prediction, such as weather conditions and the physical characteristics of roads, [52] developed the DELA model. This model not only includes an integrated model composed of CNN and LSTM for spatialâ€“temporal feature extraction but also contains a fully-connected layer based embedding component for learning external factors such as route structure, weather conditions and date information.*

åœ¨æå–å›ºå®šæ—¶ç©ºç‰¹å¾ä»¥è¿›è¡Œäº¤é€šé¢„æµ‹æ–¹é¢ï¼Œ[42] ä½¿ç”¨äº†ä¸€ç»´CNNå’Œä¸¤ä¸ªLSTMæ„å»ºäº†ä¸€ä¸ªåä¸ºCLTFPçš„æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚ä¸€ç»´CNNç”¨äºæå–é“è·¯ç½‘ç»œçš„å†…éƒ¨ç©ºé—´ä¾èµ–å…³ç³»ã€‚ä¸€ä¸ªLSTMç”¨äºæ•æ‰å…ˆå‰å‡ å°æ—¶çš„çŸ­æœŸæ—¶é—´ç‰¹å¾ï¼Œè€Œå¦ä¸€ä¸ªLSTMåˆ™ç”¨äºæå–è¿‡å»å‡ å¤©å’Œå‡ å‘¨çš„å‘¨æœŸç‰¹å¾ã€‚ç©ºé—´ã€çŸ­æœŸæ—¶é—´å’Œå‘¨æœŸç‰¹å¾è¢«èåˆæˆä¸€ä¸ªç‰¹å¾å‘é‡ï¼Œç„¶åä¼ é€’åˆ°å›å½’å±‚è¿›è¡Œé¢„æµ‹ã€‚[50,57]åˆ†åˆ«å¼€å‘äº†ä¸¤ä¸ªç±»ä¼¼çš„æ¨¡å‹ï¼ˆåä¸ºTreNetå’ŒU-Netï¼‰ã€‚ä¸[42,50,57]åˆ†åˆ«ä½¿ç”¨CNNå’ŒLSTMæå–ç©ºé—´å’Œæ—¶é—´ç‰¹å¾ä¸åŒï¼Œ[43]ç»“åˆäº†CNNå’ŒLSTMç”ŸæˆConv-LSTMæ¨¡å—è¿›è¡Œç©ºé—´-æ—¶é—´ç‰¹å¾å»ºæ¨¡ï¼Œå¹¶é‡‡ç”¨Bi-LSTMåˆ†æå†å²äº¤é€šæ•°æ®çš„å‘¨æœŸç‰¹å¾ã€‚è€ƒè™‘åˆ°å¤–éƒ¨å› ç´ å¯¹äº¤é€šé¢„æµ‹çš„å½±å“ï¼Œæ¯”å¦‚å¤©æ°”æ¡ä»¶å’Œé“è·¯çš„ç‰©ç†ç‰¹æ€§ï¼Œ[52]å¼€å‘äº†DELAæ¨¡å‹ã€‚è¯¥æ¨¡å‹ä¸ä»…åŒ…æ‹¬ç”±CNNå’ŒLSTMç»„æˆçš„ç»¼åˆæ¨¡å‹è¿›è¡Œç©ºé—´-æ—¶é—´ç‰¹å¾æå–ï¼Œè¿˜åŒ…å«ä¸€ä¸ªåŸºäºå…¨è¿æ¥å±‚çš„åµŒå…¥ç»„ä»¶ï¼Œç”¨äºå­¦ä¹ è·¯çº¿ç»“æ„ã€å¤©æ°”æ¡ä»¶å’Œæ—¥æœŸä¿¡æ¯ç­‰å¤–éƒ¨å› ç´ ã€‚

*To analyze and extract more detailed features for improved prediction accuracy, [48,78] proposed models based on CNN and LSTM, namely STRCNs and ALLSCP respectively, for traffic flow prediction based on hourly, daily and weekly spatialâ€“temporal feature extraction.*

*The differences between STRCNs and ALLSCP are that the former model feeds external factors, such as weather conditions, wind and holidays, into a fully-connected layer for external feature extraction while the latter one considers different types of roads. Specifically, ALLSCP differentiates between linear roadways and road intersections and designs different input matrices for those two types roadways when considering that traffic states on linear roadways are affected by the traffic states of upstream and downstream while, for road intersections, the traffic states are affected by the traffic states of the different entrances and exits. Another model that considered the types of roads when predicting traffic states is [45] where it firstly used a Spatialâ€“Temporal Correlation Algorithm (STCA) to identify and extract the critical road sections and then utilized a hybrid deep learning model (named CRS-ConvLSTM NN) based on CNN and LSTM for traffic speed prediction on these critical road sections. Considering the success of CNN in the area of image recognition, some of CNN-based models proposed to convert traffic data to images and then, learn spatialâ€“temporal features from those images. SRCNs [44] and MSTFLN [49] are two examples following this approach. Both models combine CNN and LSTM to analyze spatialâ€“ temporal features from generated traffic images. SRCNs uses CNN to learn spatial features and LSTM to learn temporal features. MSTFLN utilizes three ConvLSTM modules composed of CNN and LSTM to learn spatialâ€“temporal features and then concatenate those features to pass to another CNN module for final prediction. Based on the encoderâ€“decoder architecture, [53] developed a stacked autoencoder, including an encoder based on CNNs and a decoder based on BiLSTMs, for traffic flow and speed prediction. Another model (named STCNN) was proposed in [54] for predicting long-term traffic flow.*

*The encoder consists of a ConvLSTM to learn the spatialâ€“temporal traffic dependencies and a Skip-ConvLSTM to learn the periodic traffic patterns. The decoder consists of another ConvLSTM for decoding the spatialâ€“temporal dependencies from the output of the encoder.*

ä¸ºäº†åˆ†æå¹¶æå–æ›´è¯¦ç»†çš„ç‰¹å¾ä»¥æé«˜é¢„æµ‹å‡†ç¡®æ€§ï¼Œ[48,78]åˆ†åˆ«æå‡ºäº†åŸºäºCNNå’ŒLSTMçš„æ¨¡å‹ï¼Œå³STRCNså’ŒALLSCPï¼Œç”¨äºåŸºäºå°æ—¶ã€æ—¥å’Œå‘¨çš„ç©ºé—´-æ—¶é—´ç‰¹å¾æå–çš„äº¤é€šæµé¢„æµ‹ã€‚

STRCNså’ŒALLSCPä¹‹é—´çš„åŒºåˆ«åœ¨äºå‰è€…å°†å¤–éƒ¨å› ç´ ï¼ˆå¦‚å¤©æ°”æ¡ä»¶ã€é£å’Œå‡æœŸï¼‰è¾“å…¥åˆ°ä¸€ä¸ªå…¨è¿æ¥å±‚ä¸­è¿›è¡Œå¤–éƒ¨ç‰¹å¾æå–ï¼Œè€Œåè€…è€ƒè™‘äº†ä¸åŒç±»å‹çš„é“è·¯ã€‚å…·ä½“è€Œè¨€ï¼ŒALLSCPåŒºåˆ†äº†çº¿æ€§é“è·¯å’Œé“è·¯äº¤å‰å£ï¼Œå¹¶åœ¨è€ƒè™‘åˆ°çº¿æ€§é“è·¯ä¸Šçš„äº¤é€šçŠ¶æ€å—åˆ°ä¸Šæ¸¸å’Œä¸‹æ¸¸äº¤é€šçŠ¶æ€å½±å“çš„æƒ…å†µä¸‹ï¼Œä¸ºè¿™ä¸¤ç§ç±»å‹çš„é“è·¯è®¾è®¡äº†ä¸åŒçš„è¾“å…¥çŸ©é˜µï¼Œå¯¹äºé“è·¯äº¤å‰å£ï¼Œäº¤é€šçŠ¶æ€å—åˆ°ä¸åŒå…¥å£å’Œå‡ºå£çš„äº¤é€šçŠ¶æ€å½±å“ã€‚å¦ä¸€ä¸ªåœ¨é¢„æµ‹äº¤é€šçŠ¶æ€æ—¶è€ƒè™‘åˆ°é“è·¯ç±»å‹çš„æ¨¡å‹æ˜¯[45]ï¼Œå®ƒé¦–å…ˆä½¿ç”¨ç©ºé—´-æ—¶é—´ç›¸å…³ç®—æ³•ï¼ˆSTCAï¼‰è¯†åˆ«å’Œæå–å…³é”®é“è·¯æ®µï¼Œç„¶ååˆ©ç”¨åŸºäºCNNå’ŒLSTMçš„æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå‘½åä¸ºCRS-ConvLSTM NNï¼‰è¿›è¡Œè¿™äº›å…³é”®é“è·¯æ®µçš„äº¤é€šé€Ÿåº¦é¢„æµ‹ã€‚è€ƒè™‘åˆ°CNNåœ¨å›¾åƒè¯†åˆ«é¢†åŸŸçš„æˆåŠŸï¼Œä¸€äº›åŸºäºCNNçš„æ¨¡å‹æå‡ºå°†äº¤é€šæ•°æ®è½¬æ¢ä¸ºå›¾åƒï¼Œç„¶åä»è¿™äº›å›¾åƒä¸­å­¦ä¹ ç©ºé—´-æ—¶é—´ç‰¹å¾ã€‚SRCNs [44]å’ŒMSTFLN [49]æ˜¯éµå¾ªè¿™ç§æ–¹æ³•çš„ä¸¤ä¸ªä¾‹å­ã€‚è¿™ä¸¤ä¸ªæ¨¡å‹éƒ½ç»“åˆäº†CNNå’ŒLSTMï¼Œä»¥ä»ç”Ÿæˆçš„äº¤é€šå›¾åƒä¸­åˆ†æç©ºé—´-æ—¶é—´ç‰¹å¾ã€‚SRCNsä½¿ç”¨CNNå­¦ä¹ ç©ºé—´ç‰¹å¾å’ŒLSTMå­¦ä¹ æ—¶é—´ç‰¹å¾ã€‚MSTFLNåˆ©ç”¨ç”±CNNå’ŒLSTMç»„æˆçš„ä¸‰ä¸ªConvLSTMæ¨¡å—å­¦ä¹ ç©ºé—´-æ—¶é—´ç‰¹å¾ï¼Œç„¶åå°†è¿™äº›ç‰¹å¾è¿æ¥èµ·æ¥ä¼ é€’åˆ°å¦ä¸€ä¸ªCNNæ¨¡å—è¿›è¡Œæœ€ç»ˆé¢„æµ‹ã€‚åŸºäºç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œ[53]å¼€å‘äº†ä¸€ä¸ªå †å çš„è‡ªåŠ¨ç¼–ç å™¨ï¼ŒåŒ…æ‹¬ä¸€ä¸ªåŸºäºCNNçš„ç¼–ç å™¨å’Œä¸€ä¸ªåŸºäºBiLSTMçš„è§£ç å™¨ï¼Œç”¨äºäº¤é€šæµå’Œé€Ÿåº¦çš„é¢„æµ‹ã€‚å¦ä¸€ä¸ªæ¨¡å‹ï¼ˆåä¸ºSTCNNï¼‰æ˜¯åœ¨[54]ä¸­æå‡ºçš„ï¼Œç”¨äºé¢„æµ‹é•¿æœŸäº¤é€šæµã€‚ç¼–ç å™¨åŒ…æ‹¬ä¸€ä¸ªConvLSTMï¼Œç”¨äºå­¦ä¹ ç©ºé—´-æ—¶é—´äº¤é€šä¾èµ–å…³ç³»ï¼Œä»¥åŠä¸€ä¸ªSkip-ConvLSTMï¼Œç”¨äºå­¦ä¹ å‘¨æœŸæ€§äº¤é€šæ¨¡å¼ã€‚è§£ç å™¨åŒ…æ‹¬å¦ä¸€ä¸ªConvLSTMï¼Œç”¨äºä»ç¼–ç å™¨çš„è¾“å‡ºä¸­è§£ç ç©ºé—´-æ—¶é—´ä¾èµ–å…³ç³»ã€‚



#### 3.1.2 åŠ¨æ€æ—¶ç©ºç‰¹å¾çš„æ¨¡å‹

*In reality, different neighboring road segments impact traffic state on the targeted road segment differently. Similarly, traffic states in different previous time intervals also bring different effects to the traffic state in the future. Due to these, the attention mechanism [79], that represents a major breakthrough in the natural language processing field, was introduced into traffic prediction problems. It defines different weights in space and/or time dimensions for modeling dynamic spatialâ€“temporal dependencies to account for the non-uniform contributions of neighboring road segments and time intervals to the final prediction. CNN-based models, that exploit attention mechanism in CNN and/or LSTM (GRU), are able to analyze dynamic spatial and/or temporal features for traffic prediction.*

åœ¨ç°å®ä¸­ï¼Œä¸åŒçš„ç›¸é‚»é“è·¯æ®µå¯¹ç›®æ ‡é“è·¯æ®µçš„äº¤é€šçŠ¶æ€äº§ç”Ÿä¸åŒçš„å½±å“ã€‚åŒæ ·ï¼Œä¸åŒçš„å…ˆå‰æ—¶é—´é—´éš”çš„äº¤é€šçŠ¶æ€ä¹Ÿå¯¹å°†æ¥çš„äº¤é€šçŠ¶æ€äº§ç”Ÿä¸åŒçš„å½±å“ã€‚ç”±äºè¿™äº›åŸå› ï¼Œæ³¨æ„æœºåˆ¶ [79]ï¼Œåœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå–å¾—äº†é‡å¤§çªç ´ï¼Œè¢«å¼•å…¥åˆ°äº¤é€šé¢„æµ‹é—®é¢˜ä¸­ã€‚å®ƒåœ¨ç©ºé—´å’Œ/æˆ–æ—¶é—´ç»´åº¦ä¸Šå®šä¹‰ä¸åŒçš„æƒé‡ï¼Œä»¥å»ºæ¨¡åŠ¨æ€çš„ç©ºé—´-æ—¶é—´ä¾èµ–å…³ç³»ï¼Œä»¥è€ƒè™‘ç›¸é‚»é“è·¯æ®µå’Œæ—¶é—´é—´éš”å¯¹æœ€ç»ˆé¢„æµ‹çš„éå‡åŒ€è´¡çŒ®ã€‚åŸºäºCNNçš„æ¨¡å‹ï¼Œåˆ©ç”¨CNNå’Œ/æˆ–LSTMï¼ˆGRUï¼‰ä¸­çš„æ³¨æ„æœºåˆ¶ï¼Œèƒ½å¤Ÿåˆ†æäº¤é€šé¢„æµ‹çš„åŠ¨æ€ç©ºé—´å’Œ/æˆ–æ—¶é—´ç‰¹å¾ã€‚

*Dynamic on Temporal Features: Wu et al [46] proposed the Deep Neural Network-Based Traffic Flow prediction (DNN-BTF) model, which uses the attention mechanism to select near-term data from previous time intervals that is highly correlated to the future traffic flow and then compute the corresponding weights to previous traffic flows. The weighted traffic flows in time domain help CNN and GRU to learn spatial and dynamic temporal features, respectively. Similar to [46,80] also built an attention module to generate weighted past traffic data. The weighted traffic data is first sent to CNN module for spatial feature learning and then to an LSTM module for dynamic temporal feature learning. WSTNet [51] is another model that uses the attention mechanism for dynamic temporal feature extraction. It is an end-to-end deep learning model based on wavelet multi-scale analysis for network-wide traffic prediction. WSTNet firstly decomposes original traffic data into multi-level time frequency traffic matrix at different time scales by the discrete wavelet decomposition and then applied CNN for spatial feature extraction before finally sent to the LSTM with attention mechanism for dynamic temporal feature learning.*

*Another work in [81] also joined attention mechanism with LSTM for dynamic temporal feature extraction. Specifically, [81] uses two additional LSTMs for daily and weekly periodicity analysis and this enables the model to have more temporal features for the final prediction*

åŠ¨æ€æ—¶é—´ç‰¹å¾ï¼šWuç­‰äºº [46] æå‡ºäº†åŸºäºæ·±åº¦ç¥ç»ç½‘ç»œçš„äº¤é€šæµé‡é¢„æµ‹æ¨¡å‹ï¼ˆDNN-BTFï¼‰ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨æ³¨æ„æœºåˆ¶ä»å…ˆå‰çš„æ—¶é—´é—´éš”ä¸­é€‰æ‹©ä¸æœªæ¥äº¤é€šæµé«˜åº¦ç›¸å…³çš„è¿‘æœŸæ•°æ®ï¼Œå¹¶è®¡ç®—ä¸å…ˆå‰äº¤é€šæµç›¸å¯¹åº”çš„æƒé‡ã€‚æ—¶é—´åŸŸä¸­åŠ æƒçš„äº¤é€šæµå¯ä»¥å¸®åŠ©CNNå’ŒGRUåˆ†åˆ«å­¦ä¹ ç©ºé—´å’ŒåŠ¨æ€æ—¶é—´ç‰¹å¾ã€‚ç±»ä¼¼åœ°ï¼Œ[46,80] ä¹Ÿæ„å»ºäº†ä¸€ä¸ªæ³¨æ„æ¨¡å—æ¥ç”ŸæˆåŠ æƒçš„è¿‡å»äº¤é€šæ•°æ®ã€‚åŠ æƒçš„äº¤é€šæ•°æ®é¦–å…ˆé€å…¥CNNæ¨¡å—è¿›è¡Œç©ºé—´ç‰¹å¾å­¦ä¹ ï¼Œç„¶åä¼ é€åˆ°LSTMæ¨¡å—è¿›è¡ŒåŠ¨æ€æ—¶é—´ç‰¹å¾å­¦ä¹ ã€‚WSTNet [51] æ˜¯å¦ä¸€ä¸ªåˆ©ç”¨æ³¨æ„æœºåˆ¶è¿›è¡ŒåŠ¨æ€æ—¶é—´ç‰¹å¾æå–çš„æ¨¡å‹ã€‚å®ƒæ˜¯åŸºäºå°æ³¢å¤šå°ºåº¦åˆ†æçš„ç½‘ç»œèŒƒå›´äº¤é€šé¢„æµ‹çš„ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚WSTNeté¦–å…ˆé€šè¿‡ç¦»æ•£å°æ³¢åˆ†è§£å°†åŸå§‹äº¤é€šæ•°æ®åˆ†è§£ä¸ºä¸åŒæ—¶é—´å°ºåº¦çš„å¤šçº§æ—¶é—´é¢‘ç‡äº¤é€šçŸ©é˜µï¼Œç„¶ååº”ç”¨CNNè¿›è¡Œç©ºé—´ç‰¹å¾æå–ï¼Œæœ€åä¼ é€åˆ°å¸¦æœ‰æ³¨æ„æœºåˆ¶çš„LSTMè¿›è¡ŒåŠ¨æ€æ—¶é—´ç‰¹å¾å­¦ä¹ ã€‚

[81] ä¸­çš„å¦ä¸€é¡¹å·¥ä½œä¹Ÿå°†æ³¨æ„æœºåˆ¶ä¸LSTMç»“åˆï¼Œç”¨äºåŠ¨æ€æ—¶é—´ç‰¹å¾çš„æå–ã€‚å…·ä½“è€Œè¨€ï¼Œ[81] ä½¿ç”¨ä¸¤ä¸ªé¢å¤–çš„LSTMè¿›è¡Œæ¯æ—¥å’Œæ¯å‘¨å‘¨æœŸæ€§åˆ†æï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå…·æœ‰æ›´å¤šç”¨äºæœ€ç»ˆé¢„æµ‹çš„æ—¶é—´ç‰¹å¾ã€‚

*Dynamic on Both Spatial and Temporal Features: Yao et al [55] proposed the Spatialâ€“Temporal Dynamic Networks (STDN) to analyze dynamic spatial dependencies by a CNN-based Flow Gating Mechanism (FGM) and dynamic temporal dependencies by integrating the selfattention mechanism into LSTM, for traffic prediction. On the other hand, [82] developed a Convo-Recurrent Attentional Neural Network (CRANN) model for traffic prediction. The idea behind CRANN is the use of classical time-series decomposition in which CRANN consists of several modules to exploit different patterns or characteristics of traffic data and then aggregates them to make predictions. Dynamic spatial and dynamic temporal features are separately extracted by a dedicated attention-based spatial and an attention-based temporal module and then concatenated with exogenous data (i.e. weather condition) via a fully-connected layer for the final prediction.*

åŒæ—¶åŠ¨æ€å¤„ç†æ—¶ç©ºç‰¹å¾ï¼šYaoç­‰äºº [55] æå‡ºäº†æ—¶ç©ºåŠ¨æ€ç½‘ç»œï¼ˆSTDNï¼‰ï¼Œé€šè¿‡åŸºäºCNNçš„æµé‡é—¨æ§æœºåˆ¶ï¼ˆFGMï¼‰åˆ†æåŠ¨æ€çš„ç©ºé—´ä¾èµ–æ€§ï¼ŒåŒæ—¶é€šè¿‡å°†è‡ªæ³¨æ„æœºåˆ¶é›†æˆåˆ°LSTMä¸­æ¥åˆ†æåŠ¨æ€çš„æ—¶é—´ä¾èµ–æ€§ï¼Œç”¨äºäº¤é€šé¢„æµ‹ã€‚å¦ä¸€æ–¹é¢ï¼Œ[82] å¼€å‘äº†ä¸€ä¸ªç”¨äºäº¤é€šé¢„æµ‹çš„å·ç§¯-å¾ªç¯æ³¨æ„ç¥ç»ç½‘ç»œï¼ˆCRANNï¼‰æ¨¡å‹ã€‚CRANNçš„æ€æƒ³æ˜¯ä½¿ç”¨ç»å…¸çš„æ—¶é—´åºåˆ—åˆ†è§£ï¼Œå…¶ä¸­CRANNç”±å‡ ä¸ªæ¨¡å—ç»„æˆï¼Œç”¨äºæŒ–æ˜äº¤é€šæ•°æ®çš„ä¸åŒæ¨¡å¼æˆ–ç‰¹å¾ï¼Œç„¶åå°†å®ƒä»¬èšåˆä»¥è¿›è¡Œé¢„æµ‹ã€‚é€šè¿‡ä¸“ç”¨çš„åŸºäºæ³¨æ„åŠ›çš„ç©ºé—´æ¨¡å—å’ŒåŸºäºæ³¨æ„åŠ›çš„æ—¶é—´æ¨¡å—åˆ†åˆ«æå–åŠ¨æ€çš„ç©ºé—´å’ŒåŠ¨æ€çš„æ—¶é—´ç‰¹å¾ï¼Œç„¶åé€šè¿‡ä¸€ä¸ªå…¨è¿æ¥å±‚ä¸å¤–éƒ¨æ•°æ®ï¼ˆå³å¤©æ°”æ¡ä»¶ï¼‰è¿æ¥ï¼Œç”¨äºæœ€ç»ˆçš„é¢„æµ‹ã€‚



### 3.2 åŸºäºGCNçš„æ¨¡å‹

*The CNN-based models in Section 3.1 consider road networks as regular grids and traffic data with regular Euclidean structure. In fact, road networks are inherently irregular and traffic data should be treated as non-Euclidean data [83]. Therefore, GCN with the advantage of dealing with non-Euclidean structured data has been introduced into the task of traffic prediction. Similar to CNN-based models, GCN-based models can be also classified into two: fixed and dynamic.*

ç¬¬3.1èŠ‚ä¸­çš„åŸºäºCNNçš„æ¨¡å‹å°†é“è·¯ç½‘ç»œè§†ä¸ºè§„åˆ™ç½‘æ ¼ï¼Œå°†äº¤é€šæ•°æ®è§†ä¸ºå…·æœ‰è§„åˆ™æ¬§å‡ é‡Œå¾—ç»“æ„çš„æ•°æ®ã€‚å®é™…ä¸Šï¼Œé“è·¯ç½‘ç»œæœ¬è´¨ä¸Šæ˜¯ä¸è§„åˆ™çš„ï¼Œäº¤é€šæ•°æ®åº”è¯¥è¢«è§†ä¸ºéæ¬§å‡ é‡Œå¾—æ•°æ® [83]ã€‚å› æ­¤ï¼Œå…·æœ‰å¤„ç†éæ¬§å‡ é‡Œå¾—ç»“æ„æ•°æ®ä¼˜åŠ¿çš„GCNå·²è¢«å¼•å…¥åˆ°äº¤é€šé¢„æµ‹çš„ä»»åŠ¡ä¸­ã€‚ä¸åŸºäºCNNçš„æ¨¡å‹ç±»ä¼¼ï¼ŒåŸºäºGCNçš„æ¨¡å‹ä¹Ÿå¯ä»¥åˆ†ä¸ºä¸¤ç±»ï¼šå›ºå®šå’ŒåŠ¨æ€ã€‚



#### 3.2.1 å›ºå®šæ—¶ç©ºç‰¹å¾çš„æ¨¡å‹

*Zhao et al [36] proposed a Temporal Graph Convolutional Network (T-GCN) model, which combines GCN and GRU for traffic speed prediction. GCN is used to learn complex topological structures from the ğ‘˜ âˆ’ â„ğ‘œğ‘ neighborhood matrix for capturing spatial dependencies and GRU is utilized to learn changes of traffic data along the time dimension for capturing temporal dependencies. To enrich traffic information, [35] proposed the Traffic Graph Convolutional Long Short-Term Memory Neural Network (TGC-LSTM) model, based on GCN and LSTM, to learn the interactions of road segments in a large-scale road network from all ğ‘˜ âˆ’ â„ğ‘œğ‘ neighborhood matrices. A L1-norm on graph convolution weights and a L2-norm on graph convolution features are added to the loss function for enhancing the interpretability of the model. Following the proposal of the sequence-to-sequence (Seq2Seq) architecture [84] that is capable of dealing with long-term sequence problems, several hybrid deep learning models started to exploit it for analyzing long-term traffic dependency. For example, [33] developed a deep learning framework based on Diffusion Convolutional Recurrent Neural Network (DCRNN) under the Seq2Seq framework for traffic speed prediction. Both the encoder and the decoder inside the Seq2Seq framework consist of GRUs embedded by the diffusion convolutional process. Two other hybrid models exploiting the Seq2Seq framework are [59,60]. The hybrid model in [59] incorporates offline geographical and social attributes, spatial dependencies and online crowd queries with a deep fusion. The model in [60] considers temporal attributes including public holidays, working days, peak hours and off-peak hours for contributing to final prediction in the decoder of the Seq2Seq framework. Pan et al [64] developed a deep-meta-learning model named ST-MetaNet under the Seq2Seq framework to predict networkwide traffic. Both the encoder and the decoder in ST-MetaNet have the same network structure consisting of four components: (1) basic RNN for learning long temporal dependencies, (2) Meta-knowledge learner for learning the meta-knowledge of nodes and edges from node and edge attributes respectively, (3) Meta-GAT for capturing diverse spatial correlations by individually broadcasting locationsâ€™ hidden states along edges, and (4) Meta-RNN for capturing diverse temporal correlations associated with the geographical information of locations.*

èµµç­‰äºº [36] æå‡ºäº†ä¸€ç§æ—¶é—´å›¾å·ç§¯ç½‘ç»œï¼ˆT-GCNï¼‰æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»“åˆäº†GCNå’ŒGRUè¿›è¡Œäº¤é€šé€Ÿåº¦é¢„æµ‹ã€‚GCNç”¨äºä»ğ‘˜-ğ‘›ğ‘’ğ‘–ğ‘”â„ğ‘ğ‘œğ‘Ÿâ„ğ‘œğ‘œğ‘‘é‚»åŸŸçŸ©é˜µä¸­å­¦ä¹ å¤æ‚çš„æ‹“æ‰‘ç»“æ„ï¼Œä»¥æ•æ‰ç©ºé—´ä¾èµ–æ€§ï¼Œè€ŒGRUç”¨äºæ²¿æ—¶é—´ç»´åº¦å­¦ä¹ äº¤é€šæ•°æ®çš„å˜åŒ–ï¼Œä»¥æ•æ‰æ—¶é—´ä¾èµ–æ€§ã€‚ä¸ºäº†ä¸°å¯Œäº¤é€šä¿¡æ¯ï¼Œ[35] æå‡ºäº†åŸºäºGCNå’ŒLSTMçš„äº¤é€šå›¾å·ç§¯é•¿çŸ­æ—¶è®°å¿†ç¥ç»ç½‘ç»œï¼ˆTGC-LSTMï¼‰æ¨¡å‹ï¼Œç”¨äºä»æ‰€æœ‰ğ‘˜-ğ‘›ğ‘’ğ‘–ğ‘”â„ğ‘ğ‘œğ‘Ÿâ„ğ‘œğ‘œğ‘‘é‚»åŸŸçŸ©é˜µä¸­å­¦ä¹ å¤§è§„æ¨¡é“è·¯ç½‘ç»œä¸­é“è·¯æ®µä¹‹é—´çš„äº¤äº’ä½œç”¨ã€‚å¯¹å›¾å·ç§¯æƒé‡è¿›è¡ŒL1èŒƒæ•°å’Œå¯¹å›¾å·ç§¯ç‰¹å¾è¿›è¡ŒL2èŒƒæ•°ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚

åœ¨å¤„ç†é•¿æœŸåºåˆ—é—®é¢˜çš„Seq2Seqä½“ç³»ç»“æ„ [84] æå‡ºä¹‹åï¼Œä¸€äº›æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹å¼€å§‹åˆ©ç”¨å®ƒæ¥åˆ†æé•¿æœŸäº¤é€šä¾èµ–æ€§ã€‚ä¾‹å¦‚ï¼Œ[33] åŸºäºSeq2Seqæ¡†æ¶å¼€å‘äº†ä¸€ä¸ªåŸºäºæ‰©æ•£å·ç§¯å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆDCRNNï¼‰çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºäº¤é€šé€Ÿåº¦é¢„æµ‹ã€‚Seq2Seqæ¡†æ¶å†…éƒ¨çš„ç¼–ç å™¨å’Œè§£ç å™¨éƒ½åŒ…å«ç”±æ‰©æ•£å·ç§¯è¿‡ç¨‹åµŒå¥—çš„GRUã€‚åˆ©ç”¨Seq2Seqæ¡†æ¶çš„å¦å¤–ä¸¤ä¸ªæ··åˆæ¨¡å‹æ˜¯ [59,60]ã€‚[59] ä¸­çš„æ··åˆæ¨¡å‹é€šè¿‡æ·±åº¦èåˆå°†ç¦»çº¿åœ°ç†å’Œç¤¾ä¼šå±æ€§ã€ç©ºé—´ä¾èµ–æ€§å’Œåœ¨çº¿ç¾¤ä½“æŸ¥è¯¢çº³å…¥å…¶ä¸­ã€‚[60] ä¸­çš„æ¨¡å‹åœ¨Seq2Seqæ¡†æ¶çš„è§£ç å™¨ä¸­è€ƒè™‘äº†åŒ…æ‹¬å…¬å…±å‡æœŸã€å·¥ä½œæ—¥ã€é«˜å³°æ—¶æ®µå’Œéé«˜å³°æ—¶æ®µåœ¨å†…çš„æ—¶é—´å±æ€§ï¼Œç”¨äºæœ€ç»ˆé¢„æµ‹ã€‚æ½˜ç­‰äºº [64] åœ¨Seq2Seqæ¡†æ¶ä¸‹å¼€å‘äº†ä¸€ç§åä¸ºST-MetaNetçš„æ·±åº¦å…ƒå­¦ä¹ æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹æ•´ä¸ªç½‘ç»œçš„äº¤é€šæƒ…å†µã€‚ST-MetaNetä¸­çš„ç¼–ç å™¨å’Œè§£ç å™¨å…·æœ‰ç›¸åŒçš„ç½‘ç»œç»“æ„ï¼ŒåŒ…æ‹¬å››ä¸ªç»„ä»¶ï¼šï¼ˆ1ï¼‰åŸºæœ¬çš„RNNç”¨äºå­¦ä¹ é•¿æ—¶é—´ä¾èµ–å…³ç³»ï¼Œï¼ˆ2ï¼‰å…ƒçŸ¥è¯†å­¦ä¹ å™¨ç”¨äºåˆ†åˆ«ä»èŠ‚ç‚¹å’Œè¾¹ç¼˜å±æ€§ä¸­å­¦ä¹ èŠ‚ç‚¹å’Œè¾¹ç¼˜çš„å…ƒçŸ¥è¯†ï¼Œï¼ˆ3ï¼‰å…ƒ-GATç”¨äºé€šè¿‡å•ç‹¬å¹¿æ’­ä½ç½®çš„éšè—çŠ¶æ€æ¥æ•æ‰å¤šæ ·çš„ç©ºé—´ç›¸å…³æ€§ï¼Œï¼ˆ4ï¼‰å…ƒ-RNNç”¨äºæ•æ‰ä¸ä½ç½®çš„åœ°ç†ä¿¡æ¯ç›¸å…³çš„å¤šæ ·çš„æ—¶é—´ç›¸å…³æ€§ã€‚



#### 3.2.2 åŠ¨æ€æ—¶ç©ºç‰¹å¾çš„æ¨¡å‹

*Fixed GCN-based models address the traffic prediction problem as a fixed spatialâ€“temporal process. Similarly to dynamic CNN-based models, we also find dynamic GCN-based models in the literature that treat the traffic prediction problem as a dynamic spatialâ€“temporal process via introduction of the attention mechanism, due to considering the fact that different neighboring sensors or road segments and different previous time steps individually affect differently the targeted road segment and the future time intervals, respectively.*

å›ºå®šçš„GCNæ¨¡å‹å°†äº¤é€šé¢„æµ‹é—®é¢˜è§†ä¸ºä¸€ä¸ªå›ºå®šçš„æ—¶ç©ºè¿‡ç¨‹ã€‚ç±»ä¼¼äºåŠ¨æ€CNNæ¨¡å‹ï¼Œæ–‡çŒ®ä¸­è¿˜å­˜åœ¨å°†äº¤é€šé¢„æµ‹é—®é¢˜è§†ä¸ºåŠ¨æ€æ—¶ç©ºè¿‡ç¨‹çš„åŠ¨æ€GCNæ¨¡å‹ï¼Œé€šè¿‡å¼•å…¥æ³¨æ„æœºåˆ¶æ¥è€ƒè™‘ä¸åŒçš„é‚»è¿‘ä¼ æ„Ÿå™¨æˆ–é“è·¯æ®µä»¥åŠä¸åŒçš„å…ˆå‰æ—¶é—´æ­¥å¯¹ç›®æ ‡é“è·¯æ®µå’Œæœªæ¥æ—¶é—´é—´éš”çš„å½±å“ã€‚

*Dynamic on Spatial Features: The SAGCN-SST model [69] that is designed for multi-interval network-wide traffic speed prediction falls within this category. It combines the attention mechanism into GCN layers for analyzing dynamic spatial dependencies in different neighborhoods and uses GRU under an encoderâ€“decoder architecture for analyzing temporal features. The Dynamic Graph Convolutional Recurrent Network (DGCRN) model [85] is another model in this category. In DGCRN, the node embedding technology [70] is used to embed the node attributes and then sent to a hyper-network to generate dynamic graph at each time interval. GCN and GRU under an encoderâ€“decoder architecture are then utilized to respectively capture spatial and temporal features based on generated dynamic graphs and their historical traffic data. Meanwhile, [86] built a graph neural network architecture, named Graph WaveNet, to exploit dynamic and hidden spatial features by using a novel adaptive dependency matrix.It captures long-term temporal features by temporal convolution layers consisting of the dilated causal convolution [87].*

GCNæ¨¡å‹ä¸­çš„åŠ¨æ€ç©ºé—´ç‰¹å¾ï¼šSAGCN-SSTæ¨¡å‹ [69] æ˜¯ä¸“ä¸ºå¤šæ—¶é—´é—´éš”ç½‘ç»œèŒƒå›´å†…äº¤é€šé€Ÿåº¦é¢„æµ‹è€Œè®¾è®¡çš„ã€‚è¯¥æ¨¡å‹å°†æ³¨æ„æœºåˆ¶ä¸GCNå±‚ç»“åˆèµ·æ¥ï¼Œä»¥åˆ†æä¸åŒé‚»åŸŸçš„åŠ¨æ€ç©ºé—´ä¾èµ–æ€§ï¼Œå¹¶åœ¨ç¼–ç å™¨-è§£ç å™¨æ¶æ„ä¸‹ä½¿ç”¨GRUåˆ†ææ—¶æ€ç‰¹å¾ã€‚åŠ¨æ€å›¾å·ç§¯å¾ªç¯ç½‘ç»œ (DGCRN) æ¨¡å‹ [85] æ˜¯æ­¤ç±»åˆ«ä¸­çš„å¦ä¸€ä¸ªæ¨¡å‹ã€‚åœ¨DGCRNä¸­ï¼ŒèŠ‚ç‚¹åµŒå…¥æŠ€æœ¯ [70] ç”¨äºåµŒå…¥èŠ‚ç‚¹å±æ€§ï¼Œç„¶åå‘é€åˆ°ä¸€ä¸ªè¶…ç½‘ç»œä»¥åœ¨æ¯ä¸ªæ—¶é—´é—´éš”ç”ŸæˆåŠ¨æ€å›¾ã€‚æ¥ç€ï¼Œåœ¨ç¼–ç å™¨-è§£ç å™¨æ¶æ„ä¸‹ä½¿ç”¨GCNå’ŒGRUæ¥åˆ†åˆ«æ•æ‰åŸºäºç”Ÿæˆçš„åŠ¨æ€å›¾å’Œå®ƒä»¬çš„å†å²äº¤é€šæ•°æ®çš„æ—¶ç©ºç‰¹å¾ã€‚åŒæ—¶ï¼Œ[86] æ„å»ºäº†ä¸€ä¸ªåä¸ºGraph WaveNetçš„å›¾ç¥ç»ç½‘ç»œæ¶æ„ï¼Œé€šè¿‡ä½¿ç”¨ä¸€ç§æ–°é¢–çš„è‡ªé€‚åº”ä¾èµ–çŸ©é˜µæ¥å¼€å‘åŠ¨æ€å’Œéšè—çš„ç©ºé—´ç‰¹å¾ã€‚å®ƒé€šè¿‡ç”±æ‰©å¼ å› æœå·ç§¯ [87] ç»„æˆçš„æ—¶æ€å·ç§¯å±‚æ•æ‰é•¿æœŸæ—¶æ€ç‰¹å¾ã€‚

*Dynamic on Temporal Features: Li et al [63] proposed a graph and attention-based long short-term memory network (named GLA), to capture the spatialâ€“temporal features of traffic flow data. GLA uses GCN to mine the spatial relationships of traffic data, and then the output of GCN is fed to LSTM with the soft attention mechanism for the dynamic temporal feature extraction. Another model, the AGCSeq2Seq-Att [34], also joins the attention mechanism into LSTM for dynamic temporal feature analysis and uses GCN for spatial feature analysis on the adjacent matrix. He et al [88] built a Graph Attention Spatialâ€“Temporal Network (GASTN) model for citywide mobile traffic prediction. Compared to [34,63,88] adopts Dynamic Time Warping (DTW) algorithm [89] to calculate the similarities of traffic data between two nodes, and then clusters nodes into different groups and builds weighted graph based on computed similarities of these groups, before using GCN and attention-based RNN to extract spatial and dynamic temporal features*

GCNæ¨¡å‹ä¸­çš„åŠ¨æ€æ—¶æ€ç‰¹å¾ï¼šLiç­‰äºº [63] æå‡ºäº†ä¸€ç§åŸºäºå›¾å’Œæ³¨æ„åŠ›æœºåˆ¶çš„é•¿çŸ­æ—¶è®°å¿†ç½‘ç»œï¼ˆå‘½åä¸ºGLAï¼‰ï¼Œç”¨äºæ•æ‰äº¤é€šæµæ•°æ®çš„æ—¶ç©ºç‰¹å¾ã€‚GLAåˆ©ç”¨GCNæŒ–æ˜äº¤é€šæ•°æ®çš„ç©ºé—´å…³ç³»ï¼Œç„¶åå°†GCNçš„è¾“å‡ºé¦ˆé€åˆ°å¸¦æœ‰è½¯æ³¨æ„åŠ›æœºåˆ¶çš„LSTMä¸­è¿›è¡ŒåŠ¨æ€æ—¶æ€ç‰¹å¾æå–ã€‚å¦ä¸€ä¸ªæ¨¡å‹ï¼ŒAGCSeq2Seq-Att [34]ï¼Œä¹Ÿå°†æ³¨æ„åŠ›æœºåˆ¶å¼•å…¥LSTMä¸­è¿›è¡ŒåŠ¨æ€æ—¶æ€ç‰¹å¾åˆ†æï¼Œå¹¶åœ¨ç›¸é‚»çŸ©é˜µä¸Šä½¿ç”¨GCNè¿›è¡Œç©ºé—´ç‰¹å¾åˆ†æã€‚Heç­‰äºº [88] æ„å»ºäº†ä¸€ä¸ªåŸå¸‚èŒƒå›´ç§»åŠ¨äº¤é€šé¢„æµ‹çš„å›¾æ³¨æ„åŠ›æ—¶ç©ºç½‘ç»œï¼ˆGASTNï¼‰æ¨¡å‹ã€‚ä¸ [34,63,88] ç›¸æ¯”ï¼ŒGASTNé‡‡ç”¨äº†åŠ¨æ€æ—¶é—´è§„æ•´ï¼ˆDTWï¼‰ç®—æ³• [89] æ¥è®¡ç®—ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´äº¤é€šæ•°æ®çš„ç›¸ä¼¼æ€§ï¼Œç„¶åå°†èŠ‚ç‚¹èšç±»åˆ°ä¸åŒçš„ç»„ä¸­ï¼Œå¹¶åŸºäºè¿™äº›ç»„çš„è®¡ç®—ç›¸ä¼¼æ€§æ„å»ºåŠ æƒå›¾ï¼Œæœ€åä½¿ç”¨GCNå’ŒåŸºäºæ³¨æ„åŠ›çš„RNNæå–ç©ºé—´å’ŒåŠ¨æ€æ—¶æ€ç‰¹å¾ã€‚

*Dynamic on Both Spatial and Temporal Features: Shi et al [90] designed an Attention-based Periodic-Temporal Neural Network (APTN) to learn dynamic spatial and dynamic temporal features for traffic flow prediction. APTN is built based on an encoderâ€“decoder architecture, in which an LSTM-based encoder with the attention mechanism is used to capture dynamic spatial correlations of each node with the entire graph by learning individual weights and the other LSTM-based decoder with the attention mechanism is utilized to decode the encoded information. It also adaptively select the relevant encoder hidden states with individual weights to produce the output. The Spatial and Temporal Attention based Neural Network (STANN) [62] using an encoderâ€“decoder architecture based on CNN on traffic graphs and GRU is another work in this category. The difference of this work compared to [90] is that the spatial attention matrices used to represent the relationships of road segments in a traffic network are generated before using the STANN model with attention mechanism to extract both dynamic spatial and dynamic temporal features. Yin et al [68] proposed a Multi-stage Attention Spatialâ€“Temporal Graph Network (MASTGN) that captures dynamic temporal features via the interactions among multiple time series by an internal attention mechanism and extracts dynamic spatial features by a dynamic neighborhood-based attention mechanism.*

åŠ¨æ€æ—¶ç©ºç‰¹å¾æ–¹é¢ï¼šShiç­‰äºº [90] è®¾è®¡äº†ä¸€ç§åŸºäºæ³¨æ„åŠ›çš„å‘¨æœŸæ—¶æ€ç¥ç»ç½‘ç»œï¼ˆAPTNï¼‰ï¼Œç”¨äºå­¦ä¹ äº¤é€šæµé¢„æµ‹çš„åŠ¨æ€æ—¶ç©ºç‰¹å¾ã€‚APTNå»ºç«‹åœ¨ä¸€ä¸ªç¼–ç å™¨-è§£ç å™¨æ¶æ„ä¹‹ä¸Šï¼Œå…¶ä¸­ä½¿ç”¨åŸºäºLSTMçš„ç¼–ç å™¨å’Œæ³¨æ„åŠ›æœºåˆ¶æ¥æ•æ‰æ¯ä¸ªèŠ‚ç‚¹ä¸æ•´ä¸ªå›¾çš„åŠ¨æ€ç©ºé—´ç›¸å…³æ€§ï¼Œé€šè¿‡å­¦ä¹ ä¸ªä½“æƒé‡ï¼Œå¹¶ä½¿ç”¨åŸºäºLSTMçš„è§£ç å™¨å’Œæ³¨æ„åŠ›æœºåˆ¶æ¥è§£ç ç¼–ç ä¿¡æ¯ã€‚å®ƒè¿˜è‡ªé€‚åº”åœ°é€‰æ‹©ç›¸å…³çš„ç¼–ç å™¨éšè—çŠ¶æ€ï¼Œä»¥äº§ç”Ÿè¾“å‡ºã€‚åŸºäºç©ºé—´å’Œæ—¶é—´æ³¨æ„åŠ›çš„ç¥ç»ç½‘ç»œï¼ˆSTANNï¼‰[62] ä½¿ç”¨åŸºäºCNNçš„ç¼–ç å™¨-è§£ç å™¨æ¶æ„åœ¨äº¤é€šå›¾ä¸Šå’ŒGRUä¸Šè¿›è¡Œï¼Œæ˜¯è¿™ä¸€ç±»å·¥ä½œä¸­çš„å¦ä¸€é¡¹ç ”ç©¶ã€‚ä¸ [90] ç›¸æ¯”ï¼Œè¿™é¡¹å·¥ä½œçš„ä¸åŒä¹‹å¤„åœ¨äºåœ¨ä½¿ç”¨STANNæ¨¡å‹å’Œæ³¨æ„æœºåˆ¶ä»äº¤é€šç½‘ç»œä¸­æå–åŠ¨æ€æ—¶ç©ºç‰¹å¾ä¹‹å‰ï¼Œç”¨äºè¡¨ç¤ºäº¤é€šç½‘ç»œä¸­é“è·¯æ®µå…³ç³»çš„ç©ºé—´æ³¨æ„çŸ©é˜µæ˜¯åœ¨ä¹‹å‰ç”Ÿæˆçš„ã€‚Yinç­‰äºº [68] æå‡ºäº†ä¸€ä¸ªå¤šé˜¶æ®µæ³¨æ„åŠ›æ—¶ç©ºå›¾ç½‘ç»œï¼ˆMASTGNï¼‰ï¼Œé€šè¿‡å†…éƒ¨æ³¨æ„åŠ›æœºåˆ¶åœ¨å¤šä¸ªæ—¶é—´åºåˆ—ä¹‹é—´æ•æ‰åŠ¨æ€æ—¶æ€ç‰¹å¾ï¼Œå¹¶é€šè¿‡åŠ¨æ€é‚»åŸŸæ³¨æ„åŠ›æœºåˆ¶æå–åŠ¨æ€ç©ºé—´ç‰¹å¾ã€‚



### 3.3 åŸºäº transformer çš„æ¨¡å‹

*Inspired by the newly proposed transformer in [79] for efficiently modeling long-range dependencies in natural language processing, researchers have introduced the transformer architecture to replace CNN (or GCN) for spatial correlation analysis and LSTM (or GRU) for temporal dependency analysis. Self-attention-based transformer can directly learn dynamic spatial and temporal dependencies by distributing different weights on neighbors in space dimension and on previous time intervals in time dimension for contributing to the targeted road segment. Besides, transformer can exploit more hidden information in traffic data by defining multi-heads and accelerate training phase by paralleling process.*

å—åˆ° [79] ä¸­æ–°æå‡ºçš„ transformer ç”¨äºé«˜æ•ˆå»ºæ¨¡è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„é•¿è·ç¦»ä¾èµ–å…³ç³»çš„å¯å‘ï¼Œç ”ç©¶äººå‘˜å¼•å…¥äº† transformer æ¶æ„æ¥æ›¿ä»£ CNNï¼ˆæˆ– GCNï¼‰è¿›è¡Œç©ºé—´ç›¸å…³æ€§åˆ†æå’Œ LSTMï¼ˆæˆ– GRUï¼‰è¿›è¡Œæ—¶ç©ºä¾èµ–åˆ†æã€‚åŸºäºè‡ªæ³¨æ„åŠ›çš„ transformer å¯ä»¥é€šè¿‡åœ¨ç©ºé—´ç»´åº¦ä¸Šåˆ†é…ä¸åŒçš„æƒé‡å’Œåœ¨æ—¶é—´ç»´åº¦ä¸Šåˆ†é…ä¸åŒçš„æƒé‡æ¥ç›´æ¥å­¦ä¹ åŠ¨æ€çš„æ—¶ç©ºä¾èµ–å…³ç³»ï¼Œä»è€Œæœ‰åŠ©äºé’ˆå¯¹æ€§åœ°æ”¹å–„é“è·¯æ®µã€‚æ­¤å¤–ï¼Œtransformer å¯ä»¥é€šè¿‡å®šä¹‰å¤šä¸ªå¤´éƒ¨æ¥æŒ–æ˜äº¤é€šæ•°æ®ä¸­çš„æ›´å¤šéšè—ä¿¡æ¯ï¼Œå¹¶é€šè¿‡å¹¶è¡Œå¤„ç†åŠ é€Ÿè®­ç»ƒé˜¶æ®µã€‚

#### 3.3.1 åŠ¨æ€æ—¶ç©ºç‰¹å¾çš„æ¨¡å‹

*Dynamic on Both Spatial and Temporal Features: Xu et al [71] developed a Spatialâ€“Temporal Transformer Networks (STTNs) to improve the accuracy of long-term traffic prediction, which consists of spatial transformer for modeling dynamic spatial dependencies with self-attention mechanism and temporal transformer for modeling dynamic long-range temporal dependencies across previous time intervals. Another transformer-based model (named GMAN) was developed under an encoderâ€“decoder architecture in [70]. Both encoder and decoder consist of multiple spatialâ€“temporal attention blocks to model the impact of the spatialâ€“temporal factors on traffic state. In addition, it also includes a spatialâ€“temporal embedding to encode vertices into vectors using the node2vec approach [91] for the vertex representation learning.*

åŠ¨æ€æ—¶ç©ºç‰¹å¾ï¼šå¾ç­‰äºº [71] å¼€å‘äº†ä¸€ç§åä¸ºç©ºé—´-æ—¶é—´ Transformer ç½‘ç»œï¼ˆSTTNsï¼‰çš„æ¨¡å‹ï¼Œä»¥æé«˜é•¿æœŸäº¤é€šé¢„æµ‹çš„å‡†ç¡®æ€§ã€‚è¯¥æ¨¡å‹åŒ…æ‹¬ç”¨äºå»ºæ¨¡åŠ¨æ€æ—¶ç©ºä¾èµ–å…³ç³»çš„å¸¦æœ‰è‡ªæ³¨æ„æœºåˆ¶çš„ç©ºé—´å˜æ¢å™¨å’Œç”¨äºå»ºæ¨¡è·¨å…ˆå‰æ—¶é—´é—´éš”çš„åŠ¨æ€é•¿æ—¶åºä¾èµ–å…³ç³»çš„æ—¶ç©ºå˜æ¢å™¨ã€‚å¦ä¸€ä¸ªåŸºäº Transformer çš„æ¨¡å‹ï¼ˆåä¸º GMANï¼‰åœ¨ [70] ä¸­ä»¥ç¼–ç å™¨-è§£ç å™¨æ¶æ„å¼€å‘ã€‚ç¼–ç å™¨å’Œè§£ç å™¨éƒ½åŒ…æ‹¬å¤šä¸ªç©ºé—´-æ—¶é—´æ³¨æ„å—ï¼Œä»¥å»ºæ¨¡æ—¶ç©ºå› ç´ å¯¹äº¤é€šçŠ¶æ€çš„å½±å“ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜åŒ…æ‹¬ä¸€ä¸ªç©ºé—´-æ—¶é—´åµŒå…¥ï¼Œä½¿ç”¨ node2vec æ–¹æ³• [91] å¯¹é¡¶ç‚¹è¿›è¡Œç¼–ç ï¼Œä»¥å­¦ä¹ é¡¶ç‚¹è¡¨ç¤ºã€‚