# java

[TOC]

## 一、java基础

### 红黑树、B树和B+树

AVL树：平衡二叉树

BST树：二叉查找树

#### 红黑树

##### 来源

其实红黑树是 2-3-4树（也可以叫做 2-4 树）的等价实现，因为2-3-4树有完美的自平衡性，它的所有操作在最坏的情况下复杂度也是 O(log n) 所以2-3-4树的查找、插入和删除的效率都很高。

但是由于2-3-4树按照它最初的定义来实现的话，不仅需要大量的代码，而且它们所产生的额外开销可能会使算法比标准的二叉查找树更慢。所以产生了红黑树，红黑树的红黑，其实值得是连接当前节点的链接的属性，因为每个节点都只有一个指向它的链接所以用节点的属性代替链接的属性。红色链接 指的就是 红色链接两端的节点，其实可以转化为2-3-4中的一个3节点或者4节点。2-3-4树的到达每一个空链接的路径长相等性质，也就转化为红黑树的到叶子节点的黑色节点数量一致的性质。

> 其实最早的完美平衡查找树为 2-3 树，它对应的二叉树实现为左偏红黑树。

##### 性质

1. **根节点是黑色的**： 第一个性质要求根节点始终是黑色的，这确保了树的整体结构保持平衡。
2. **红色子节点性质**： 不能有两个相连的红色节点。这意味着从任意节点到其子节点的路径上不能出现连续的红色节点，以避免出现不平衡情况。
3. **黑高度平衡性质**： 从任意节点出发，到达其每个叶子节点的路径上的黑色节点数量必须相同。这确保了树的高度始终保持在一个合理的范围内，从而保证了高效的查找操作。
4. **红黑性质的维护**： 在执行插入和删除操作后，红黑树需要通过旋转和颜色调整来保持这些性质，从而恢复平衡。这些操作保证了在更新操作之后，树仍然是一颗满足红黑性质的树。
5. **空节点的处理**： 空节点（NIL节点）被认为是黑色的。这样可以确保每个路径上的黑色节点数量相等，即使是经过了空节点的路径。

##### 对比AVL树

+ 平衡性：
  + 红黑树：红黑树保证了一种弱平衡，即树的高度最多是2倍的对数级别。这使得红黑树在插入和删除操作时具有更高的灵活性，但可能导致一些操作稍微不如AVL树高效。
  + AVL树：AVL树是一种严格的平衡树，保证任何节点的左子树和右子树的高度差（平衡因子）不超过1。这确保了AVL树在平衡方面表现更好，但在插入和删除操作时可能需要更多的旋转来维持平衡。
+ 插入和删除操作的性能：
  + 红黑树：由于红黑树的平衡性要求相对较弱，插入和删除操作通常需要更少的旋转操作，因此在这些操作上性能可能比AVL树更好。
  + AVL树：AVL树的严格平衡性可能导致插入和删除操作需要更频繁的旋转操作，因此在这些操作上可能比红黑树略逊一筹。


##### 插入

当在红黑树中执行插入操作时，需要考虑两个主要方面：保持二叉搜索树性质和保持红黑性质。以下是插入操作的详细步骤，包括可能的旋转操作和颜色调整。

插入操作的基本步骤：

1. 将新节点插入到BST中： 首先，将新节点插入到红黑树中，就像在普通的二叉搜索树中一样。新节点会被标记为红色，因为它可能会破坏红黑性质的第一个性质（根节点必须是黑色）。

2. 检查红黑性质： 插入新节点后，可能会破坏红黑性质。需要通过一系列的操作来调整以确保所有的红黑性质得到满足。

颜色调整： 在进行旋转操作之前，需要进行颜色调整以满足红黑性质。以下是颜色调整的可能情况：

1. 父节点为黑色： 如果插入的节点的父节点是黑色的，那么树的结构没有破坏，不需要进一步的调整。

2. 父节点为红色： 如果插入的节点的父节点是红色的，那么可能会破坏红黑性质的第二个性质（不能有两个相连的红色节点）。在这种情况下，需要考虑插入节点的叔叔节点（父节点的兄弟节点）的颜色。

a. 叔叔节点是红色： 如果叔叔节点是红色的，可以通过改变父节点和叔叔节点的颜色，然后将问题向上移动到父节点。这样可以保持黑高度平衡性质。

b. 叔叔节点是黑色或缺失： 如果叔叔节点是黑色的（包括叔叔节点为NIL节点），需要通过旋转来修复这种情况。

**情况一：如果关注节点是 a，它的叔叔节点 d 是红色**

![img](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202404221734309.png)


具体操作为：将关注节点 a 的父节点 b、叔叔节点 d 的颜色都设置成黑色；将关注节点 a 的祖父节点 c 的颜色设置成红色；关注节点变成 a 的祖父节点 c；跳到情况二或者情况三。

**情况二：如果关注节点是 a，它的叔叔节点 d 是黑色，关注节点 a 是其父节点 b 的右子节点**

![img](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202404221734603.png)

具体操作为：关注节点变成节点 a 的父节点 b；围绕新的关注节点b 左旋；跳到情况三。

**情况三：如果关注节点是 a，它的叔叔节点 d 是黑色，关注节点 a 是其父节点 b 的左子节点**

![img](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202404221735941.png)

具体操作为：围绕关注节点 a 的祖父节点 c 右旋；将关注节点 a 的父节点 b、兄弟节点 c 的颜色互换，调整结束。

##### 删除

删除操作比较复杂，其实贱但来说就是通过，旋转和调整颜色，分情况处理使删除后的红黑树依然符合红黑树的性质。



#### B树

##### 简介

首先 B树 和 B-树 是同一种数据结构。在计算机科学中，B树是一种自平衡的树，能够保持数据有序。这种数据结构能够让查找数据、顺序访问、插入数据及删除的动作，都在对数量级的时间复杂度内完成。B树，其实是一颗特殊的二叉查找树（binary search tree），可以拥有多于2个子节点。与自平衡二叉查找树不同，B树为系统大块数据的读写操作做了优化。B树减少定位记录时所经历的中间过程，从而加快存取速度，其实B树主要解决的就是数据IO的问题。B树这种数据结构可以用来描述外部存储。这种数据结构常被应用在数据库和文件系统的实现上。

##### 性质

首先介绍一下一棵 m 阶的 B 树的特性。m表示这个树的每一个节点最多可以拥有的子节点个数。一棵 m 阶的 B 树满足的性质如下：

1. 每个节点最多有 m 个子节点。
2. 每一个非叶子节点（除根节点）最少有 $ \left \lceil m/2 \right \rceil $ 个子节点。
3. 如果根节点不是叶子节点，那么它至少有两个子节点。
4. 有 k 个子节点的非叶子节点拥有 k-1 个键，且升序排列，满足 k[i] < k[i+1]。
6. 所有的叶子节点都在同一层。

##### 优势

之前已经介绍过二叉查找树。但是这类型数据结构的问题在于，由于每个节点只能容纳一个数据，导致树的高度很高，逻辑上挨着的节点数据可能离得很远。

考虑在磁盘中存储数据的情况，与内存相比，读写磁盘有以下不同点：

1. 读写磁盘的速度相比内存读写慢很多。
2. 每次读写磁盘的单位要比读写内存的最小单位大很多。

由于读写磁盘的这个特点，因此对应的数据结构应该尽量的满足「局部性原理」：「当一个数据被用到时，其附近的数据也通常会马上被使用」，为了满足局部性原理， 所以应该将逻辑上相邻的数据在物理上也尽量存储在一起。这样才能减少读写磁盘的数量。

所以，对比起一个节点只能存储一个数据的 BST 类数据结构来，要求这种数据结构在形状上更「胖」、更加「扁平」，即：每个节点能容纳更多的数据， 这样就能降低树的高度，同时让逻辑上相邻的数据都能尽量存储在物理上也相邻的硬盘空间上，减少磁盘读写。



#### B+树

##### 介绍

B+ 树是 [B 树](https://oi-wiki.org/ds/b-tree/) 的一个升级，它比 B 树更适合实际应用中操作系统的文件索引和数据库索引。目前现代关系型数据库最广泛的支持索引结构就是 B+ 树。

##### 性质

B+树是B树的变种，但不同资料中B+树的定义各有不同，其差异在于节点中关键字个数和孩子节点个数。一种是节点中关键字个数和孩子个数相同，另一种是关键字个数比孩子节点个数小1，这种方式是和B树基本相同。

1. B+树包含2种类型的节点：内部节点（也称索引节点）和叶子节点。根节点本身即可以是内部节点，也可以是叶子节点。根节点的关键字key个数最少可以只有1个；
2. B+树与B树最大的不同是内部节点不保存数据，只用于索引，所有数据（或者说记录）都保存在叶子节点中；
3. m阶B+树表示了内部节点最多有m-1个关键字（或者说内部节点最多有m个子树，和B树相同），阶数m同时限制了叶子节点最多存储m-1个记录；
4. 内部节点中的key都按照从小到大的顺序排列，对于内部节点中的一个key，左树中的所有key都小于它，右子树中的key都大于等于它。叶子节点中的记录也按照key的大小排列；
5. 每个叶子节点都存有相邻叶子节点的指针，叶子节点本身依关键字的大小自小而大顺序链接；

##### 优势

由于索引节点上只有索引而没有数据，所以索引节点上能存储比 B 树更多的索引，这样树的高度就会更矮。树的高度越矮，磁盘寻道的次数就会越少。

因为数据都集中在叶子节点，而所有叶子节点的高度相同，那么可以在叶子节点中增加前后指针，指向同一个父节点的相邻兄弟节点，这样可以更好地支持查询一个值的前驱或后继，使连续访问更容易实现。

比如这样的 SQL 语句：`select * from tbl where t > 10`，如果使用 B+ 树存储数据的话，可以首先定位到数据为 10 的节点，再沿着它的 `next` 指针一路找到所有在该叶子节点右边的叶子节点，返回这些节点包含的数据。

而如果使用 B 树结构，由于数据既可以存储在内部节点也可以存储在叶子节点，连续访问的实现会更加繁琐（需要在树的内部结构中进行移动）。

> 由上边的 二叉查找树 引出数据库引擎。
>
> 像这种二叉树结构比较常见的使用场景是 Mysql 两种引擎，Myisam 使用的是 B 树，InnoDB 使用的是 B+树







## 二、java集合

### 2.1 List

#### 2.1.1 ArrayList 的扩容机制

首先 ArrayList 可以初始化为指定大小容量，或者默认初始化容量10，不过如果是无参初始化的话是懒加载策略，只有第一次添加元素才真正的初始化为容量大小为10的数组。扩容就是当当前容量+1超过数组长度时，会创建一个1.5倍容量的新数组，然后把原数组的值拷贝上去。

#### 2.1.3 ArrayList 和 LinkedList 的区别

它们两个主要是底层使用的数据结构不一样，ArrayList 是动态数组，LinkedList 是双向链表。数据结构的不同是一切不同的根源。

1. 是否支持随机访问

+ ArrayList基于数组，所以它可以根据下标查找，支持随机访问，当然，它也实现了RandmoAccess 接口，这个接口只是用来标识是否支持随机访问。 
+ LinkedList基于链表，所以它没法根据序号直接获取元素，它没有实现 RandmoAccess 接口，标记不支持随机访问。

2. 内存占用，ArrayList基于数组，是一块连续的内存空间，LinkedList基于链表，内存空间不连续，它们在空间占用上都有一些额外的消耗：

+ ArrayList是预先定义好的数组，可能会有空的内存空间，存在一定空间浪费 
+ LinkedList每个节点，需要存储前驱和后继，所以每个节点会占用更多的空

3. 从线程安全来说，ArrayList和LinkedList都不是线程安全的

#### 2.1.4 ArrayList 和 LinkedList 不是线程安全的，你们在项目中是如何解决这个的线程安全问题的？

其实在我们的项目中我们使用 Arraylist 的时候都是在方法内使用的，都是局部变量不会出现线程安全问题。如果要在成员变量中使用的话，有几种方案：

+ 使用 Collections.synchronizedList 包装 ArrayList，然后操作包装后的 list。
+ 使用 CopyOnWriteArrayList 代替 ArrayList。
+ 在使用 ArrayList 时，应用程序通过同步机制去控制 ArrayList 的读写。



### 2.2  Map

#### 2.2.1 HashMap 内部的存储结构：

hashmap底层的数据结构是 **数组 + 链表 + 红黑树**。

数据元素通过hash函数计算出对应的在数组中的存储位置，如果发生冲突的话，就是用拉链法来解决冲突，当链表的长度大于8，并且数组的长度大于64的时候，链表会转化为红黑树，如果链表长度大于8，但是数组长度小于64，则会触发扩容。在移除数据的时候红黑树长度小于6会退化为链表。

#### 2.2.2 为什么使用红黑树，不用二叉查找树，或者平衡二叉树

+ 普通的二叉查找树，形状收到插入顺序的影响，可能导致最后的形状是链表，使得查找效率很低。

+ 平衡二叉树是比红黑树更严格的平衡树，为了保持保持平衡，需要旋转的次数更 多，也就是说平衡二叉树保持平衡的效率更低，所以平衡二叉树插入和删除的效率 比红黑树要低。

所以在查找效率和保持平衡的代价之间权衡最终选择红黑树。

#### 2.2.3 HashMap 的put流程

1. 判断键值对数组table是否为空或为null，否则执行resize()进行扩容（初始化）

2. 根据键值key通过扰动算法计算hash值得到数组索引`(key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);`（key.hashcode()的高16位与低16位取异或）

3. 判断table[i]==null，条件成立，直接新建节点添加

4. 如果table[i]==null ,不成立

  	4.1 判断table[i]的首个元素是否和key一样，如果相同直接覆盖value
  	
  	4.2 判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对
  	
  	4.3 如果不是树节点，表明当前桶为链表，遍历table[i]，链表的尾部（尾插法）插入数据，然后判断链表长度是否大于8，并且数组的长度是否大于64，大于的话把链表转换为红黑树，数组长度小于64的话则扩容。

5. 插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold（数组长度*0.75），如果超过，进行扩容。

#### 2.2.4 HashMap 的扰动函数是怎么设计的

HashMap的哈希函数是先拿到 key 的hashcode，是一个32位的int类型的数值，然后让 hashcode的高16位和低16位进行异或操作。

优点：使最终结果即和低位相关，又和高位相关。并且异或不同于与，或操作。结果1,0是均匀分布，可以减少hash冲突。

#### 2.2.5 HashMap 的容量为什么一定是2的倍数

1. 通过hashcode得到当前元素的数组下标的时候，可以通过对 length - 1 做与操作 来代替模运算，可以提高计算效率。
2. 数组扩容的时候，每次扩大一倍容量（换成二进制就是高位多了1），扩容后的元素的重新定位，直接判断最高位是1还是0来判断是否需要移动位置，移动位置的话就是 现在的下标 + 原数组长度。

#### 2.2.6 若是初始化的时候，大小指定的不是2的幂次方怎么处理？

变成比原值大的最近一个2的幂次方。

#### 2.2.7 为什么HashMap链表转红黑树的阈值为8呢？

其实转换为红黑树所占空间更大，空间换时间，是一种兜底策略。和统计学有关，理想情况下，使用随机哈希码，链表里的节点 符合泊松分布，出现节点个数的概率是递减的，节点个数为8的情况，发生概率仅为 0.00000006 。

至于红黑树转回链表的阈值为什么是6，而不是8？是因为如果这个阈值也设置成8， 假如hashmap的删除和插入操作频繁，节点增减刚好在8附近，会发生链表和红黑树的不断转换，导致资源浪费。

#### 2.2.8 扩容在什么时候呢？为什么扩容因子是0.75？

**扩容有三个地方**

1. 第一次对hashmap进行操作的时候，hashmap为空，需要进行一次resize(),默认大小16.

2. 若链表的长度大于等于8并且总数组大小小于64则进行一次resize()
3. 若是总的元素个数大于 元素个数 * 扩容因子。则进行一次resize()

**为什么是0.75**

这是一个经验值。

假如我们设的比较大，元素比较多，空位比较少的时候才扩容，那么发生哈希冲突的概率就增加了，查找的时间成本就增加了。

我们设的比较小的话，元素比较少，空位比较多的时候就扩容了，发生哈希碰撞的概率就降低了，查找时间成本降低，但是就需要更多的空间去存储元素，空间成本 就增加了。

#### 2.2.9 HashMap 的扩容机制

**扩容量**：每次扩容的时候，容量扩大一倍。（容量用二进制表示，就是原来的二进制高位再增加一位）。

**元素迁移**：只用判断扰动函数计算出的hash值对应位置（与新长度length - 1对应二进制的最高位）是否是1，若是1，则移动到新的位置（原位置=旧索引位置 + 旧容量）。不是则放在原来的位置。

#### 2.2.10 HashMap 是线程安全的吗？多线程下会有什么问题？

HashMap不是线程安全的，可能会发生这些问题： 

+ 多线程下扩容死循环。JDK1.7 中的 HashMap 使用头插法插入元素，在多线程的 环境下，扩容的时候有可能导致环形链表的出现，形成死循环。因此，JDK1.8 使用尾插法插入元素，在扩容时会保持链表元素原本的顺序，不会出现环形链表 的问题。
+ 多线程的 put 可能导致元素的丢失。多线程同时执行 put 操作，如果计算出来的 索引位置是相同的，那会造成前一个 key 被后一个 key 覆盖，从而导致元素的丢 失。此问题在 JDK 1.7 和 JDK 1.8 中都存在。 
+ put 和 get 并发时，可能导致 get 为 null。线程 1 执行 put 时，因为元素个数超出 threshold 而导致 rehash，线程 2 此时执行 get，有可能导致这个问题。这个问题 在 JDK 1.7 和 JDK 1.8 中都存在。

#### 2.2.11 有什么办法能解决HashMap线程不安全的问题呢？

Java 中有 HashTable、Collections.synchronizedMap、以及 ConcurrentHashMap 可以实 现线程安全的 Map。 

+ **遗留的安全集合（不推荐使用）**：HashTable 是直接在操作方法上加 synchronized 关键字，锁住整个table数组，粒 度比较大； 
+ **修饰的安全集合（不推荐使用，内部也是synchronized ）**：Collections.synchronizedMap 是使用 Collections 集合工具的内部类，通过传入 Map 封装出一个 SynchronizedMap 对象，内部定义了一个对象锁，方法内通过对 象锁实现； 
+ **JUC安全集合**：ConcurrentHashMap 在jdk1.7中使用分段锁，在jdk1.8中使用CAS+synchronized。

#### 2.2.12 ConcurrentHashmap的实现

1. concurrentHashmap在jdk1.7的时候，使用的是分段锁（reneetrylock 锁住一个segment数组）
   + 大小数组，大数组是segment，每个segment包含一个HashEntry数组，每个HashEntry又是一个链表结构的元素，对同一个segment相关操作用reneetrylock加锁。多个segment之间操作可以并发执行。但是Segment 的个数⼀旦初始化就不能改变。 Segment 数组的大小默认是 16，也就是说默认可以同时⽀持 16 个线程并发写。
2. jdk1.8后用的cas和synchronized实现。
   + 若是Node结点没有分配就使用CAS，若是已经分配了就使用synchronized加锁，锁住当前链表或者红红黑树的首节点，这样只要 hash 不 冲突，就不会产生并发，就不会影响其他 Node 的读写，效率⼤幅提升。



#### 2.2.13 LinkedHashMap

LinkedHashMap 是 Java 中的一种特殊的 Map 实现，它继承自 HashMap 类，并且保留了插入顺序。在 LinkedHashMap 中==，每个条目（键值对）都保留了一个指向其前一个条目和后一个条目的指针，这样就形成了一个双向链表==。这个双向链表可以确保元素在迭代时按照插入顺序进行访问。

LinkedHashMap 与普通的 HashMap 相比，多了一个特性就是它保留了插入顺序。这意味着当你迭代一个 LinkedHashMap 时，你会按照元素插入的顺序来获取元素，而不是按照键的哈希值顺序或其他顺序。这种特性在某些场景下非常有用，例如需要维护一个键值对的顺序，或者需要实现 LRU（Least Recently Used）缓存等。







## 三、java并发



### 3.1 多线程基础

#### 3.1.1 线程的生命周期和状态

![image-20240711154740546](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407111547752.png)

分别是

* NEW：当一个线程对象被创建，但还未调用 start 方法时处于**新建**状态
* RUNNABLE：调用了 start 方法，就会由**新建**进入**可运行**
* TERMINATED：线程内代码已经执行完毕，由**可运行**进入**终结**
* BLOCKED：当获取锁失败后，由**可运行**进入**阻塞**状态，等待其他线程释放锁
* WAITING：成功获取锁的线程，由于调用了 wait() 或者别的方法（join()方法，park()方法），此时从**可运行**状态进入等待状态，等待其他线程的特定操作。
* TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样⼀直等待

#### 3.1.2 run() 和 start() 的区别

调用start()方法的作用是启动线程，让线程状态由 new 变为 runnable 表示线程准备就绪可以运行了，而调用 run() 方法表示 并不把它当作多线程方法调用，而是非多线程的正常方法调用。

#### 3.1.3 wait()方法 和 sleep()方法 有什么区别

共同点：

+ 两个方法都可以暂停当前线程的执行。不过 sleep() 方法 和 带参数的 wait(long) 方法是让线程进入 TIMED_WAITING 状态，而 不带参数的 wait() 方法是让线程进入 WAITING 状态。

不同点：

根本上的不同：wait() 通常被用于线程间交互/通信， sleep() 通常被用于暂停执行

+ sleep() 是 Thread 的静态方法，而 wait() 是 Object 的成员方法
+ wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象的 notify() 或者 notifyAll() 方法。带参数的 wait 方法 和 sleep 方法会在等待响应的时间后自动唤醒。
+ wait 方法的调用必须先获取 wait 对象的锁，wait 方法执行后会释放对象锁，允许其它线程获得该对象锁，而 sleep 如果在 synchronized 代码块中执行，并不会释放对象锁



### 3.2 多线程安全

#### 3.2.1 CAS

CAS 就是 **Compare And Swap（比较与交换）** ，用于实现乐观锁。CAS 的思想很简单，就是用一个预期值和要更新的变量值进行比较，两值相等才会进行更新。不相等时会进行自旋操作。

CAS 涉及到三个操作数：

- **V**：要更新的变量值(Var)
- **E**：预期值(Expected)
- **N**：拟写入的新值(New)

当且仅当 V 的值等于 E 时，CAS 通过原子方式用新值 N 来更新 V 的值。如果不等，说明已经有其它线程更新了 V，则当前线程放弃更新。

当多个线程同时使用 CAS 操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。

> Java 语言并没有直接实现 CAS，CAS 相关的实现是通过 C++ 内联汇编的形式实现的（JNI 调用）。因此， CAS 的具体实现和操作系统以及 CPU 都有关系。

>  `sun.misc`包下的`Unsafe`类提供了`compareAndSwapObject`、`compareAndSwapInt`、`compareAndSwapLong`方法来实现的对`Object`、`int`、`long`类型的 CAS 操作。

**CAS 存在的问题：**

1. ABA问题：

   一个值初次读取的时候是 V，赋值的时候还是 V，并不能说明它没有改变过。可能修改了两次又变回了原值。解决方法： **加上版本号**

2. 循环时间长开销大：

   CAS 经常会用到自旋操作来进行重试，也就是不成功就一直循环执行直到成功。如果长时间不成功，会给 CPU 带来非常大的执行开销。



#### 3.2.2 乐观锁与悲观锁

悲观锁认为安全问题一定会发生，因此要在操作数据前先获取锁，确保线程串行执行。典型实现：syncronized 。因为悲观锁的性能比较差，所以一般都是在竞争激烈的场景下才会使用悲观锁。

乐观锁认为安全问题不一定会发生，所以它不加锁，只在更新数据的时候去判断是否有其他线程修改了数据。典型实现 CAS，版本号机制。乐观锁的性能比较好，但是在多竞争的场景下可能会导致程序不断的自旋操作，所以乐观锁通常用于竞争较少的场景下。



#### 3.2.3 synchronized

synchronized 主要解决的是多个线程之间访问资源的同步性，可以保 证被它修饰的方法或者代码块在任意时刻只能有⼀个线程执行。 在 Java 早期版本中， synchronized 属于 重量级锁，效率低下。 因为监视器锁（monitor）是依赖于 底层的操作系统的互斥锁 来实现的，需要频繁的内核态和用户态的转换。

 不过，在 Java 6 之后，Java 官方对从 JVM 层面对 synchronized 优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6 对锁的实现引⼊了大量的优化，如自旋锁、适应性 自旋锁、偏向锁、轻量级锁等技术来减少锁操作的开销。

##### 3.2.3.1 synchronized的使用

+ 修饰实例方法 （锁当前对象实例）
+ 修饰静态方法 （锁当前类）
+ 修饰代码块 （锁指定对象/类）

##### 3.2.3.2 synchronized 重量级锁（monitor） 底层原理

重量级锁的底层由monitor实现的，线程获得锁需要使用对象（锁）关联monitor，在monitor内部有三个属性，分别是owner、entrylist、waitset。其中owner是关联的获得锁的线程，并且只能关联一个线程；entrylist关联的是处于阻塞状态的线程；waitset关联的是处于Waiting状态的线程。monitor指令的执行是JVM通过调用操作系统的互斥原语mutex来实现，被阻塞的线程会被挂起、等待重新调度，会导致“用户态和内核态”两个态之间来回切换，对性能有较大影响。

##### 3.2.3.3 锁升级

JDK1.6之后的 Java中的synchronized有无锁、偏向锁、轻量级锁、重量级锁四种形式，且四种状态会随着竞争的情况逐渐升级，而且是不可逆的过程。

![output](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407112215282.png)

##### 匿名偏向

在程序启动一段时间（可以通过 JVM 参数配置）之后，新建的对象的对象空间的对象头中（markword）都会被设置为偏向锁的类型，不过因为还没有线程占用它，所以markword中的 threadId 先为空，所以称为匿名偏向。在这段时间之前创建的的对象markword为无锁的状态。

##### 偏向锁

当执行到synchronized代码块时，无锁状态的对象会变成偏向锁，匿名偏向也会被赋值threadId，当然偏向锁可以通过 JVM 配置关闭，如果关闭就直接成为轻量级锁。或者当前对象执行过 hashcode 方法，也会禁用偏向锁，因为 非偏向锁的类型，在 markword 部分会保存一个hashcode字段，这个字段初始化为 空，执行完 hashcode 会被赋值，一旦被赋值就会禁用 偏向锁，因为偏向锁的 markword 部分没有 hashcode 字段。

当一个线程访问同步代码块并获取锁时，会在 Mark Word 里存储锁偏向的线程 ID。在线程进入和退出同步块时不再通过 CAS 操作来加锁和解锁，而是检测 Mark Word 里是否存储着指向当前线程的偏向锁。轻量级锁的获取及释放依赖多次 CAS 原子指令，而偏向锁只需要在置换 ThreadID 的时候依赖一次 CAS 原子指令即可。这也是为什么轻量级锁比偏向锁的级别更高。

偏向锁只适用于只有一个线程执行同步代码块的情况，一旦有第二个线程进入，偏向锁就会升级为轻量级锁。 

##### 轻量级锁（自旋锁）

轻量级锁的实现和偏向锁的差别不大，都是在线程栈中创建一个 Lock Record 对象，只不过偏向锁是在 markword 字段存储偏向锁的线程 id ，而轻量级锁的 markword 是存储 lock Record 的地址，所以这也导致了 轻量级锁的 每次重入 都要进行一次 CAS 操作。

在轻量级锁状态下继续锁竞争，没有抢到锁的线程将自旋，进入忙等状态。此忙等是有限度的（有个计数器记录自旋次数，默认允许循环10次，可以通过虚拟机参数更改）。如果锁竞争情况严重，某个达到最大自旋次数的线程，会将轻量级锁升级为重量级锁。当后续线程尝试获取锁时，发现被占用的锁是重量级锁，则直接将自己挂起（而不是忙等），等待将来被唤醒。

重量级锁是指当有一个线程获取锁之后，其余所有等待获取该锁的线程都会处于阻塞状态。简言之，就是所有的控制权都交给了操作系统，由操作系统来负责线程间的调度和线程的状态变更。而这样会出现频繁地对线程运行状态的切换，线程的挂起和唤醒，从而消耗大量的系统资。



#### 3.2.4 JMM （Java内存模型）

JMM就是Java的内存模型，它规定了 Java 程序中多线程并发访问共享内存的规则。

具体而言就是每个线程有自己的工作内存，所有线程都共享主内存。当我们要同步更新共享变量的值的时候，JMM规定在加锁前，必须读取主内存中的最新变量值到当前线程的工作内存中，然后在线程解锁前，必须把共享变量写回主内存中，以此来确保线程间的安全性和可见性。



#### 3.2.5 volatile

##### 3.2.5.1 介绍一下volatile

volatile用于修饰变量，可以用来保证可见性与有序性，但volatile不保证volatile变量的原子性。

**可见性问题**：可见性问题指的是，线程一开始读取了变量的值到自己的工作内存中，因为线程要频繁的访问这个变量，那么 JIT 编译器会把这个变量的值缓存到自己的工作内存中，后面即使主内存中的变量值被改变了，但是线程依然会在自己的工作内存中读取它的旧值，这就导致了可见性问题。其实可见性问题也可以直接用 JVM 参数关闭 JIT 来解决。

**可见性问题解决**：volatile关键字会强制 在读取这个变量的时候就会强制去主内存中读取这个变量的值，在写操作之后就会强制将最新的值写入主内存中，这样来实现可见性。

**有序性问题：**有序性问题指的是，JVM会在不影响结果的前提下，进行指令重排。但是在多线程模式下这样肯恶搞会带来问题。

**有序性问题解决：**volatile会通过插入内存屏障来禁止指令重排，具体来说在对变量的写操作前会插入写屏障，会确保指令重排的时候，不会将写屏障前的代码排在写屏障之后。在读操作后加入读屏障，确保读屏障后的代码不会重排到读屏障之前。



##### 3.2.5.2 单例模式DCL中的 volatile

单例模式：该模式只会有一个实例对象。

volatile有个比较经典的应用就是双层校验锁的单例模式DCL（double check lock）单例

```java
class A{
    private volatile static A uniqueInstance;
    private A(){}
    public static A getuniqueInstance(){
        if(uniqueInstance == null){//第一层检查可以减少所有的线程都加锁，减少了锁的粒度
            syncronized(A.class){
                if(uniqueInstance == null){
                    uniqueInstance = new A();
                }
            }
        }
        return uniqueInstance;
    }
}
```

双层校验锁：为了减少 syncronized 锁住的范围。

若不加volatile则多线程情况下，对象初始化和引用指向地址这步骤可能发生指令重排，导致得到该单例的线程，这个单例是没有完全初始化的。



##### 3.2.5.1 syncronized  和 volatile 对比

- 使用：volatile修饰变量，synchronized修饰方法或者代码块
- 功能：volatile只能实现可见性有序性不能实现原子性，syncronized三个都能实现。
  - 实现可见性的原理是相同的。修改线程本地内存的变量后直接刷新到主内存，然后其他线程本地内存需要读该数据，先从主内存中读。底层都是使用内存屏障来完成。
- 原理：实现有序性原理不太一样，volatile是使用内存屏障来抑制指令重排，而syncronized不能抑制执行指令重排和处理器优化，但是单线程满足as if serial语义（不论怎么重排，最终的结果不能够改变）。



#### 3.2.6 AQS

##### 3.2.6.1 介绍一下 AQS

全称是抽象队列同步器 AbstractQueuedSynchronizer，是JUC中构建锁或者其他同步组件的基础框架。

1. 提供了一个volatile修饰的 int变量 state来表示资源抢占状态，`volatile`保证线程之间对它可见性；不同线程通过CAS来改变state；state等于0表示锁没有被占有，1表示被占有，大于1表示同一个线程多次占有锁（锁可重入）。
2. 使用了一个FIFO双向队列，来存储没有抢占到资源而被阻塞的线程。结点代表线程thread。

> AQS 既可以是 共享锁 也可以是 独占锁，既可以是 公平锁 也可以是 非公平锁

##### 3.2.6.2 Reentranlock

ReentrantLock主要利用CAS+AQS队列来实现。它同时支持公平锁和非公平锁，通过构造方法接受一个可选的公平参数（默认非公平锁），当设置为true时，表示公平锁，否则为非公平锁。公平锁则体现在所有的线程按照先后顺序获取锁，非公平体现在不在排队的线程也可以抢锁。

其他方面基本就是AQS的实现了：

- 线程来抢锁后使用cas的方式修改state状态，修改状态成功为1，则让exclusiveOwnerThread属性指向当前线程，获取锁成功；
- 假如修改状态失败，则会进入双向队列中等待；
- 当exclusiveOwnerThread为null的时候，则会唤醒在双向队列中等待的线程；

> **公平锁与非公平锁**
>
> **公平锁** : 锁被释放之后，先申请的线程先得到锁。性能较差一些，因为公平锁为了保证时间上的绝对顺序，上下文切换更频繁。
>
> **非公平锁**：锁被释放之后，后申请的线程可能会先获取到锁，是随机或者按照其他优先级排序的。性能更好，但可能会导致某些线程永远无法获取到锁。

##### 3.2.6.3 （Lock）Reentranlock 和 syncronized 的对比

* 语法层面
  * synchronized 是关键字，源码在 jvm 中，用 c++ 语言实现
  * Lock 是接口，源码由 jdk 提供，用 java 语言实现
  * 使用 synchronized 时，退出同步代码块锁会自动释放，而使用 Lock 时，需要手动调用 unlock 方法释放锁
* 功能层面
  * 二者均属于悲观锁，但是 Lock 提供了许多 synchronized 不具备的功能，例如获取公平锁、可打断、多条件变量
  * Lock 有适合不同场景的实现，如 ReentrantLock， ReentrantReadWriteLock
* 性能层面
  * 在没有竞争时，synchronized 做了很多优化，如偏向锁、轻量级锁，性能不赖
  * 在竞争激烈时，Lock 的实现通常会提供更好的性能

> **可中断锁和不可中断锁有什么区别？**
>
> - **可中断锁**：获取锁的过程中可以被中断，不需要一直等到获取锁之后 才能进行其他逻辑处理。`ReentrantLock` 就属于是可中断锁。
> - **不可中断锁**：一旦线程申请了锁，就只能等到拿到锁以后才能进行其他的逻辑处理。 `synchronized` 就属于是不可中断锁

##### 3.2.6.4  如何控制某个方法允许并发访问线程的数量？（Semaphore）

在juc中提供了一个Semaphore[seməfɔːr]类（信号量），其实就和操作系统中的信号量是相同的机制。我们在需要控制并发量的线程中使用，在进入线程前先定义能并发的最大数量，在线程中先用semaphore.acquire() 请求信号量，一个线程获取了信号量则信号量数量减一，到0的时候就不许其他线程获取信号量了，使用semaphore.release()方法，可以释放信号量。

##### 3.2.6.4  如何控制线程的同步？（Semaphore）

两种方法：1. CountDownLatch等待线程完成 2. Future 类接受线程返回数据

CountDownLatch（闭锁/倒计时锁）用来进行线程同步协作，等待所有线程完成，初始化需要等待的线程数，然后每个线程结束调用countDown() 用来让计数减一，等待计数为0，调用了await() 方法的线程就可以继续执行。

Future 类的get方法可以等待我们的线程数据返回后，获取这个数据然后继续执行。



#### 3.2.7 并发程序出现问题的根本原因

根本原因就是 没有满足 Java 并发编程三大特性中的一个或者多个：

- **原子性**：即一个操作或者多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。解决：synchronized，或者 JUC 里的 Lock；

- **可见性**：让一个线程对共享变量的修改对另一个线程可见。解决：synchronized、volatile、Lock；

- **有序性**：处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。在多线程下，会出现问题。解决：volatile；



### 3.3 线程池

#### 3.3.1 线程池的核心参数

线程池就是管理一系列线程的资源池。当有任务要处理时，直接从线程池中获取线程来处理，而不是每次都新建线程，这样可以显著的优化处理速度，处理完之后线程并不会立即被销毁，而是等待下一个任务。线程池核心参数主要参考ThreadPoolExecutor这个类的7个参数的构造函数

- corePoolSize 核心线程数目

- maximumPoolSize 最大线程数目 = (核心线程+救急线程的最大数目)

- keepAliveTime 生存时间：救急线程的生存时间，生存时间内没有新任务，此线程资源会释放

- unit 时间单位 - 救急线程的生存时间单位，如秒、毫秒等

- workQueue - 当没有空闲核心线程时，新来任务会加入到此队列排队，队列满会创建救急线程执行任务

- threadFactory 线程工厂 - 可以定制线程对象的创建，例如设置线程名字、是否是守护线程等

- handler 拒绝策略 - 当所有线程都在繁忙，workQueue 也放满时，会触发拒绝策略

#### 3.3.2 线程池的工作流程

![image-20240713164511253](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407131645425.png)

1，任务在提交的时候，首先判断核心线程数是否已满，如果没有满则直接添加到工作线程执行

2，如果核心线程数满了，则判断阻塞队列是否已满，如果没有满，当前任务存入阻塞队列

3，如果阻塞队列也满了，则判断线程数是否小于最大线程数，如果满足条件，则使用临时线程执行任务

如果核心或临时线程执行完成任务后会检查阻塞队列中是否有需要执行的线程，如果有，则使用非核心线程执行任务

4，如果所有线程都在忙着（核心线程+临时线程），则走拒绝策略



#### 3.3.3 拒绝策略

1.AbortPolicy：直接抛出异常，默认策略；

2.CallerRunsPolicy：用调用者所在的线程来执行任务；

3.DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务；

4.DiscardPolicy：直接丢弃任务；



#### 3.3.4 常用的阻塞队列

比较常见的有4个，用的最多是ArrayBlockingQueue和LinkedBlockingQueue

1.ArrayBlockingQueue：基于数组结构的有界阻塞队列，FIFO。需要在初始化的时候指定长度。

2.LinkedBlockingQueue：基于链表结构的有界阻塞队列，FIFO。默认长度为 Integer.MAX_VALUE，默认长度创建的话，可能会堆积大量的请求，导致OOM。

3.DelayedWorkQueue ：是一个优先级队列，可以自定义比较器。

4.SynchronousQueue：不存储元素的阻塞队列，每个插入操作都必须等待一个移出操作。



#### 3.3.5  常见的线程池有那些，为什么不推荐使用Executors创建线程池

FixedThreadPool：固定线程数的线程池

SingleThreadExecutor：单线程化的线程池

CachedThreadPool：可缓存线程池

ScheduledThreadPool：可定时执行的线程池

`Executors` 返回线程池对象的弊端如下：

- `FixedThreadPool` 和 `SingleThreadExecutor`:使用的是有界阻塞队列是 `LinkedBlockingQueue` ，其任务队列的最大长度为 `Integer.MAX_VALUE` ，可能堆积大量的请求，从而导致 OOM。
- `CachedThreadPool`:使用的是同步队列 `SynchronousQueue`, 允许创建的线程数量为 `Integer.MAX_VALUE` ，如果任务数量过多且执行速度较慢，可能会创建大量的线程，从而导致 OOM。
- `ScheduledThreadPool` :使用的无界的延迟阻塞队列 `DelayedWorkQueue` ，任务队列最大长度为 `Integer.MAX_VALUE` ，可能堆积大量的请求，从而导致 OOM。



#### 3.3.6 如何设定线程池的大小

线程池的大小根据任务类型不同也有不同的配置策略，但是这种预定义线程池大小的策略总归是静态的，很难直接估计出一个合理的参数，现在有很多动态配置线程池参数的设计，有一个简单并且适用面比较广的公式：

- **CPU 密集型任务(N+1)：** 这种任务消耗的主要是 CPU 资源，可以将线程数设置为 N（CPU 核心数）+1。比 CPU 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。为了防止防止上下文切换带来的消耗，所以 cpu 密集型任务 一般设置为 和 cpu 核数相等。
- **I/O 密集型任务(2N)：** 这种任务应用起来，系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。因此在 I/O 密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 2N。

> 上下文切换：
>
> 多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。**任务从保存到再加载的过程就是一次上下文切换**。



#### 3.3.7 动态线程池的原理

**动态调整线程池的参数，成熟的轮子有dynamic-tp等。**

主要的原理：

1. **监听模块：**从配置中心中获取可以动态改变的线程池参数。
2. **线程池管理模块：**java线程池的类（`ThreadPoolExecutor`）中提供了可以修改核心线程数、最大线程数、存活时间、拒绝策略等参数修改的接口，在配置中心中修改对应的数值后，**线程池管理模块**就会调用对应的接口进行动态修改。

![img](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407131826464.png)

 3. 但是线程池类（`ThreadPoolExecutor`）中没有提供修改阻塞队列大小的方法，但是很多动态线程池的组件都可以修改，原理是它重写了阻塞链表队列这个类，把队列大小这个值是个final类型，删除了final并且提供了修改大小的接口。

**平滑过渡**

以setCorePoolSize()为例子

 - 先覆盖旧值corePoolSize
 - 若是新值小于原来的值，则会让处于闲置（idle）状态的线程（worker）发起中断请求。
 - 若是新值大于原来的值，则会创建worker线程去执行阻塞队列的任务。



### 3.4 ThreadLocal

#### 3.4.1 ThreadLocal

ThreadLocal 主要是解决在多线程环境下的共享变量的隔离，并且实现在线程内的资源共享。比较经典的例子就是用于保存用户登录信息，这样每个线程可以保存自己的用户信息，并且在同一个线程中的任何地方都可以获取到登录信息。但是我的项目中并没有这样使用过ThreadLocal，因为我们使用了成熟的安全框架，比如shiro和springsecurity，都内置了获取用户信息的方式。

#### 3.4.2 ThreadLocal的原理

- threadlocal不存储对应的本地变量值，它是存在线程中的。每个线程中有一个叫`threadLocalMap`的数据结构，它的key是一个`threadLocal`对象的弱引用，value是需要隔离的本地变量。
- 当执行`threadlocal.set()`的时候，底层会拿到当前执行线程的`threadlocalmap`然后将当前`threadlocal`的弱引用设置为key，需要隔离的变量设置为value。
- 当执行`threadlocal.get()`的时候，从`threadlocalmap`中通过threadlocal作为key得到对应的map。

#### 3.4.3 ThreadLocal内存泄漏

`ThreadLocalMap` 中使用的 key 为 `ThreadLocal` 的弱引用，而 value 是强引用。所以，如果 `ThreadLocal` 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。

这样一来，`ThreadLocalMap` 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。`ThreadLocalMap` 实现中已经考虑了这种情况，在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 `ThreadLocal`方法后最好手动调用`remove()`方法。

> 强引用：我们最常见使用的引用，只有当强引用为null的时候才会触发GC。
>
> 软引用：使用`SoftReference`声明，当JVM内存将要发生OOM的时候会回收对应的对象。
>
> 弱引用：使用`WeakReference`声明，当JVM发生GC（各种GC）的时候，就会回收该对象。
>
> 虚引用：无法使用虚引用来使用对应的对象实例，它存在的作用是GC的时候会发送一个系统通知。

##### 3.4.3.1 key为什么设置为弱引用

- 若是把key设置成强引用，那么当threadlocalMap外面threadlocal强引用设置为空了，这时候threadlocalMap里面的key其实已经访问不到了，但是因为是强引用，导致不能通过gc得到及时的删除。造成内存泄漏。
- 设置成弱引用，当不存在强引用了，在最近一次GC对象就会被回收，threadlocalMap中对应的key为null了，然后下一次调用get(),set(),remove()的时候，会删除key为null的value值。



#### 3.4.5 threadLocalMap的结构

ThreadLocalMap 它是一个定制的哈希表，专门用于保存每个线程中的线程局部变量。ThreadLocalMap 内部维护了一个 Entry 类型的数组，初始化长度为16，每次扩容为两倍的大小，加载因子为三分之二，解决哈希冲突的方式是线性探测，内部的hashcode方法使用了**斐波那契数**作为hash的计算因子，大大减少了冲突的概率。



### 3.5 ==我的项目中的线程池使用==

超限治理系统中：因为一超四罚（驾驶员、车辆、车辆所属企业、订单委托企业）政策的存在，所以治超系统大屏需要一个联动效果，左边展示了所有的超限车辆名单（车牌，时间，地点），点击某辆车的信息，右侧要展示 一超四罚的信息（人、车辆、车辆所属企业），所有信息都要使用大件运输许可的接口数据排除。

人和车辆的超限信息在我们单位的治超部门的数据库中，企业信息是在执法大队的数据库中，驾驶人黑名单是在我们自己的数据库中（因为这是我们自己定义的标准，不是官方的标准，当一个司机上个月超限超过三次加入黑名单），还有一个大件运输许可的接口数据。

原本的串行获取数据，再计算逻辑接口时间基本在两秒多，使用线程池和Future类来并行获取每个线程数据，接口速度优化到几百毫秒。具体实现就是定义了一个ExecutorService的Bean，使用线程池的submit方法来提交任务，然后用Future接收返回值，用Future的get方法获取结果。后面再进行逻辑处理。

#### 3.5.1 具体要获取那些信息呢

具体来说就是这个驾驶员 本月的的超限次数，平均超限百分比，联系方式，是否为黑名单成员；
车辆的超限次数，平均超限的百分比，车辆允许最大载重，实际承载最大重量；
车辆所属企业的，超限次数，拥有车辆数，联系人方式（企业重点关注的是超限车次占拥有车辆的百分比）；

#### 3.5.2 涉及哪些数据库，为什么不在一个数据库中

本接口涉及了，三个数据库，一个接口信息，我们单位治超部门的数据库，我们信息中心的数据库，执法大队的数据库，大件运输许可的接口。因为公路局的治超部门的主要任务是防止超重车辆压坏道路、桥梁这种道路基础设施，治超的执法权并不在公路局。所以我们的治超部门只有基本的超限信息，而执法大队则包含着比较全面的信息，包括物流企业的信息。使用了我们自己的数据库是因为这个黑名单的功能是我们自己设计的，不是官方标准，就用了自己的数据库存储。大件运输许可这个我也不清楚，我只知道他们那边这个数据只有接口提供。

#### 3.5.3 线程池的参数如何设计的

在接口中，用了线程池进行优化
主要的参数：
- 核心线程数选择的128，最大线程数选择的128（因为项目部署的服务器的64核的，然后处理的任务是获取不同数据源数据，本质是网络IO。所以选择了经验值2 * 8。）
- 阻塞队列选择的是链表阻塞队列，大小1024，这个是经验值。
- 拒绝策略选择是任务调用线程去执行。





## 四、JVM

JVM——Java虚拟机，它是Java实现平台无关性的基石。

 Java程序运行的时候，编译器将Java文件编译成平台无关的Java字节码文件（.class）, 接下来对应平台JVM对字节码文件进行解释，翻译成对应平台匹配的机器指令并运行.

### 4.1 JVM 内存区域

#### 4.1.1 内存区域的组成

![image-20240726150523979](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407261505098.png)

运行时数据区域：

1. 线程共有：堆，方法区
2. 线程私有：虚拟机栈、本地方法栈、程序计算器PC

- 堆：储存对象实例、数组、字符串常量池等

  - 新生代：edge区，surviver区：
  - 老年代：到达一定条件，对象会从新生代进入老年代。
  - 永久代：JDK 8 版本之后 PermGen(永久代) 已被 Metaspace(元空间) 取代，元空间使用的是本地内存。
  - 字符串常量池：（JDK7 时从方法区移动到堆中）主要目的是为了避免字符串的重复创建。

- 方法区：存储已被虚拟机加载的类相关信息（类信息、字段信息、方法信息、常量、静态变量、即时编译器编译后的代码缓存等数据。）、运行时常量池等。

  - 运行时常量池：各种字面量和符号引用的常量池表 。
  - JDK 8 之前实现方式为 堆中的永久代，JDK 8 开始用元空间实现并且存储在本地内存中。

- 虚拟机栈：主要是存放一般方法执行时候的数据。每一次方法调用都会有一个对应的栈帧被压入栈中，每一个方法调用结束后，都会有一个栈帧被弹出。每个栈帧都有：

  - 局部变量表（基本数据类型的值或者对象引用）

  - 操作数栈（方法执行过程中产生的中间计算结果或临时变量）

  - 动态链接（调用其他函数相关）

  > 动态链接部分包含一个指向方法区（或元空间）中常量池的引用，这个常量池包括了方法和字段的符号引用。然后再方法执行的时候，动态链接会被解析为直接引用。

  - 方法返回地址 

- 本地方法栈：存放native方法执行时候的相关数据。

- 程序计数器：记录下一条指令地址，从而实现代码的流程控制。

#### 4.1.2 为什么要将永久代 替换为元空间呢?

降低OOM风险：整个永久代有一个 JVM 本身设置的固定大小上限，无法进行调整（也就是受到 JVM 内存的限制），而元空间使用的是本地内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小。



#### 4.1.3 JDK 1.7 为什么要将字符串常量池移动到堆中？

主要是因为永久代（方法区实现）的 GC 回收效率太低，只有在整堆收集 (Full GC)的时候才会被执行 GC。Java 程序中通常会有大量的被创建的字符串等待回收，将字符串常量池放到堆中，能够更高效及时地回收字符串内存。



#### 4.1.4 对象的创建过程

在JVM中对象的创建，虚拟机遇到new指令开始：

+ 类加载检查：首先检查这个指令的参数是否能在常量池中定位到一个类的符号引用 
+ 检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，就先执 行相应的类加载过程 
+ 类加载检查通过后，接下来虚拟机将为新生对象分配内存。 
+ 内存分配完成之后，虚拟机将分配到的内存空间（但不包括对象头）都初始化为 零值。 
+ 接下来设置对象头，请求头里包含了对象是哪个类的实例、如何才能找到类的元 数据信息、对象的哈希码、对象的GC分代年龄等信息。





### 4.2 JVM 类加载器

#### 4.2.1 什么是字节码，class 文件结构

在 Java 中，JVM 可以理解的代码就叫做`字节码`（即扩展名为 `.class` 的文件），它不面向任何特定的处理器，只面向虚拟机。

**class文件结构**

+ 魔数：标识是否为Class文件。
+ Class文件版本号：确定使用java的版本。
+ 常量池：字面量和符号引用。
  + 类和接口的全限定名
  + 字段的名称和描述符
  + 方法的名称和描述符
+ 访问标志：public 或者 abstract 或者 final 等。
+ 当前类、父类、接口索引集合：Java 类的继承关系由类索引、父类索引和接口索引集合三项确定。
+ 字段表集合：描述接口或类中声明的变量。
+ 方法表集合：描述接口或类中声明的方法。
+ 属性表集合：在 Class 文件，字段表，方法表中都可以携带自己的属性表集合，以用于描述某些场景专有的信息。

#### 4.2.2 什么是类加载器，类加载器有哪些

类加载器（ClassLoader）的主要作用就是将**字节码文件加载到JVM中**，在内存中生成一个代表该类的 Class 对象，从而让Java程序能够启动起来。

常见的类加载器有4个：

+ 启动类加载器(BootStrap ClassLoader)：其是由C++编写实现。用于加载JAVA_HOME/jre/lib目录下的类库。

+ 扩展类加载器(ExtClassLoader)：该类是ClassLoader的子类，主要加载JAVA_HOME/jre/lib/ext目录中的类库。

+ 应用类加载器(AppClassLoader)：该类是ClassLoader的子类，主要用于加载classPath下的类，也就是加载开发者自己编写的Java类。

+ 自定义类加载器：开发者自定义类继承ClassLoader，实现自定义类加载规则。

#### 4.2.3 类加载的过程

类从加载到虚拟机中开始，直到卸载为止，它的整个生命周期包括了：加载、验证、准备、解析、初始化、使用和卸载这7个阶段。其中，验证、准备和解析这三个部分统称为连接（linking）

1. 加载：查找和导入class文件

   a. 根据类的**全限定名称**定位到.class文件

   b. 将对应二进制字节流表示的数据结构转化为方法区中的**数据结构**

   c. 在堆中生成一个class对象，作为访问这个类的入口

2. 验证：确保 Class 文件的字节码符合 JVM 规范

3. 准备：将类变量（静态变量）分配内存并且赋予初始值。

4. 解析：把类中的符号引用转换为直接引用

5. 初始化：对类的静态变量，静态代码块执行初始化操作

6. 使用

7. 卸载：卸载类即该类的 Class 对象被 GC

#### 4.2.4 双亲委派模型

##### 4.2.4.1 什么是双亲委派模型

1. 首先判断类是否被当前类加载器加载过，已经被加载的类会直接返回
2. 把这个请求委派给父类加载器去完成（调用父加载器 `loadClass()`方法来加载类）。父类再调用父类的父类，最终都会传送到顶层的启动类加载器 `BootstrapClassLoader` 中。
3. 只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载（调用自己的 `findClass()` 方法来加载类）。
4. 如果子类加载器也无法加载这个类，那么它会抛出一个 `ClassNotFoundException` 异常。

##### 4.2.4.2 双亲委派模型的好处

+ 双亲委派模型可以避免类的重复加载：jvm中判断两个类是否相同的不仅要看全限定类名相同，还要看类加载器是否相同。若是没有双亲委派机制，可能造成同一个类被多个类加载器加载的情况。

+ 也保证了 Java 的核心 API 不被篡改：如果用户自定义了一个同核心类相同全限定名的类（比如java.lang.Object），若是没有双亲委派机制，则环境中可能出现多个版本的核心类。

##### 4.2.4.3 如何打破双亲委派模型

自定义加载器的话，需要继承 `ClassLoader` 。如果我们不想打破双亲委派模型，就重写 `ClassLoader` 类中的 `findClass()` 方法即可，无法被父类加载器加载的类最终会通过这个方法被加载。但是，如果想打破双亲委派模型则需要重写 `loadClass()` 方法。因为类加载器都是通过这个方法去加载类的。比如 Tomcat 就打破了双亲委派模型。

##### 4.2.4.4 Tomcat的类加载机制

Tomcat 类加载器：

![image-20240726214034707](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407262140878.png)

Tomact是web容器，可能需要部署多个应用程序。不同的应用程序可能会依赖同一个 第三方类库的不同版本，但是不同版本的类库中某一个类的全路径名可能是一样 的。如多个应用都要依赖hollis.jar，但是A应用需要依赖1.0.0版本，但是B应用需要 依赖1.0.1版本。这两个版本中都有一个类是com.hollis.Test.class。如果采用默认的双 亲委派类加载机制，那么无法加载多个相同的类。 

所以，Tomcat破坏了双亲委派原则，提供隔离的机制，为每个web容器单独提供一 个WebAppClassLoader加载器。每一个WebAppClassLoader负责加载本身的目录下的 class文件，加载不到时再交CommonClassLoader加载，这和双亲委派刚好相反。





### 4.3 JVM 垃圾回收



### 4.4 JVM 调优
