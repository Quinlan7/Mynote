# java

[TOC]

## 数据结构基础

### 红黑树、B树和B+树

AVL树：平衡二叉树

BST树：二叉查找树

#### 红黑树

##### 来源

其实红黑树是 2-3-4树（也可以叫做 2-4 树）的等价实现，因为2-3-4树有完美的自平衡性，它的所有操作在最坏的情况下复杂度也是 O(log n) 所以2-3-4树的查找、插入和删除的效率都很高。

但是由于2-3-4树按照它最初的定义来实现的话，不仅需要大量的代码，而且它们所产生的额外开销可能会使算法比标准的二叉查找树更慢。所以产生了红黑树，红黑树的红黑，其实指得是连接当前节点的链接的属性，因为每个节点都只有一个指向它的链接所以用节点的属性代替链接的属性。红色链接 指的就是 红色链接两端的节点，其实可以转化为2-3-4中的一个3节点或者4节点。2-3-4树的到达每一个空链接的路径长相等性质，也就转化为红黑树的到叶子节点的黑色节点数量一致的性质。

> 其实最早的完美平衡查找树为 2-3 树，它对应的二叉树实现为左偏红黑树。
>
> 2-3-4树的四节点，其实对应的红黑树的情况是，一个黑色的父节点有两个红色的孩子，这样就是四节点了。

##### 性质

1. **根节点是黑色的**： 第一个性质要求根节点始终是黑色的，这确保了树的整体结构保持平衡。
2. **红色子节点性质**： 不能有两个相连的红色节点。这意味着从任意节点到其子节点的路径上不能出现连续的红色节点，以避免出现不平衡情况。
3. **黑高度平衡性质**： 从任意节点出发，到达其每个叶子节点的路径上的黑色节点数量必须相同。这确保了树的高度始终保持在一个合理的范围内，从而保。证了高效的查找操作。
4. **红黑性质的维护**： 在执行插入和删除操作后，红黑树需要通过旋转和颜色调整来保持这些性质，从而恢复平衡。这些操作保证了在更新操作之后，树仍然是一颗满足红黑性质的树。
5. **空节点的处理**： 空节点（NIL节点）被认为是黑色的。这样可以确保每个路径上的黑色节点数量相等，即使是经过了空节点的路径。

##### 对比AVL树

+ 平衡性：
  + 红黑树：红黑树保证了一种弱平衡，即树的高度最多是2倍的对数级别。这使得红黑树在插入和删除操作时具有更高的灵活性，但可能导致一些操作稍微不如AVL树高效。
  + AVL树：AVL树是一种严格的平衡树，保证任何节点的左子树和右子树的高度差（平衡因子）不超过1。这确保了AVL树在平衡方面表现更好，但在插入和删除操作时可能需要更多的旋转来维持平衡。
+ 插入和删除操作的性能：
  + 红黑树：由于红黑树的平衡性要求相对较弱，插入和删除操作通常需要更少的旋转操作，因此在这些操作上性能可能比AVL树更好。
  + AVL树：AVL树的严格平衡性可能导致插入和删除操作需要更频繁的旋转操作，因此在这些操作上可能比红黑树略逊一筹。


##### 插入

当在红黑树中执行插入操作时，需要考虑两个主要方面：保持二叉搜索树性质和保持红黑性质。以下是插入操作的详细步骤，包括可能的旋转操作和颜色调整。

插入操作的基本步骤：

1. 将新节点插入到BST中： 首先，将新节点插入到红黑树中，就像在普通的二叉搜索树中一样。新节点会被标记为红色，因为它可能会破坏红黑性质的第一个性质（根节点必须是黑色）。

2. 检查红黑性质： 插入新节点后，可能会破坏红黑性质。需要通过一系列的操作来调整以确保所有的红黑性质得到满足。

颜色调整： 在进行旋转操作之前，需要进行颜色调整以满足红黑性质。以下是颜色调整的可能情况：

1. 父节点为黑色： 如果插入的节点的父节点是黑色的，那么树的结构没有破坏，不需要进一步的调整。

2. 父节点为红色： 如果插入的节点的父节点是红色的，那么可能会破坏红黑性质的第二个性质（不能有两个相连的红色节点）。在这种情况下，需要考虑插入节点的叔叔节点（父节点的兄弟节点）的颜色。

a. 叔叔节点是红色： 如果叔叔节点是红色的，可以通过改变父节点和叔叔节点的颜色，然后将问题向上移动到父节点。这样可以保持黑高度平衡性质。

b. 叔叔节点是黑色或缺失： 如果叔叔节点是黑色的（包括叔叔节点为NIL节点），需要通过旋转来修复这种情况。

**情况一：如果关注节点是 a，它的叔叔节点 d 是红色**

![img](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202404221734309.png)


具体操作为：将关注节点 a 的父节点 b、叔叔节点 d 的颜色都设置成黑色；将关注节点 a 的祖父节点 c 的颜色设置成红色；关注节点变成 a 的祖父节点 c；跳到情况二或者情况三。

**情况二：如果关注节点是 a，它的叔叔节点 d 是黑色，关注节点 a 是其父节点 b 的右子节点**

![img](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202404221734603.png)

具体操作为：关注节点变成节点 a 的父节点 b；围绕新的关注节点b 左旋；跳到情况三。

**情况三：如果关注节点是 a，它的叔叔节点 d 是黑色，关注节点 a 是其父节点 b 的左子节点**

![img](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202404221735941.png)

具体操作为：围绕关注节点 a 的祖父节点 c 右旋；将关注节点 a 的父节点 b、兄弟节点 c 的颜色互换，调整结束。

##### 删除

删除操作比较复杂，其实贱但来说就是通过，旋转和调整颜色，分情况处理使删除后的红黑树依然符合红黑树的性质。



#### B树

##### 简介

首先 B树 和 B-树 是同一种数据结构。在计算机科学中，B树是一种自平衡的树，能够保持数据有序。这种数据结构能够让查找数据、顺序访问、插入数据及删除的动作，都在对数量级的时间复杂度内完成。B树，其实是一颗特殊的二叉查找树（binary search tree），可以拥有多于2个子节点。与自平衡二叉查找树不同，B树为系统大块数据的读写操作做了优化。B树减少定位记录时所经历的中间过程，从而加快存取速度，其实B树主要解决的就是数据IO的问题。B树这种数据结构可以用来描述外部存储。这种数据结构常被应用在数据库和文件系统的实现上。

##### 性质

首先介绍一下一棵 m 阶的 B 树的特性。m表示这个树的每一个节点最多可以拥有的子节点个数。一棵 m 阶的 B 树满足的性质如下：

1. 每个节点最多有 m 个子节点。
2. 每一个非叶子节点（除根节点）最少有 $ \left \lceil m/2 \right \rceil $ 个子节点。
3. 如果根节点不是叶子节点，那么它至少有两个子节点。
4. 有 k 个子节点的非叶子节点拥有 k-1 个键，且升序排列，满足 k[i] < k[i+1]。
5. 所有的叶子节点都在同一层。

##### 优势

之前已经介绍过二叉查找树。但是这类型数据结构的问题在于，由于每个节点只能容纳一个数据，导致树的高度很高，逻辑上挨着的节点数据可能离得很远。

考虑在磁盘中存储数据的情况，与内存相比，读写磁盘有以下不同点：

1. 读写磁盘的速度相比内存读写慢很多。
2. 每次读写磁盘的单位要比读写内存的最小单位大很多。

由于读写磁盘的这个特点，因此对应的数据结构应该尽量的满足「局部性原理」：「当一个数据被用到时，其附近的数据也通常会马上被使用」，为了满足局部性原理， 所以应该将逻辑上相邻的数据在物理上也尽量存储在一起。这样才能减少读写磁盘的数量。

所以，对比起一个节点只能存储一个数据的 BST 类数据结构来，要求这种数据结构在形状上更「胖」、更加「扁平」，即：每个节点能容纳更多的数据， 这样就能降低树的高度，同时让逻辑上相邻的数据都能尽量存储在物理上也相邻的硬盘空间上，减少磁盘读写。



#### B+树

##### 介绍

B+ 树是 [B 树](https://oi-wiki.org/ds/b-tree/) 的一个升级，它比 B 树更适合实际应用中操作系统的文件索引和数据库索引。目前现代关系型数据库最广泛的支持索引结构就是 B+ 树。

##### 性质

B+树是B树的变种，但不同资料中B+树的定义各有不同，其差异在于节点中关键字个数和孩子节点个数。一种是节点中关键字个数和孩子个数相同，另一种是关键字个数比孩子节点个数小1，这种方式是和B树基本相同。

1. B+树包含2种类型的节点：内部节点（也称索引节点）和叶子节点。根节点本身即可以是内部节点，也可以是叶子节点。根节点的关键字key个数最少可以只有1个；
2. B+树与B树最大的不同是内部节点不保存数据，只用于索引，所有数据（或者说记录）都保存在叶子节点中；
3. m阶B+树表示了内部节点最多有m-1个关键字（或者说内部节点最多有m个子树，和B树相同），阶数m同时限制了叶子节点最多存储m-1个记录；
4. 内部节点中的key都按照从小到大的顺序排列，对于内部节点中的一个key，左树中的所有key都小于它，右子树中的key都大于等于它。叶子节点中的记录也按照key的大小排列；
5. 每个叶子节点都存有相邻叶子节点的指针，叶子节点本身依关键字的大小自小而大顺序链接；

##### 优势

由于索引节点上只有索引而没有数据，所以索引节点上能存储比 B 树更多的索引，这样树的高度就会更矮。树的高度越矮，磁盘寻道的次数就会越少。

因为数据都集中在叶子节点，而所有叶子节点的高度相同，那么可以在叶子节点中增加前后指针，指向同一个父节点的相邻兄弟节点，这样可以更好地支持查询一个值的前驱或后继，使连续访问更容易实现。

比如这样的 SQL 语句：`select * from tbl where t > 10`，如果使用 B+ 树存储数据的话，可以首先定位到数据为 10 的节点，再沿着它的 `next` 指针一路找到所有在该叶子节点右边的叶子节点，返回这些节点包含的数据。

而如果使用 B 树结构，由于数据既可以存储在内部节点也可以存储在叶子节点，连续访问的实现会更加繁琐（需要在树的内部结构中进行移动）。

> 由上边的 二叉查找树 引出数据库引擎。
>
> 像这种二叉树结构比较常见的使用场景是 Mysql 两种引擎，Myisam 使用的是 B 树，InnoDB 使用的是 B+树





## 一、java基础

### 1.1 基础

#### 1.1.1 面向对象的三大特征

**封装**

封装是指把⼀个对象的状态信息（也就是属性）隐藏在对象内部，不允许外部对象直接访问对象的内部信息。但是可以提供一些可以被外界访问的方法来操作属性。

**继承**

继承是使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能。通过使用继承，可以快速地创建新的类，可以提高代码的重用，程序的可维护性，节省大量创建新类的时间 ，提高我们的开发效率。

**多态**

方法的多态：重写和重载

对象的多态：一个对象的编译类型和运行类型可以不一致，运行类型可以是编译类型的子类



#### 1.1.2 JVM vs JDK vs JRE

JDK包含JRE，JRE包含JVM。

+ JVM：Java 虚拟机（JVM）是运行 Java 字节码的虚拟机
+ JRE：JRE 是 Java 运行时环境，但是不能创建java程序，主要包括 Java 虚拟机（JVM）、Java 基础类库（Class Library）。
+ JDK：JDK是java开发工具包，它拥有 JRE 所拥有的⼀切，还有 编译器（javac）和工具（如 javadoc 和 jdb）。它能够创建和编译程序。



#### 1.1.3 JAVA的 编译与解释并存

这是因为 Java 语言既具有编译型语言的特征，也具有解释型语言的特征。因为 Java 程序要经过先编译，后解释两个步骤，由 Java 编写的程序需要先经过编译步骤，生成字节码（ .class文件），这 种字节码必须由 Java 解释器来解释执行。

![image-20240813143858225](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202408131438330.png)



### 1.2 数据类型

#### 1.2.1 包装类的缓存机制

Byte , Short , Integer , Long 这 4 种包装类默认创建了数值 [-128，127] 的相应类型的缓存数 据， Character 创建了数值在 [0,127] 范围的缓存数据， Boolean 直接返回 True or False 。

实现的原理是int 在自动装箱的时候会调用Integer.valueOf，进而用到了 IntegerCache。

使用 valueOf 或者 自动装箱时才会去使用缓存的对象，如果直接 new 的话，还是新建对象。

![image-20240813144411075](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202408131444183.png)



#### 1.2.2 自动装箱与拆箱

+ 装箱：将基本类型用它们对应的引用类型包装起来； 

+ 拆箱：将包装类型转换为基本数据类型；



#### 1.2.3 == 和 equals()

== 对于基本类型和引用类型的作用效果是不同的： 

+ 对于基本数据类型来说， == 比较的是值。 
+ 对于引用数据类型来说， == 比较的是对象的内存地址。

> 因为 Java 只有值传递，所以，对于 == 来说，不管是比较基本数据类型，还是引用数据类型的变量，其本质比较的都是值，只是引用类型变量存的值是对象的地址。

equals() 方法存在两种使用情况： 

+ 类没有重写 equals() 方法 ：通过 equals() 比较该类的两个对象时，等价于通过“==”比较这两个对象，使用的默认是 Object 类 equals() 方法。 
+ 类重写了 equals() 方法 ：那么通过我们重写的方法逻辑来比较。



#### 1.2.4 hashCode()

**hashCode() 有什么用？**

hashCode() 的作用是获取哈希值，这个哈希码的作用是确定该对象在哈希表中的索引位置。

**那为什么两个对象有相同的 hashCode 值，它们也不一定是相等的？**

因为 哈希算法 可能会产生碰撞，就是两个不同对象的哈希值相同。

**为什么重写 equals() 时必须重写 hashCode() 方法？**

equals 方法判断两个对象是相等的，那这两个对象的 hashCode 值也要相等。

如果没有重写 hashcode 方法，可能会产生 两个对象 equals 相等，但是 hashcode 不相等的情况，这种情况下如果使用 hash 类型的数据结构会出现问题。比如 hashMap 中可能会有两个相等的 key。



#### 1.2.5 String和StringBuilder、StringBuffer的区别？

+ String：String 的值被创建后不能修改，任何对 String 的修改都会引发新的 String 对象的生成。 
+ StringBuffer：跟 String 类似，但是值可以被修改，使用 synchronized 来保证**线程安全**。 
+ StringBuilder：StringBuffer 的非线程安全版本，**性能上更高**一些。



#### 1.2.6 String为什么是不可变的？字符串拼接是如何实现的？

1. 保存字符串的数组被 final 修饰且为私有的，并且 String 类没有提供修改这个字符串的方法。 
2. String 类被 final 修饰导致其不能被继承，进而避免了子类破坏 String 不可变。

“+”的拼接操作，其实是会生成新的对象。Java会在编译期对“+”号进行处理，优化为基于 String Builder 的 append 方法进行拼接。

字符串拼接建议使用  String Builder 的 append 方法。



#### 1.2.7 String s1 = new String("abc");这句话创建了几个字符串对象？

+ 如果字符串常量池中不存在字符串对象“abc”的引用，那么会在堆中创建 2 个字符串对象“abc”。
  + 一个是字符串字面量 "abc" 所对应的、字符串常量池中的实例
  + 另一个是通过 new String() 创建并初始化的，内容与"abc"相同的实例，在堆中。
+ 如果字符串常量池中已存在字符串对象“abc”的引⽤，则只会在堆中创建 1 个字符串对象“abc”。

> 为什么在字符串常量池中创建一个常量：
>
> - **内存共享**：对于相同的字符串字面量，常量池中的对象是唯一的。这意味着 `"abc"` 这个字符串会被存储在常量池中，并在程序中多次使用时，不会重复创建新的对象，而是共享这个唯一的常量池中的对象。
> - **性能优化**：通过重用常量池中的对象，避免了频繁创建新的字符串对象，从而节省了内存和提高了性能。



#### 1.2.8 intern 方法有什么作用?

String.intern() 是⼀个 native（本地）方法，其作用是将指定的字符串对象的引用保存在字符串常量池中，可以简单分为两种情况： 

+ 如果字符串常量池中保存了对应的字符串对象的引用，就直接返回该引用。 
+ 如果字符串常量池中没有保存了对应的字符串对象的引用，那就在常量池中创建一个指向该字符串对象的引用并返回。









### 1.3 面向对象

#### 1.3.1 访问修饰符

+ public : 对所有类可见。可以修饰类、接口、变量、方法 
+ protected : 对同一包内的类和所有子类可见。可以修饰变量、方法。 注意：不能修饰类（外部类） 。
+ default (即默认，什么也不写）: 在同一包内可见，不使用任何修饰符。可以修饰在类、接口、变量、方法。 
+ private : 在同一类内可见。可以修饰变量、方法。 注意：不能修饰类（外部 类） 

![image-20240813153423882](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202408131534978.png)

#### 1.3.2 抽象类和接口的区别

首先呢，是在设计层面上，抽象类是对整个类整体进行抽象，包括属性、行为，但是接口却是对类的行为进行抽象。

其次是在语法层面上

- 抽象类可以提供成员方法的实现细节，而接口中只能存在 public abstract 方法（从 java8 开始接口可以有默认方法）；
- 抽象类中的成员变量可以是各种类型的，而接口中的成员变量只能是 public static final 类型的；
- 接口中不能含有静态代码块，而抽象类可以有静态代码块；
- 一个类只能继承一个抽象类，而一个类却可以实现多个接口。

抽象类和普通类的区别：

+ 普通类不能有抽象方法，抽象类可以有抽象方法
+ 抽象类不能被实例化，普通类可以



#### 1.3.3 深拷贝、浅拷贝和引用拷贝

+ 引用拷贝：引用拷贝就是两个不同的引用指向同一个对象。
+ 浅拷贝：浅拷贝会在堆上创建⼀个新的对象（区别于引用拷贝的⼀点），不过，如果原对象内部的属性是**引用类型**的话，浅拷贝会直接复制内部对象的引用地址，也就是说拷贝对象和原对象共用同⼀个内部对象。 
+ 深拷贝 ：深拷贝会完全复制整个对象，包括这个对象所包含的内部对象。



#### 1.3.4 java 是值传递还是引用传递

Java语言是值传递。Java 语言的方法调用只支持参数的值传递。当一个对象实例作为一个参数被传递到方法中时，参数的值就是对该对象的地址。

JVM 的内存分为堆和栈，其中栈中存储了基本数据类型和**引用数据类型实例的地址**，也就是对象地址。 而对象所占的空间是在堆中开辟的，所以传递的时候可以理解为把变量存储的对象地址给传递过去，因此引用类型也是值传递。



### 1.4 异常处理

#### 1.4.1 java 异常体系

![image-20240813202052972](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202408132020134.png)

Throwable 是 Java 语言中所有错误或异常的基类。 Throwable 又分为 Error 和 Exception 。

+ Error是系统内部错误，比如虚拟机异常和栈溢出，是程序无法处理的。 
+ Exception 是程序问题导致的异常，又分为两种： 
  + CheckedException受检异常：编译器会强制检查并要求处理的异常。 
  + RuntimeException运行时异常：程序运行中出现异常，比如我们熟悉的空指针、 数组下标越界等等

#### 1.4.2 异常处理

![image-20240813203042331](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202408132030439.png)

+ 遇到异常不进行具体处理，而是继续抛给调用者 （throw，throws）
  + throws 用在方法上，后面跟的是异常类，可以跟多个。
  + throw 用在方法内，一般用于主动抛出一个异常。

+ try-catch-finally、try-with-resources 捕获并处理异常



### 1.5 I/O

#### 1.5.1 IO流的分类

流按照不同的特点，有很多种划分方式。

+  按照流的流向分，可以分为 输入流 和 输出流 ； 
+ 按照操作单元划分，可以划分为 字节流 和 字符流 ； 
+ 按照流的角色划分为 节点流 和 处理流 

> 节点流 和 处理流
>
> + 节点流是底层流/低级流直接跟数据源相接。
> + 处理流(包装流)包装节点流，既可以消除不同节点流的实现差异，也可以提供更方便的方法来完成输入输出。
> + 处理流(也叫包装流)对节点流进行包装，使用了修饰器设计模式，不会直接与数据源相连[模拟==修饰器设计模式==]

Java Io流共涉及40多个类，看上去杂乱，其实都存在一定的关联， Java I0流的40多 个类都是从如下4个抽象类基类中派生出来的。 

+ InputStream / Reader : 所有的输入流的基类，前者是字节输入流，后者是字符输 入流。 
+ OutputStream / Writer : 所有输出流的基类，前者是字节输出流，后者是字符输出 流。

#### 1.5.2 I/O 流为什么要分为字节流和字符流呢

+ 字节流用于处理原始的字节数据。适合于处理二进制文件，如图像、音频、视频等。**字符流用于处理文本数据。适合于处理字符数据，如文本文件。
+ 字符流可以避免手动的编码和解码，字符流可以自动处理字符的编码和解码。

#### 1.5.3 BIO、NIO、AIO

见 操作系统

#### 1.5.4 序列化与反序列化

+ 序列化就是把Java对象转为二进制流，方便存储和传输。 
+ 反序列化就是把二进制流恢复成对象。

**Serializable接口有什么用？**

这个接口只是一个标记，没有具体的作用，但是如果不实现这个接口，在有些序列化场景会报错，所以一般建议，创建的JavaBean类都实现 Serializable。

**serialVersionUID 又有什么用？**

就是用于验证我们序列化后的对象有没有被修改，修改了的话，反序列化会失败。

**如果有些变量不想序列化，怎么办？**

对于不想进行序列化的变量，使用 transient 关键字修饰。

**序列化方式**

一般都是序列化为 JSON 对象，进行传输



### 1.6 反射

#### 1.6.1 什么是反射？应用？原理？

**什么是反射**

反射（Reflection）是 Java 提供的一种强大的功能，它允许程序在运行时动态地访问、修改和操作类的信息。通过反射，Java 程序可以在运行时检查类、接口、字段、方法以及构造函数等的元数据，并可以创建和操作对象，而不需要在编译时就知道它们的具体实现。

反射的核心类

![image-20240813221345223](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202408132213380.png)

**反射的应用场景**

一般我们平时都是在在写业务代码，很少会接触到直接使用反射机制的场景。

比如说动态代理的实现就是依赖于反射，invoke 方法就通过了反射类 Method 来调用指定的方法。

![image-20240813221550703](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202408132215824.png)

还比如说 spring boot 的自动配置原理，最终就是通过，在 META-INF/spring.factories 文件中的类的全限定名，来动态的加载 这些类到 Bean 工厂中。



### 1.7 JDK1.8

#### 1.7.1 新特性

![image-20240813222140292](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202408132221387.png)

+ 接口默认方法：Java 8允许我们给接口添加一个非抽象的方法实现，只需要使用 default关键字修饰即可 
+ Lambda 表达式和函数式接口：Lambda 表达式本质上是一段匿名内部类，也可以是一段可以传递的代码。Lambda 允许把函数作为一个方法的参数（函数作为参数传递到方法中），使用 Lambda 表达式使代码更加简洁，但是也不要滥用， 否则会有可读性等问题，《Effective Java》作者 Josh Bloch 建议使用 Lambda 表 达式最好不要超过3行。 
+ Stream API：用函数式编程方式在集合类上进行复杂操作的工具，配合Lambda 表达式可以方便的对集合进行处理。 Java8 中处理集合的关键抽象概念，它可以指定你希望对集合进行的操作，可以 执行非常复杂的查找、过滤和映射数据等操作。
+ 日期时间API：Java 8 引入了新的日期时间API改进了日期时间的管理。 
+ Optional 类：用来解决空指针异常的问题。很久以前 Google Guava 项目引入了 Optional 作为解决空指针异常的一种方式，不赞成代码被 null 检查的代码污染， 期望程序员写整洁的代码。受Google Guava的鼓励，Optional 现在是Java 8库的 一部分。





## 二、java集合

### 2.1 List

#### 2.1.1 ArrayList 的扩容机制

首先 ArrayList 可以初始化为指定大小容量，或者默认初始化容量10，不过如果是无参初始化的话是懒加载策略，只有第一次添加元素才真正的初始化为容量大小为10的数组。扩容就是当当前容量+1超过数组长度时，会创建一个1.5倍容量的新数组，然后把原数组的值拷贝上去。

#### 2.1.3 ArrayList 和 LinkedList 的区别

它们两个主要是底层使用的数据结构不一样，ArrayList 是动态数组，LinkedList 是双向链表。数据结构的不同是一切不同的根源。

1. 是否支持随机访问

+ ArrayList基于数组，所以它可以根据下标查找，支持随机访问，当然，它也实现了RandmoAccess 接口，这个接口只是用来标识是否支持随机访问。 
+ LinkedList基于链表，所以它没法根据序号直接获取元素，它没有实现 RandmoAccess 接口，标记不支持随机访问。

2. 内存占用，ArrayList基于数组，是一块连续的内存空间，LinkedList基于链表，内存空间不连续，它们在空间占用上都有一些额外的消耗：

+ ArrayList是预先定义好的数组，可能会有空的内存空间，存在一定空间浪费 
+ LinkedList每个节点，需要存储前驱和后继，所以每个节点会占用更多的空

3. 从线程安全来说，ArrayList和LinkedList都不是线程安全的

#### 2.1.4 ArrayList 和 LinkedList 不是线程安全的，你们在项目中是如何解决这个的线程安全问题的？

其实在我们的项目中我们使用 Arraylist 的时候都是在方法内使用的，都是局部变量不会出现线程安全问题。如果要在成员变量中使用的话，有几种方案：

+ 使用 Collections.synchronizedList 包装 ArrayList，然后操作包装后的 list。

```java
// 创建一个普通的 ArrayList
List<Integer> list = new ArrayList<>();

// 使用 Collections.synchronizedList 将其包装成线程安全的 List
List<Integer> synchronizedList = Collections.synchronizedList(list);
```

+ 使用 CopyOnWriteArrayList 代替 ArrayList。`CopyOnWriteArrayList` 是一个线程安全的替代方案，它在每次修改（如添加、删除元素）时都会创建一个新的数组副本。虽然这种方式会增加内存开销，但在读操作远多于写操作的场景中，性能表现非常好。

```java
// 使用 CopyOnWriteArrayList 代替 ArrayList
List<Integer> list = new CopyOnWriteArrayList<>();
```

+ 在使用 ArrayList 时，应用程序通过同步机制去控制 ArrayList 的读写。

```java
// 创建一个普通的 ArrayList
List<Integer> list = new ArrayList<>();

// 添加元素时进行同步控制
synchronized (list) {
    list.add(1);
    list.add(2);
}
```





### 2.2  Map

#### 2.2.0 HashMap 的初始化与懒加载

初始化的时候只会设置默认的负载因子，并不会进行其他初始化的操作，在首次使用的时候才会进行初始化。

当new一个新的HashMap的时候，不会立即对哈希数组进行初始化，而是在首次put元素的时候，通过resize()方法进行初始化。

#### 2.2.1 HashMap 内部的存储结构：

hashmap底层的数据结构是 **数组 + 链表 + 红黑树**。

数据元素通过hash函数计算出对应的在数组中的存储位置，如果发生冲突的话，就是用拉链法来解决冲突，当链表的长度大于8，并且数组的长度大于64的时候，链表会转化为红黑树，如果链表长度大于8，但是数组长度小于64，则会触发扩容。在移除数据的时候红黑树长度小于6会退化为链表。

#### 2.2.2 为什么使用红黑树，不用二叉查找树，或者平衡二叉树

+ 普通的二叉查找树，形状收到插入顺序的影响，可能导致最后的形状是链表，使得查找效率很低。

+ 平衡二叉树是比红黑树更严格的平衡树，为了保持保持平衡，需要旋转的次数更 多，也就是说平衡二叉树保持平衡的效率更低，所以平衡二叉树插入和删除的效率 比红黑树要低。

所以在查找效率和保持平衡的代价之间权衡最终选择红黑树。

#### 2.2.3 HashMap 的put流程

1. 判断键值对数组table是否为空或为null，否则执行resize()进行扩容（初始化）

2. 根据键值key通过扰动算法计算hash值得到数组索引`(key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);`（key.hashcode()的高16位与低16位取异或）

3. 判断table[i]==null，条件成立，直接新建节点添加

4. 如果table[i]==null ,不成立

  	4.1 判断table[i]的首个元素是否和key一样，如果相同直接覆盖value
  	
  	4.2 判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对
  	
  	4.3 如果不是树节点，表明当前桶为链表，遍历table[i]，链表的尾部（尾插法）插入数据，然后判断链表长度是否大于8，并且数组的长度是否大于64，大于的话把链表转换为红黑树，数组长度小于64的话则扩容。

5. 插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold（数组长度*0.75），如果超过，进行扩容。

#### 2.2.4 HashMap 的扰动函数是怎么设计的

HashMap的哈希函数是先拿到 key 的hashcode，是一个32位的int类型的数值，然后让 hashcode的高16位和低16位进行异或操作。

优点：使最终结果即和低位相关，又和高位相关。并且异或不同于与，或操作。结果1,0是均匀分布，可以减少hash冲突。

#### 2.2.5 HashMap 的容量为什么一定是2的倍数

1. 通过hashcode得到当前元素的数组下标的时候，可以通过对 length - 1 做与操作 来代替模运算，可以提高计算效率。
2. 数组扩容的时候，每次扩大一倍容量（换成二进制就是高位多了1），扩容后的元素的重新定位，直接判断最高位是1还是0来判断是否需要移动位置，移动位置的话就是 现在的下标 + 原数组长度。

#### 2.2.6 若是初始化的时候，大小指定的不是2的幂次方怎么处理？

变成比原值大的最近一个2的幂次方。

#### 2.2.7 为什么HashMap链表转红黑树的阈值为8呢？

其实转换为红黑树所占空间更大，空间换时间，是一种兜底策略。和统计学有关，理想情况下，使用随机哈希码，链表里的节点 符合泊松分布，出现节点个数的概率是递减的，节点个数为8的情况，发生概率仅为 0.00000006 。

至于红黑树转回链表的阈值为什么是6，而不是8？是因为如果这个阈值也设置成8， 假如hashmap的删除和插入操作频繁，节点增减刚好在8附近，会发生链表和红黑树的不断转换，导致资源浪费。

#### 2.2.8 扩容在什么时候呢？为什么扩容因子是0.75？

**扩容有三个地方**

1. 第一次对hashmap进行操作的时候，hashmap为空，需要进行一次resize(),默认大小16.

2. 若链表的长度大于等于8并且总数组大小小于64则进行一次resize()
3. 若是总的元素个数大于 元素个数 * 扩容因子。则进行一次resize()

**为什么是0.75**

这是一个经验值。

假如我们设的比较大，元素比较多，空位比较少的时候才扩容，那么发生哈希冲突的概率就增加了，查找的时间成本就增加了。

我们设的比较小的话，元素比较少，空位比较多的时候就扩容了，发生哈希碰撞的概率就降低了，查找时间成本降低，但是就需要更多的空间去存储元素，空间成本 就增加了。

#### 2.2.9 HashMap 的扩容机制

**扩容量**：每次扩容的时候，容量扩大一倍。（容量用二进制表示，就是原来的二进制高位再增加一位）。

**元素迁移**：只用判断扰动函数计算出的hash值对应位置（与新长度length - 1对应二进制的最高位）是否是1，若是1，则移动到新的位置（原位置=旧索引位置 + 旧容量）。不是则放在原来的位置。

#### 2.2.10 HashMap 是线程安全的吗？多线程下会有什么问题？

HashMap不是线程安全的，可能会发生这些问题： 

+ 多线程下扩容死循环。JDK1.7 中的 HashMap 使用头插法插入元素，在多线程的 环境下，扩容的时候有可能导致环形链表的出现，形成死循环。因此，JDK1.8 使用尾插法插入元素，在扩容时会保持链表元素原本的顺序，不会出现环形链表 的问题。
+ 多线程的 put 可能导致元素的丢失。多线程同时执行 put 操作，如果计算出来的 索引位置是相同的，那会造成前一个 key 被后一个 key 覆盖，从而导致元素的丢 失。此问题在 JDK 1.7 和 JDK 1.8 中都存在。 
+ put 和 get 并发时，可能导致 get 为 null。线程 1 执行 put 时，因为元素个数超出 threshold 而导致 rehash，线程 2 此时执行 get，有可能导致这个问题。这个问题 在 JDK 1.7 和 JDK 1.8 中都存在。

#### 2.2.11 有什么办法能解决HashMap线程不安全的问题呢？

Java 中有 HashTable、Collections.synchronizedMap、以及 ConcurrentHashMap 可以实 现线程安全的 Map。 

+ **遗留的安全集合（不推荐使用）**：HashTable 是直接在操作方法上加 synchronized 关键字，锁住整个table数组，粒 度比较大； 
+ **修饰的安全集合（不推荐使用，内部也是synchronized ）**：Collections.synchronizedMap 是使用 Collections 集合工具的内部类，通过传入 Map 封装出一个 SynchronizedMap 对象，内部定义了一个对象锁，方法内通过对 象锁实现； 
+ **JUC安全集合**：ConcurrentHashMap 在jdk1.7中使用分段锁，在jdk1.8中使用CAS+synchronized。

#### 2.2.12 ConcurrentHashmap的实现

1. concurrentHashmap在jdk1.7的时候，使用的是分段锁（reentrantlock 锁住一个segment数组）
   + 大小数组，大数组是segment，每个segment包含一个HashEntry数组，每个HashEntry又是一个链表结构的元素，对同一个segment相关操作用reentrantlock 加锁。多个segment之间操作可以并发执行。但是Segment 的个数⼀旦初始化就不能改变。 Segment 数组的大小默认是 16，也就是说默认可以同时⽀持 16 个线程并发写。
2. jdk1.8后用的cas和synchronized实现。
   + 若是Node结点没有分配就使用CAS，若是已经分配了就使用synchronized加锁，锁住当前链表或者红红黑树的首节点，这样只要 hash 不 冲突，就不会产生并发，就不会影响其他 Node 的读写，效率⼤幅提升。



#### 2.2.13 LinkedHashMap

LinkedHashMap 是 Java 中的一种特殊的 Map 实现，它继承自 HashMap 类，并且保留了插入顺序。在 LinkedHashMap 中==，每个条目（键值对）都保留了一个指向其前一个条目和后一个条目的指针，这样就形成了一个双向链表==。这个双向链表可以确保元素在迭代时按照插入顺序进行访问。

LinkedHashMap 与普通的 HashMap 相比，多了一个特性就是它保留了插入顺序。这意味着当你迭代一个 LinkedHashMap 时，你会按照元素插入的顺序来获取元素，而不是按照键的哈希值顺序或其他顺序。这种特性在某些场景下非常有用，例如需要维护一个键值对的顺序，或者需要实现 LRU（Least Recently Used）缓存等。







## 三、java并发



### 3.1 多线程基础

#### 3.1.1 线程的生命周期和状态

![image-20240711154740546](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407111547752.png)

分别是

* NEW：当一个线程对象被创建，但还未调用 start 方法时处于**新建**状态
* RUNNABLE：调用了 start 方法，就会由**新建**进入**可运行**
* TERMINATED：线程内代码已经执行完毕，由**可运行**进入**终结**
* BLOCKED：当获取锁失败后，由**可运行**进入**阻塞**状态，等待其他线程释放锁
* WAITING：成功获取锁的线程，由于调用了 wait() 或者别的方法（join()方法，park()方法），此时从**可运行**状态进入等待状态，等待其他线程的特定操作。
* TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样⼀直等待

#### 3.1.2 run() 和 start() 的区别

调用start()方法的作用是启动线程，让线程状态由 new 变为 runnable 表示线程准备就绪可以运行了，而调用 run() 方法表示 并不把它当作多线程方法调用，而是非多线程的正常方法调用。

#### 3.1.3 wait()方法 和 sleep()方法 有什么区别

共同点：

+ 两个方法都可以暂停当前线程的执行。不过 sleep() 方法 和 带参数的 wait(long) 方法是让线程进入 TIMED_WAITING 状态，而 不带参数的 wait() 方法是让线程进入 WAITING 状态。

不同点：

根本上的不同：wait() 通常被用于线程间交互/通信， sleep() 通常被用于暂停执行

+ sleep() 是 Thread 的静态方法，而 wait() 是 Object 的成员方法
+ wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象的 notify() 或者 notifyAll() 方法。带参数的 wait 方法 和 sleep 方法会在等待响应的时间后自动唤醒。
+ wait 方法的调用必须先获取 wait 对象的锁，wait 方法执行后会释放对象锁，允许其它线程获得该对象锁，而 sleep 如果在 synchronized 代码块中执行，并不会释放对象锁



### 3.2 多线程安全

#### 3.2.1 CAS

CAS 就是 **Compare And Swap（比较与交换）** ，用于实现乐观锁。CAS 的思想很简单，就是用一个预期值和要更新的变量值进行比较，两值相等才会进行更新。不相等时会进行自旋操作。

CAS 涉及到三个操作数：

- **V**：要更新的变量值(Var)
- **E**：预期值(Expected)
- **N**：拟写入的新值(New)

当且仅当 V 的值等于 E 时，CAS 通过原子方式用新值 N 来更新 V 的值。如果不等，说明已经有其它线程更新了 V，则当前线程放弃更新。

当多个线程同时使用 CAS 操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。

> Java 语言并没有直接实现 CAS，CAS 相关的实现是通过 C++ 内联汇编的形式实现的（JNI 调用）。因此， CAS 的具体实现和操作系统以及 CPU 都有关系。

>  `sun.misc`包下的`Unsafe`类提供了`compareAndSwapObject`、`compareAndSwapInt`、`compareAndSwapLong`方法来实现的对`Object`、`int`、`long`类型的 CAS 操作。

**CAS 存在的问题：**

1. ABA问题：

   一个值初次读取的时候是 V，赋值的时候还是 V，并不能说明它没有改变过。可能修改了两次又变回了原值。解决方法： **加上版本号**

2. 循环时间长开销大：

   CAS 经常会用到自旋操作来进行重试，也就是不成功就一直循环执行直到成功。如果长时间不成功，会给 CPU 带来非常大的执行开销。



#### 3.2.2 乐观锁与悲观锁

悲观锁认为安全问题一定会发生，因此要在操作数据前先获取锁，确保线程串行执行。典型实现：syncronized 。因为悲观锁的性能比较差，所以一般都是在竞争激烈的场景下才会使用悲观锁。

乐观锁认为安全问题不一定会发生，所以它不加锁，只在更新数据的时候去判断是否有其他线程修改了数据。典型实现 CAS，版本号机制。乐观锁的性能比较好，但是在多竞争的场景下可能会导致程序不断的自旋操作，所以乐观锁通常用于竞争较少的场景下。



#### 3.2.3 synchronized

synchronized 主要解决的是多个线程之间访问资源的同步性，可以保 证被它修饰的方法或者代码块在任意时刻只能有⼀个线程执行。 在 Java 早期版本中， synchronized 属于 重量级锁，效率低下。 因为监视器锁（monitor）是依赖于 底层的操作系统的互斥锁 来实现的，需要频繁的内核态和用户态的转换。

 不过，在 Java 6 之后，Java 官方对从 JVM 层面对 synchronized 优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6 对锁的实现引⼊了大量的优化，如自旋锁、适应性 自旋锁、偏向锁、轻量级锁等技术来减少锁操作的开销。

##### 3.2.3.1 synchronized的使用

+ 修饰实例方法 （锁当前对象实例）
+ 修饰静态方法 （锁当前类）
+ 修饰代码块 （锁指定对象/类）

##### 3.2.3.2 synchronized 重量级锁（monitor） 底层原理

重量级锁的底层由monitor实现的，线程获得锁需要使用对象（锁）关联monitor，在monitor内部有三个属性，分别是owner、entrylist、waitset。其中owner是关联的获得锁的线程，并且只能关联一个线程；entrylist关联的是处于阻塞状态的线程；waitset关联的是处于Waiting状态的线程。monitor指令的执行是JVM通过调用操作系统的互斥原语mutex来实现，被阻塞的线程会被挂起、等待重新调度，会导致“用户态和内核态”两个态之间来回切换，对性能有较大影响。

##### 3.2.3.3 锁升级

JDK1.6之后的 Java中的synchronized有无锁、偏向锁、轻量级锁、重量级锁四种形式，且四种状态会随着竞争的情况逐渐升级，而且是不可逆的过程。

![output](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407112215282.png)

##### 匿名偏向

在程序启动一段时间（可以通过 JVM 参数配置）之后，新建的对象的对象空间的对象头中（markword）都会被设置为偏向锁的类型，不过因为还没有线程占用它，所以markword中的 threadId 先为空，所以称为匿名偏向。在这段时间之前创建的的对象markword为无锁的状态。

##### 偏向锁

当执行到synchronized代码块时，无锁状态的对象会变成偏向锁，匿名偏向也会被赋值threadId，当然偏向锁可以通过 JVM 配置关闭，如果关闭就直接成为轻量级锁。或者当前对象执行过 hashcode 方法，也会禁用偏向锁，因为 非偏向锁的类型，在 markword 部分会保存一个hashcode字段，这个字段初始化为 空，执行完 hashcode 会被赋值，一旦被赋值就会禁用 偏向锁，因为偏向锁的 markword 部分没有 hashcode 字段。

当一个线程访问同步代码块并获取锁时，会在 Mark Word 里存储锁偏向的线程 ID。在线程进入和退出同步块时不再通过 CAS 操作来加锁和解锁，而是检测 Mark Word 里是否存储着指向当前线程的偏向锁。轻量级锁的获取及释放依赖多次 CAS 原子指令，而偏向锁只需要在置换 ThreadID 的时候依赖一次 CAS 原子指令即可。这也是为什么轻量级锁比偏向锁的级别更高。

偏向锁只适用于只有一个线程执行同步代码块的情况，一旦有第二个线程进入，偏向锁就会升级为轻量级锁。 

##### 轻量级锁（自旋锁）

轻量级锁的实现和偏向锁的差别不大，都是在线程栈中创建一个 Lock Record 对象，只不过偏向锁是在 markword 字段存储偏向锁的线程 id ，而轻量级锁的 markword 是存储 lock Record 的地址，所以这也导致了 轻量级锁的 每次重入 都要进行一次 CAS 操作。

在轻量级锁状态下继续锁竞争，没有抢到锁的线程将自旋，进入忙等状态。此忙等是有限度的（有个计数器记录自旋次数，默认允许循环10次，可以通过虚拟机参数更改）。如果锁竞争情况严重，某个达到最大自旋次数的线程，会将轻量级锁升级为重量级锁。当后续线程尝试获取锁时，发现被占用的锁是重量级锁，则直接将自己挂起（而不是忙等），等待将来被唤醒。

重量级锁是指当有一个线程获取锁之后，其余所有等待获取该锁的线程都会处于阻塞状态。简言之，就是所有的控制权都交给了操作系统，由操作系统来负责线程间的调度和线程的状态变更。而这样会出现频繁地对线程运行状态的切换，线程的挂起和唤醒，从而消耗大量的系统资。



#### 3.2.4 JMM （Java内存模型）

JMM就是Java的内存模型，是一种抽象的概念，并不真实存在，它规定了 Java 程序中多线程并发访问共享内存的规则。

Java 内存模型（JMM）本质上是为了解决多线程环境下内存可见性问题、指令重排序问题和线程间操作的有序性问题。它通过一系列的规范（如 **happens-before** 原则）以及语言级别的工具（如 `volatile`、`synchronized` 等）来实现这些目标。

可见性、原子性和有序性。

具体而言就是每个线程有自己的工作内存，所有线程都共享主内存。当我们要同步更新共享变量的值的时候，JMM规定在加锁前，必须读取主内存中的最新变量值到当前线程的工作内存中，然后在线程解锁前，必须把共享变量写回主内存中，以此来确保线程间的安全性和可见性。



#### 3.2.5 volatile

##### 3.2.5.1 介绍一下volatile

volatile用于修饰变量，可以用来保证可见性与有序性，但volatile不保证volatile变量的原子性。

**可见性问题**：可见性问题指的是，线程一开始读取了变量的值到自己的工作内存中，因为线程要频繁的访问这个变量，那么 JIT 编译器会把这个变量的值缓存到自己的工作内存中，后面即使主内存中的变量值被改变了，但是线程依然会在自己的工作内存中读取它的旧值，这就导致了可见性问题。其实可见性问题也可以直接用 JVM 参数关闭 JIT 来解决。

**可见性问题解决**：volatile关键字会强制 在读取这个变量的时候就会强制去主内存中读取这个变量的值，在写操作之后就会强制将最新的值写入主内存中，这样来实现可见性。

**有序性问题：**有序性问题指的是，JVM会在不影响结果的前提下，进行指令重排。但是在多线程模式下这样肯定会带来问题。

**有序性问题解决：**volatile会通过插入内存屏障来禁止指令重排，具体来说在对变量的写操作前会插入写屏障，会确保指令重排的时候，不会将写屏障前的代码排在写屏障之后。在读操作后加入读屏障，确保读屏障后的代码不会重排到读屏障之前。



##### 3.2.5.2 单例模式DCL中的 volatile

单例模式：该模式只会有一个实例对象。

volatile有个比较经典的应用就是双层校验锁的单例模式DCL（double check lock）单例

```java
class A{
    private volatile static A uniqueInstance;
    private A(){}
    public static A getuniqueInstance(){
        if(uniqueInstance == null){//第一层检查可以减少所有的线程都加锁，减少了锁的粒度
            syncronized(A.class){
                if(uniqueInstance == null){
                    uniqueInstance = new A();
                }
            }
        }
        return uniqueInstance;
    }
}
```

双层校验锁：为了减少 syncronized 锁住的范围。

若不加volatile则多线程情况下，对象初始化和引用指向地址这步骤可能发生指令重排，导致得到该单例的线程，这个单例是没有完全初始化的。



##### 3.2.5.1 syncronized  和 volatile 对比

- 使用：volatile修饰变量，synchronized修饰方法或者代码块
- 功能：volatile只能实现可见性有序性不能实现原子性，syncronized三个都能实现。
  - 实现可见性的原理是相同的。修改线程本地内存的变量后直接刷新到主内存，然后其他线程本地内存需要读该数据，先从主内存中读。底层都是使用内存屏障来完成。
- 原理：实现有序性原理不太一样，volatile是使用内存屏障来抑制指令重排，而syncronized不能抑制执行指令重排和处理器优化，但是单线程满足as if serial语义（不论怎么重排，最终的结果不能够改变）。



#### 3.2.6 AQS

##### 3.2.6.1 介绍一下 AQS

全称是抽象队列同步器 AbstractQueuedSynchronizer，是JUC中构建锁或者其他同步组件的基础框架。AQS 就是一个抽象类，AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 **CLH 队列锁** 实现的，即将暂时获取不到锁的线程加入到队列中。



1. 提供了一个volatile修饰的 int变量 state来表示资源抢占状态，`volatile`保证线程之间对它可见性；不同线程通过CAS来改变state；state等于0表示锁没有被占有，1表示被占有，大于1表示同一个线程多次占有锁（锁可重入）。
2. 使用了一个FIFO双向队列，来存储没有抢占到资源而被阻塞的线程。结点代表线程thread。

> AQS 既可以是 共享锁 也可以是 独占锁，既可以是 公平锁 也可以是 非公平锁

##### 3.2.6.2 Reentranlock

ReentrantLock主要利用CAS+AQS队列来实现。它同时支持公平锁和非公平锁，通过构造方法接受一个可选的公平参数（默认非公平锁），当设置为true时，表示公平锁，否则为非公平锁。公平锁则体现在所有的线程按照先后顺序获取锁，非公平体现在不在排队的线程也可以抢锁。

其他方面基本就是AQS的实现了：

- 线程来抢锁后使用cas的方式修改state状态，修改状态成功为1，则让exclusiveOwnerThread属性指向当前线程，获取锁成功；
- 假如修改状态失败，则会进入双向队列中等待；
- 当exclusiveOwnerThread为null的时候，则会唤醒在双向队列中等待的线程；

> **公平锁与非公平锁**
>
> **公平锁** : 锁被释放之后，先申请的线程先得到锁。性能较差一些，因为公平锁为了保证时间上的绝对顺序，上下文切换更频繁。
>
> **非公平锁**：锁被释放之后，后申请的线程可能会先获取到锁，是随机或者按照其他优先级排序的。性能更好，但可能会导致某些线程永远无法获取到锁。

##### 3.2.6.3 （Lock）Reentranlock 和 syncronized 的对比

* 语法层面
  * synchronized 是关键字，源码在 jvm 中，用 c++ 语言实现
  * Lock 是接口，源码由 jdk 提供，用 java 语言实现
  * 使用 synchronized 时，退出同步代码块锁会自动释放，而使用 Lock 时，需要手动调用 unlock 方法释放锁
* 功能层面
  * 二者均属于悲观锁，但是 Lock 提供了许多 synchronized 不具备的功能，例如获取公平锁、可打断、多条件变量
  * Lock 有适合不同场景的实现，如 ReentrantLock， ReentrantReadWriteLock
* 性能层面
  * 在没有竞争时，synchronized 做了很多优化，如偏向锁、轻量级锁，性能不赖
  * 在竞争激烈时，Lock 的实现通常会提供更好的性能

> **可中断锁和不可中断锁有什么区别？**
>
> - **可中断锁**：获取锁的过程中可以被中断，不需要一直等到获取锁之后 才能进行其他逻辑处理。`ReentrantLock` 就属于是可中断锁。
> - **不可中断锁**：一旦线程申请了锁，就只能等到拿到锁以后才能进行其他的逻辑处理。 `synchronized` 就属于是不可中断锁。

##### 3.2.6.4  如何控制某个方法允许并发访问线程的数量？（Semaphore）

在juc中提供了一个Semaphore[seməfɔːr]类（信号量），其实就和操作系统中的信号量是相同的机制。我们在需要控制并发量的线程中使用，在进入线程前先定义能并发的最大数量，在线程中先用semaphore.acquire() 请求信号量，一个线程获取了信号量则信号量数量减一，到0的时候就不许其他线程获取信号量了，使用semaphore.release()方法，可以释放信号量。

##### 3.2.6.4  如何控制线程的同步？（Semaphore）

两种方法：1. CountDownLatch等待线程完成 2. Future 类接受线程返回数据

CountDownLatch（闭锁/倒计时锁）用来进行线程同步协作，等待所有线程完成，初始化需要等待的线程数，然后每个线程结束调用countDown() 用来让计数减一，等待计数为0，调用了await() 方法的线程就可以继续执行。

Future 类的get方法可以等待我们的线程数据返回后，获取这个数据然后继续执行。



#### 3.2.7 并发程序出现问题的根本原因

根本原因就是 没有满足 Java 并发编程三大特性中的一个或者多个：

- **原子性**：即一个操作或者多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。解决：synchronized，或者 JUC 里的 Lock；

- **可见性**：让一个线程对共享变量的修改对另一个线程可见。解决：synchronized、volatile、Lock；

- **有序性**：处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。在多线程下，会出现问题。解决：volatile；



### 3.3 线程池

#### 3.3.1 线程池的核心参数

线程池就是管理一系列线程的资源池。当有任务要处理时，直接从线程池中获取线程来处理，而不是每次都新建线程，这样可以显著的优化处理速度，处理完之后线程并不会立即被销毁，而是等待下一个任务。线程池核心参数主要参考ThreadPoolExecutor这个类的7个参数的构造函数

- corePoolSize 核心线程数目

- maximumPoolSize 最大线程数目 = (核心线程+救急线程的最大数目)

- keepAliveTime 生存时间：救急线程的生存时间，生存时间内没有新任务，此线程资源会释放

- unit 时间单位 - 救急线程的生存时间单位，如秒、毫秒等

- workQueue - 当没有空闲核心线程时，新来任务会加入到此队列排队，队列满会创建救急线程执行任务

- threadFactory 线程工厂 - 可以定制线程对象的创建，例如设置线程名字、是否是守护线程等

- handler 拒绝策略 - 当所有线程都在繁忙，workQueue 也放满时，会触发拒绝策略

#### 3.3.2 线程池的工作流程

![image-20240713164511253](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407131645425.png)

1，任务在提交的时候，首先判断核心线程数是否已满，如果没有满则直接添加到工作线程执行

2，如果核心线程数满了，则判断阻塞队列是否已满，如果没有满，当前任务存入阻塞队列

3，如果阻塞队列也满了，则判断线程数是否小于最大线程数，如果满足条件，则使用临时线程执行任务

如果核心或临时线程执行完成任务后会检查阻塞队列中是否有需要执行的线程，如果有，则使用非核心线程执行任务

4，如果所有线程都在忙着（核心线程+临时线程），则走拒绝策略



#### 3.3.3 拒绝策略

1.AbortPolicy：直接抛出异常，默认策略；

2.CallerRunsPolicy：用调用者所在的线程来执行任务；

3.DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务；

4.DiscardPolicy：直接丢弃任务；



#### 3.3.4 常用的阻塞队列

比较常见的有4个，用的最多是ArrayBlockingQueue和LinkedBlockingQueue

1.ArrayBlockingQueue：基于数组结构的有界阻塞队列，FIFO。需要在初始化的时候指定长度。

2.LinkedBlockingQueue：基于链表结构的有界阻塞队列，FIFO。默认长度为 Integer.MAX_VALUE，默认长度创建的话，可能会堆积大量的请求，导致OOM。

3.DelayedWorkQueue ：是一个优先级队列，可以自定义比较器。

4.SynchronousQueue：不存储元素的阻塞队列，每个插入操作都必须等待一个移出操作。



#### 3.3.5  常见的线程池有那些，为什么不推荐使用Executors创建线程池

FixedThreadPool：固定线程数的线程池

SingleThreadExecutor：单线程化的线程池

CachedThreadPool：可缓存线程池

ScheduledThreadPool：可定时执行的线程池

`Executors` 返回线程池对象的弊端如下：

- `FixedThreadPool` 和 `SingleThreadExecutor`:使用的是有界阻塞队列是 `LinkedBlockingQueue` ，其任务队列的最大长度为 `Integer.MAX_VALUE` ，可能堆积大量的请求，从而导致 OOM。
- `CachedThreadPool`:使用的是同步队列 `SynchronousQueue`, 允许创建的线程数量为 `Integer.MAX_VALUE` ，如果任务数量过多且执行速度较慢，可能会创建大量的线程，从而导致 OOM。
- `ScheduledThreadPool` :使用的无界的延迟阻塞队列 `DelayedWorkQueue` ，任务队列最大长度为 `Integer.MAX_VALUE` ，可能堆积大量的请求，从而导致 OOM。



#### 3.3.6 如何设定线程池的大小

线程池的大小根据任务类型不同也有不同的配置策略，但是这种预定义线程池大小的策略总归是静态的，很难直接估计出一个合理的参数，现在有很多动态配置线程池参数的设计，有一个简单并且适用面比较广的公式：

- **CPU 密集型任务(N+1)：** 这种任务消耗的主要是 CPU 资源，可以将线程数设置为 N（CPU 核心数）+1。比 CPU 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。为了防止防止上下文切换带来的消耗，所以 cpu 密集型任务 一般设置为 和 cpu 核数相等。
- **I/O 密集型任务(2N)：** 这种任务应用起来，系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。因此在 I/O 密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 2N。

> 上下文切换：
>
> 多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。**任务从保存到再加载的过程就是一次上下文切换**。



#### 3.3.7 动态线程池的原理

**动态调整线程池的参数，成熟的轮子有dynamic-tp等。**

主要的原理：

1. **监听模块：**从配置中心中获取可以动态改变的线程池参数。
2. **线程池管理模块：**java线程池的类（`ThreadPoolExecutor`）中提供了可以修改核心线程数、最大线程数、存活时间、拒绝策略等参数修改的接口，在配置中心中修改对应的数值后，**线程池管理模块**就会调用对应的接口进行动态修改。

![img](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407131826464.png)

 3. 但是线程池类（`ThreadPoolExecutor`）中没有提供修改阻塞队列大小的方法，但是很多动态线程池的组件都可以修改，原理是它重写了阻塞链表队列这个类，把队列大小这个值是个final类型，删除了final并且提供了修改大小的接口。

**平滑过渡**

以setCorePoolSize()为例子

 - 先覆盖旧值corePoolSize
 - 若是新值小于原来的值，则会让处于闲置（idle）状态的线程（worker）发起中断请求。
 - 若是新值大于原来的值，则会创建worker线程去执行阻塞队列的任务。



### 3.4 ThreadLocal

#### 3.4.1 ThreadLocal

ThreadLocal 主要是解决在多线程环境下的共享变量的隔离，并且实现在线程内的资源共享。比较经典的例子就是用于保存用户登录信息，这样每个线程可以保存自己的用户信息，并且在同一个线程中的任何地方都可以获取到登录信息。但是我的项目中并没有这样使用过ThreadLocal，因为我们使用了成熟的安全框架，比如shiro和springsecurity，都内置了获取用户信息的方式。

#### 3.4.2 ThreadLocal的原理

- threadlocal不存储对应的本地变量值，它是存在线程中的。每个线程中有一个叫`threadLocalMap`的数据结构，它的key是一个`threadLocal`对象的弱引用，value是需要隔离的本地变量。
- 当执行`threadlocal.set()`的时候，底层会拿到当前执行线程的`threadlocalmap`然后将当前`threadlocal`的弱引用设置为key，需要隔离的变量设置为value。
- 当执行`threadlocal.get()`的时候，从`threadlocalmap`中通过threadlocal作为key得到对应的map。

#### 3.4.3 ThreadLocal内存泄漏

`ThreadLocalMap` 中使用的 key 为 `ThreadLocal` 的弱引用，而 value 是强引用。所以，如果 `ThreadLocal` 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。

这样一来，`ThreadLocalMap` 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。`ThreadLocalMap` 实现中已经考虑了这种情况，在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 `ThreadLocal`方法后最好手动调用`remove()`方法。

> 强引用：我们最常见使用的引用，只有当强引用为null的时候才会触发GC。
>
> 软引用：使用`SoftReference`声明，当JVM内存将要发生OOM的时候会回收对应的对象。
>
> 弱引用：使用`WeakReference`声明，当JVM发生GC（各种GC）的时候，就会回收该对象。
>
> 虚引用：无法使用虚引用来使用对应的对象实例，它存在的作用是GC的时候会发送一个系统通知。

##### 3.4.3.1 key为什么设置为弱引用

- 若是把key设置成强引用，那么当threadlocalMap外面threadlocal强引用设置为空了，这时候threadlocalMap里面的key其实已经访问不到了，但是因为是强引用，导致不能通过gc得到及时的删除。造成内存泄漏。
- 设置成弱引用，当不存在强引用了，在最近一次GC对象就会被回收，threadlocalMap中对应的key为null了，然后下一次调用get(),set(),remove()的时候，会删除key为null的value值。



#### 3.4.5 threadLocalMap的结构

ThreadLocalMap 它是一个定制的哈希表，专门用于保存每个线程中的线程局部变量。ThreadLocalMap 内部维护了一个 Entry 类型的数组，初始化长度为16，每次扩容为两倍的大小，加载因子为三分之二，解决哈希冲突的方式是线性探测，内部的hashcode方法使用了**斐波那契数**作为hash的计算因子，大大减少了冲突的概率。



### 3.5 ==我的项目中的线程池使用==

超限治理系统中：因为一超四罚（驾驶员、车辆、车辆所属企业、订单委托企业）政策的存在，所以治超系统大屏需要一个联动效果，左边展示了所有的超限车辆名单（车牌，时间，地点），点击某辆车的信息，右侧要展示 一超四罚的信息（人、车辆、车辆所属企业），所有信息都要使用大件运输许可的接口数据排除。

人和车辆的超限信息在我们单位的治超部门的数据库中，企业信息是在执法大队的数据库中，驾驶人黑名单是在我们自己的数据库中（因为这是我们自己定义的标准，不是官方的标准，当一个司机上个月超限超过三次加入黑名单），还有一个大件运输许可的接口数据。

原本的串行获取数据，再计算逻辑接口时间基本在两秒多，使用线程池和Future类来并行获取每个线程数据，接口速度优化到几百毫秒。具体实现就是定义了一个ExecutorService的Bean，使用线程池的submit方法来提交任务，然后用Future接收返回值，用Future的get方法获取结果。后面再进行逻辑处理。

#### 3.5.1 具体要获取那些信息呢

具体来说就是这个驾驶员 本月的的超限次数，平均超限百分比，联系方式，是否为黑名单成员；
车辆的超限次数，平均超限的百分比，车辆允许最大载重，实际承载最大重量；
车辆所属企业的，超限次数，拥有车辆数，联系人方式（企业重点关注的是超限车次占拥有车辆的百分比）；

#### 3.5.2 涉及哪些数据库，为什么不在一个数据库中

本接口涉及了，三个数据库，一个接口信息，我们单位治超部门的数据库，我们信息中心的数据库，执法大队的数据库，大件运输许可的接口。因为公路局的治超部门的主要任务是防止超重车辆压坏道路、桥梁这种道路基础设施，治超的执法权并不在公路局。所以我们的治超部门只有基本的超限信息，而执法大队则包含着比较全面的信息，包括物流企业的信息。使用了我们自己的数据库是因为这个黑名单的功能是我们自己设计的，不是官方标准，就用了自己的数据库存储。大件运输许可这个我也不清楚，我只知道他们那边这个数据只有接口提供。

#### 3.5.3 线程池的参数如何设计的

在接口中，用了线程池进行优化
主要的参数：
- 核心线程数选择的128，最大线程数选择的128（因为项目部署的服务器的64核的，然后处理的任务是获取不同数据源数据，本质是网络IO。所以选择了经验值2 * 8。）
- 阻塞队列选择的是链表阻塞队列，大小1024，这个是经验值。
- 拒绝策略选择是任务调用线程去执行。





## 四、JVM

JVM——Java虚拟机，它是Java实现平台无关性的基石。

 Java程序运行的时候，编译器将Java文件编译成平台无关的Java字节码文件（.class）, 接下来对应平台JVM对字节码文件进行解释，翻译成对应平台匹配的机器指令并运行.

### 4.1 JVM 内存区域

#### 4.1.1 内存区域的组成

![image-20240726150523979](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407261505098.png)

运行时数据区域：

1. 线程共有：堆，方法区
2. 线程私有：虚拟机栈、本地方法栈、程序计算器PC

- 堆：储存对象实例、数组、字符串常量池等

  - 新生代：edge区，surviver区：
  - 老年代：到达一定条件，对象会从新生代进入老年代。
  - 永久代：JDK 8 版本之后 PermGen(永久代) 已被 Metaspace(元空间) 取代，元空间使用的是本地内存。
  - 字符串常量池：（JDK7 时从方法区移动到堆中）主要目的是为了避免字符串的重复创建。

- 方法区：存储已被虚拟机加载的类相关信息（类信息、字段信息、方法信息、常量、静态变量、即时编译器编译后的代码缓存等数据。）、运行时常量池等。

  - 运行时常量池：各种字面量和符号引用的常量池表 。
  - JDK 8 之前实现方式为 堆中的永久代，JDK 8 开始用元空间实现并且存储在本地内存中。

- 虚拟机栈：主要是存放一般方法执行时候的数据。每一次方法调用都会有一个对应的栈帧被压入栈中，每一个方法调用结束后，都会有一个栈帧被弹出。每个栈帧都有：

  - 局部变量表（基本数据类型的值或者对象引用）

  - 操作数栈（方法执行过程中产生的中间计算结果或临时变量）

  - 动态链接（调用其他函数相关）

  > 动态链接部分包含一个指向方法区（或元空间）中常量池的引用，这个常量池包括了方法和字段的符号引用。然后再方法执行的时候，动态链接会被解析为直接引用。

  - 方法返回地址 

- 本地方法栈：存放native方法执行时候的相关数据。

- 程序计数器：记录下一条指令地址，从而实现代码的流程控制。

##### 4.1.1.1 为什么要将永久代 替换为元空间呢?

降低OOM风险：整个永久代有一个 JVM 本身设置的固定大小上限，无法进行调整（也就是受到 JVM 内存的限制），而元空间使用的是本地内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小。



##### 4.1.1.2 JDK 1.7 为什么要将字符串常量池移动到堆中？

主要是因为永久代（方法区的实现）的 GC 回收效率太低，只有在整堆收集 (Full GC)的时候才会被执行 GC。Java 程序中通常会有大量的被创建的字符串等待回收，将字符串常量池放到堆中，能够更高效及时地回收字符串内存。



#### 4.1.2 虚拟机中的对象

##### 4.1.2.1 对象的创建

在JVM中对象的创建，虚拟机遇到new指令开始：

+ 类加载检查：首先检查这个指令的参数是否能在自己的运行时常量池中定位到一个类的符号引用，检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，就先执 行相应的类加载过程 
+ 内存分配：类加载检查通过后，接下来虚拟机将为新生对象分配内存。 **分配方式**有 **“指针碰撞”** 和 **“空闲列表”** 两种。
+ 初始化零值：内存分配完成之后，虚拟机将分配到的内存空间（但不包括对象头）都初始化为零值。 
+ 设置对象头：对象头里包含了对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。
+ 执行 init 方法



##### 4.1.2.2 内存的分配方式

分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。

**内存分配的两种方式** ：

- 指针碰撞： 
  - 适用场合：堆内存规整（即没有内存碎片）的情况下。
  - 原理：用过的内存全部整合到一边，没有用过的内存放在另一边，中间有一个分界指针，只需要向着没用过的内存方向将该指针移动对象内存大小位置即可。
  - 使用该分配方式的 GC 收集器：Serial, ParNew
- 空闲列表： 
  - 适用场合：堆内存不规整的情况下。
  - 原理：虚拟机会维护一个列表，该列表中会记录哪些内存块是可用的，在分配的时候，找一块儿足够大的内存块儿来划分给对象实例，最后更新列表记录。
  - 使用该分配方式的 GC 收集器：CMS

选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是"标记-清除"，还是"标记-整理"（也称作"标记-压缩"），值得注意的是，复制算法内存也是规整的。



##### 4.1.2.3 JVM 里 new 对象时，堆会发生抢占吗？JVM是怎么设计来保证 线程安全的？

会，在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全：

- **CAS+失败重试：** 虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。
- **TLAB（Thread Local Allocation Buffer）：** 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配



##### 4.1.2.4 对象的内存布局

在HotSpot虚拟机里，对象在堆内存中的存储布局可以划分为三个部分：对象头 （Header）、实例数据（Instance Data）和对齐填充（Padding）。

+ 对象头主要由两部分组成： 
  + 第一部分存储对象自身的运行时数据：哈希码、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等，官方称它为Mark Word，它是个动态的结构，随着对象状态变化。 
  + 第二部分是类型指针，指向对象的类元数据类型（元空间中的类元数据）。 
  + 此外，如果对象是一个Java数组，还有一块用于记录数组长度的数据 
+ 实例数据用来存储对象真正的有效信息，也就是我们在程序代码里所定义的各种类型的字段内容，无论是从父类继承的，还是自己定义的。 
+ 对齐填充不是必须的，没有特别含义，仅仅起着占位符的作用。（Hotspot 对象的大小必须是 8 字节的整数倍）



##### 4.1.2.5 对象的访问定位

建立对象就是为了使用对象，我们的 Java 程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式由虚拟机实现而定，目前主流的访问方式有：**使用句柄**、**直接指针**。

+ 句柄：如果使用句柄的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与对象类型数据（元空间）各自的具体地址信息。

![对象的访问定位-使用句柄](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407271508539.png)

+ 直接指针： 如果使用直接指针访问，reference 中存储的直接就是对象的地址。

![对象的访问定位-直接指针](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407271508873.png)

这两种对象访问方式各有优势。使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。

HotSpot 虚拟机主要使用的就是这种方式来进行对象访问。







### 4.2 JVM 类加载器

#### 4.2.1 什么是字节码，class 文件结构

在 Java 中，JVM 可以理解的代码就叫做`字节码`（即扩展名为 `.class` 的文件），它不面向任何特定的处理器，只面向虚拟机。

**class文件结构**

+ 魔数：标识是否为Class文件。
+ Class文件版本号：确定使用java的版本。
+ 常量池：字面量和符号引用。
  + 类和接口的全限定名
  + 字段的名称和描述符
  + 方法的名称和描述符
+ 访问标志：public 或者 abstract 或者 final 等。
+ 当前类、父类、接口索引集合：Java 类的继承关系由类索引、父类索引和接口索引集合三项确定。
+ 字段表集合：描述接口或类中声明的变量。
+ 方法表集合：描述接口或类中声明的方法。
+ 属性表集合：在 Class 文件，字段表，方法表中都可以携带自己的属性表集合，以用于描述某些场景专有的信息。

#### 4.2.2 什么是类加载器，类加载器有哪些

类加载器（ClassLoader）的主要作用就是将**字节码文件加载到JVM中**，在内存中生成一个代表该类的 Class 对象，从而让Java程序能够启动起来。

常见的类加载器有4个：

+ 启动类加载器(BootStrap ClassLoader)：其是由C++编写实现。用于加载JAVA_HOME/jre/lib目录下的类库。

+ 扩展类加载器(ExtClassLoader)：该类是ClassLoader的子类，主要加载JAVA_HOME/jre/lib/ext目录中的类库。

+ 应用类加载器(AppClassLoader)：该类是ClassLoader的子类，主要用于加载classPath下的类，也就是加载开发者自己编写的Java类。

+ 自定义类加载器：开发者自定义类继承ClassLoader，实现自定义类加载规则。

#### 4.2.3 类加载的过程

类从加载到虚拟机中开始，直到卸载为止，它的整个生命周期包括了：加载、验证、准备、解析、初始化、使用和卸载这7个阶段。其中，验证、准备和解析这三个部分统称为连接（linking）

1. 加载：查找和导入class文件

   a. 根据类的**全限定名称**定位到.class文件

   b. 将对应二进制字节流表示的数据结构转化为方法区中的**数据结构**

   c. 在堆中生成一个class对象，作为访问这个类的入口

2. 验证：确保 Class 文件的字节码符合 JVM 规范

3. 准备：将类变量（静态变量）分配内存并且赋予初始值。

4. 解析：把类中的符号引用转换为直接引用

5. 初始化：对类的静态变量，静态代码块执行初始化操作

6. 使用

7. 卸载：卸载类即该类的 Class 对象被 GC

#### 4.2.4 双亲委派模型

##### 4.2.4.1 什么是双亲委派模型

1. 首先判断类是否被当前类加载器加载过，已经被加载的类会直接返回
2. 把这个请求委派给父类加载器去完成（调用父加载器 `loadClass()`方法来加载类）。父类再调用父类的父类，最终都会传送到顶层的启动类加载器 `BootstrapClassLoader` 中。
3. 只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载（调用自己的 `findClass()` 方法来加载类）。
4. 如果子类加载器也无法加载这个类，那么它会抛出一个 `ClassNotFoundException` 异常。

##### 4.2.4.2 双亲委派模型的好处

+ 双亲委派模型可以避免类的重复加载：jvm中判断两个类是否相同的不仅要看全限定类名相同，还要看类加载器是否相同。若是没有双亲委派机制，可能造成同一个类被多个类加载器加载的情况。

+ 也保证了 Java 的核心 API 不被篡改：如果用户自定义了一个同核心类相同全限定名的类（比如java.lang.Object），若是没有双亲委派机制，则环境中可能出现多个版本的核心类。

##### 4.2.4.3 如何打破双亲委派模型

自定义加载器的话，需要继承 `ClassLoader` 。如果我们不想打破双亲委派模型，就重写 `ClassLoader` 类中的 `findClass()` 方法即可，无法被父类加载器加载的类最终会通过这个方法被加载。但是，如果想打破双亲委派模型则需要重写 `loadClass()` 方法。因为类加载器都是通过这个方法去加载类的。比如 Tomcat 就打破了双亲委派模型。

##### 4.2.4.4 Tomcat的类加载机制

Tomcat 类加载器：

![image-20240726214034707](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407262140878.png)

Tomact是web容器，可能需要部署多个应用程序。不同的应用程序可能会依赖同一个 第三方类库的不同版本，但是不同版本的类库中某一个类的全路径名可能是一样 的。如多个应用都要依赖hollis.jar，但是A应用需要依赖1.0.0版本，但是B应用需要 依赖1.0.1版本。这两个版本中都有一个类是com.hollis.Test.class。如果采用默认的双 亲委派类加载机制，那么无法加载多个相同的类。 

所以，Tomcat破坏了双亲委派原则，提供隔离的机制，为每个web容器单独提供一 个WebAppClassLoader加载器。每一个WebAppClassLoader负责加载本身的目录下的 class文件，加载不到时再交CommonClassLoader加载，这和双亲委派刚好相反。





### 4.3 JVM 垃圾回收

#### 4.3.1 方法区的垃圾回收

方法区主要回收的是无用的类，类需要同时满足下面 3 个条件才能算是 **“无用的类”**：

- 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。
- 加载该类的 `ClassLoader` 已经被回收。
- 该类对应的 `java.lang.Class` 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。

虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。

#### 4.3.2 如何判断一个对象能否被回收

有两种方式引用计数法和可达性分析算法

+ 引用计数法：在对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加一；当引用失效时，计数器值就减一；当计数器为零表示对象可以被回收。 但是，当存在对象间的循环引用的时候，会出现内存泄漏的问题。

+ 可达性分析算法：目前 Java 虚拟机的主流垃圾回收器采取的是可达性分析算法。这个算法的实质在于 将一系列 GC Roots 作为初始的存活对象合集（Gc Root Set），然后从该合集出发， 所有能够被该集合引用到的对象都是存活的，未被探索到的对象便是不可用的，是可以回收的。

##### 4.3.2.1 那些对象可以作为GC Roots

+ 虚拟机栈(栈帧中的本地变量表)中引用的对象
+ 方法区中类静态属性引用的对象
+ 方法区中常量引用的对象
+ 本地方法栈中JNI引用的对象

##### 4.3.2.2 `finalize`方法？对象可以被回收，就代表一定会被回收吗？

`finalize`方法是`Object`类的一个 protected 方法，子类可以重写它。当垃圾回收器确定某个对象不可达时，在回收该对象占用的内存之前，垃圾回收器会调用该对象的`finalize`方法。但是当对象没有覆盖 `finalize` 方法，或 `finalize` 方法已经被虚拟机调用过时，虚拟机将不再执行`finalize`方法。（`finalize`方法只能被执行一次）如果在`finalize`方法中，对象重新获得了引用，那么它可能不会被回收；如果没有重新获得引用，最终还是会被回收。

#### 4.3.3 对象的引用类型

Java中的引用有四种，分为强引用（Strongly Reference）、软引用（Soft Reference）、弱引用（Weak Reference）和虚引用（Phantom Reference）4种，这4种 引用强度依次逐渐减弱。

+ 强引用：只要强引用关系还存在，垃圾收集器就永远不会回收掉被引用的对象，即使OOM。

+ 软引用：使用softReference声明，当jvm内存将要发生oom的时候会回收对应的对象。

  软引用可以和一个引用队列（ReferenceQueue）联合使用，如果**软引用所引用的对象**被垃圾回收，JAVA 虚拟机就会把这个**软引用**加入到与之关联的引用队列中。从而达到回收SoftReference 对象的目的。

+ 弱引用：使用weakreference声明，当jvm发生GC的时候，就会回收该对象。

+ 虚引用：使用PhantomReference类声明，无法通过虚引用来取得一个对象实例。虚引用的唯一目的只是为了能在这个对象被回收时收到一个系统通知，从而释放一些相关资源。



#### 4.3.4 垃圾收集算法

1. 标记清除：算法分为两个阶段，先标记出所有需要回收的对象，然后回收所有被标记的对象。但是会产生内存碎片，并且执行效率不稳定，随被回收的对象变多，效率变低。适合老年代GC。
2. 标记复制：将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。不会有内存碎片，但是需要牺牲一半的内存空间。常用于新生代GC，因为老年代存活对象数量比较大，复制性能会很差。
3. 标记整理：标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。不会有内存碎片，但是移动数据需要成本很高，常用于老年代GC。

4. 分代收集算法：当前虚拟机的垃圾收集都采用分代收集算法，只是根据对象存活周期的不同将内存分为几块。一般将 Java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。



#### 4.3.5 堆 的内存分区

Java堆划分为新生代 （Young Generation）和老年代（Old Generation）两个区域，新生代存放存活时间短的对象，这些对象每次垃圾回收后，如果存活年龄加一，一定年龄后会移动到老年代，当然大对象可能会提前进入老年代，因为大对象的频繁移动效率很低。 而新生代又可以分为三个区域，eden、Survivor from、Survivor to，比例是8：1：1。



#### 4.3.6 Minor GC/Young GC、Major GC/Old GC、Mixed GC、Full GC

部分收集（Partial GC）：指目标不是完整收集整个Java堆的垃圾收集，其中又分 为： 

+ 新生代收集（Minor GC/Young GC）：指目标只是新生代的垃圾收集。 新创建的对象优先在新生代Eden区进行分配，如果Eden区没有足够的空间时，就会触发Young GC来清理新生代。eden+from对象标记后，剩余对象复制到to区。eden+to对象标记后，剩余对象复制到from区。如此循环往复。
+ 老年代收集（Major GC/Old GC）：指目标只是老年代的垃圾收集。
+ 混合收集（Mixed GC）：指目标是收集整个新生代以及部分老年代的垃圾收 集。目前只有G1收集器会有这种行为。 

整堆收集（Full GC）：收集整个Java堆和方法区的垃圾收集。

##### 4.3.6.1 full GC 触发时机

- 老年代空间不足：老年代的空间达到一定比例后会触发
- 老年代空间**将要**不足：老年代容不下将要从新生代进入老年代的对象
- 方法区空间不足
- 主动调用了system.gc()

##### 4.3.6.2 新生代进入老年代的时机

- 达到年龄的对象：每次young GC都会对象的年龄都会加1，达到一个阈值，就会进入老年代。可以通过参数配置。
- 大对象直接进入老年代：防止大对象频繁在from 和to来回复制。可以通过参数配置。
- 动态年龄：当超过某个年龄的对象大于serviver区的一半，则直接进入老年代。
- 内存分配担保：YOUNG GC的后，可能出现存活下来的对象to区容纳不下，这个时候多余的对象会直接进入老年代



#### 4.3.7 垃圾收集器

##### 4.3.7.1 你知道那些垃圾收集器

+ Serial收集器：它是一个单线程工作的收集器，使用一个线程去完成垃圾收集工作。并且进行垃圾收集时，必须暂停其他所有工作线程， 直到垃圾收集结束——这就是所谓的“Stop The World”。**新生代采用标记-复制算法，老年代采用标记-整理算法。**

+ Serial Old：Serial Old 是 Serial收集器的老年代版本，使用**标记整理**算法
+ ParNew：ParNew收集器实质上是Serial收集器的多线程并行版本，使用多条线程进行垃圾收集。**新生代采用标记-复制算法，老年代采用标记-整理算法。**
+ Parallel Scavenge：和ParNew有些类似，但Parallel Scavenge主要关注的是垃圾收集的吞吐量—— 所谓吞吐量，就是CPU用于运行用户代码的时间和总消耗时间的比值，比值越大， 说明垃圾收集的占比越小。并且 Parallel Scavenge 收集器拥有自适应调节策略，可以自适应的优化内存管理。**新生代采用标记-复制算法，老年代采用标记-整理算法。**

![image-20240728164357472](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407281643738.png)

+ Parallel Old：Parallel Old是Parallel Scavenge收集器的老年代版本。

+ CMS收集器：CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器，同样是**老年代**的收集器，采用**标记-清除**算法。
+ G1 收集器：采用了局部收集的设计思路和基于Region的内存布局形式。

##### 4.3.7.2 【重要】CMS收集器

![CMS 收集器](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407281709657.png)

CMS收集齐的垃圾收集分为四步： 

+ 初始标记 （CMS initial mark）：单线程运行，需要STW，标记GC Roots能直达的对象。 
+ 并发标记 （（CMS concurrent mark）：无停顿，和用户线程同时运行，标记所有可达对象。 
  + 浮动垃圾：标记为可达，但是用户线程执行过程变为不可达。
  + 漏标：没有标记，但是用户线程执行过程中引用了。
+ 重新标记 （CMS remark）：多线程运行，需要STW，解决上一步的漏标问题。 
+ 并发**清除** （CMS concurrent sweep）：无停顿，和用户线程同时运行，清理掉标 记阶段标记的死亡的对象。

**优缺点**

- 优点：分为多个阶段，减少 STW 时间。
- 缺点：
  - 多线程依赖cpu，导致用户程序性能下降。
  - 标记清除会产生内存碎片。
  - 产生浮动垃圾，如果浮动垃圾太多，会触发新的垃圾回收（线性回收），导致性能降低。

##### 4.3.7.3 【重要】G1 收集器

别的收集器的瓶颈其实都是 最后的 整理 或者 复制 阶段，这个阶段的 STW 过长，G1 和 ZGC 的设计目标都是缩小 STW。

![G1 收集器](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407281812239.png)

**特点：**

- Region：将堆分为等大小的多个区域（Region），每个区域都可能是eden，survice，old或者Humongous（大对象区）。大小大于等于region一半的对象会直接存储在 H 中，属于老年代。
- 采用STAB（snapshot at the beginning）和RSet 优化解决漏标问题。
- 可预测停顿时间：可以设置一个最大预期GC时间，G1维护了一个回收价值列表 ：每次根据设置的允许GC时间，从列表中选择回收价值最大的区域。
- 分为 Young GC 和 Mixed GC 两种情况，当年轻代不足的时候就会 Young GC，默认是年轻代超过总空间的 60%，当老年代超过 45% 时就会 mixed GC。

**过程：**

1. 初始标记：STW，标记线程找到gc roots的直连的对象
2. 并发标记：与用户线程并发进行，标记线程标记可达对象
3. 再次标记：STW，多个标记线程并发解决上一步产生的漏标问题。采用STAB（snapshot at the beginning）和RSet 优化解决漏标问题。
4. 筛选清理：STW， 制定回收计划，根据允许的收集时间和停顿预测算法，优先选择回收价值大的 Region 构成回收集，把回收集中Region的存活对象复制到空的Region中，再清理掉整个旧 Region的全部空间。

> 实际的 G1 收集器，涉及很多细小的优化内容，了解 G1 就可以了，细节实现太复杂了！

**参考**

[美团技术团队：Java Hotspot G1 GC的一些关键技术](https://tech.meituan.com/2016/09/23/g1.html)

##### 4.3.7.4 ZGC

G1 收集器的瓶颈存在于最后的筛选清理阶段，这个阶段需要把Region中存活的对象复制到别的区域，并且要 对 对象的引用重置，这个阶段是 STW 的。ZGC将这个阶段也优化为非 STW，采用了**着色指针**和**读屏障**的技术，让并发访问的用户线程可以判断自己访问的对象是否需要复制转移，是否已完成复制转移，若未完成则可以利用转移映射表自己去完成对象的转移和重映射的工作。

![image-20240727222212381](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407272222620.png)

![image-20240727222313270](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407272223394.png)

![image-20240727222343186](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407272223358.png)

![image-20240727222234948](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407272222124.png)

**参考**

[新一代垃圾回收器ZGC的探索与实践](https://tech.meituan.com/2020/08/06/new-zgc-practice-in-meituan.html)



### 4.4 JIT

热点代码的字节码指令将被 JIT 即时编译器编译成机器码同时进行一些优化，最后保存在内存中，将来执行时直接读取就可以运行在计算机硬件上了。

热点代码：被调用很多次的方法；循环很多次的循环体；

#### 4.4.1 JIT 编译器分类

JVM 中集成了两种编译器，一种是 Client Compiler，另外一种是 Server Compiler。

+ Client Compiler 注重启动速度和局部的优化。在hotspot的实现中是 c1编译器
+ Server Compiler 则更加关注全局的优化，性能会更好，但由于会进行更多的全局分析，所以启动速度会慢一些。在 hotspot 的实现中 是 c2 编译器。

#### 4.4.2 分层编译

Java 7 中引入的分层编译（Tiered Compilation）确实是一种结合了 C1 编译器（Client Compiler）和 C2 编译器（Server Compiler）优势的技术。

1. **层级 0 - 解释器（Interpreter）**：这是程序最初执行的阶段，代码通过解释器逐行解释执行。这一阶段的目的是尽快开始执行而不等待编译完成。
2. **层级 1 - C1 编译器带有轻量级优化（C1 with Simple Optimizations）**：在这一层级，代码首次由 C1 编译器编译，应用了一些基本的优化，如方法内联。这一阶段的编译速度较快，能迅速提供优于解释执行的性能。
3. **层级 2 - C1 编译器带有完整优化（C1 with Full Optimizations）**：此层级仍由 C1 编译器处理，但应用了更多优化技术，如逃逸分析。虽然这些优化需要更长的编译时间，但能进一步提升运行性能。
4. **层级 3 - C1 编译器带有分析数据收集（C1 with Profiling）**： 在这个层级，C1 编译器除了执行优化，还收集方法执行的详细分析数据（如分支频率、热点代码等）。这些数据将用于 C2 编译器的后续优化。
5. **层级 4 - C2 编译器优化（C2 Optimizations）**：最终阶段由 C2 编译器处理，它使用收集的分析数据进行深入优化。C2 编译器的优化更加彻底和复杂，适用于长时间运行的代码，能够提供最佳的运行性能。

#### 4.4.3 JIT 的主要优化技术

**方法内联**

方法体中的字节码指令直接复制到调用方的字节码指令中，节省了创建栈帧的开销。

**逃逸分析**

通过分析对象是否逃逸到方法或线程的外部，JIT 可以进行以下优化：

+ 锁消除
+ 栈上分配：对象没有逃逸到方法之外，编译器可以选择在栈上分配对象，而非在堆上分配。这样可以提高内存分配的效率，并减少垃圾收集器的压力。
+ 标量替换：如果这个对象没有逃逸出方法，那么它的各个字段可以视为独立的局部变量。





### 4.5 JVM 调优

>  光看视频，文字教程，我觉得有点扯淡，不深入，面试回答了也不太行。后面再详细学

内存泄露：就是申请的内存空间没有被正确释放，导致内存被白白占用。

内存溢出：就是申请的内存超过了可用内存，内存不够了。

#### 4.5.1 有哪些常用的命令行性能监控和故障处理工具？

操作系统工具 

+ top：显示系统整体资源使用情况 
+ vmstat：监控内存和CPU 
+ iostat：监控IO使用 
+ netstat：监控网络使用 

JDK性能监控工具 

+ jps：虚拟机进程查看 
+ jstat：虚拟机运行时信息查看 
+ jinfo：虚拟机配置查看 
+ jmap：内存映像（导出） 
+ jhat：堆转储快照分析 
+ jstack：Java堆栈跟踪 
+ jcmd：实现上面除了jstat外所有命令的功能

#### 4.5.2 了解哪些可视化的性能监控和故障处理工具？

以下是一些JDK自带的可视化性能监控和故障处理工具：

+ JConsole
+ VisualVM

阿里

+ arthas

#### 4.5.3 JVM的常见参数配置知道哪些？

堆配置：

+ -Xms:初始堆大小 
+ -Xms：最大堆大小 
+ -XX:NewSize=n:设置年轻代大小 
+ -XX:NewRatio=n:设置年轻代和年老代的比值。如：为3表示年轻代和年老代比值 为1：3，年轻代占整个年轻代年老代和的1/4 
+ -XX:SurvivorRatio=n:年轻代中Eden区与两个Survivor区的比值。注意Survivor区 有两个。如3表示Eden： 3 Survivor：2，一个Survivor区占整个年轻代的1/5 -
+ XX:MaxPermSize=n:设置持久代大小

收集器设置： 

+ -XX:+UseSerialGC:设置串行收集器 
+ -XX:+UseParallelGC:设置并行收集器 
+ -XX:+UseParalledlOldGC:设置并行年老代收集器 
+ -XX:+UseConcMarkSweepGC:设置并发收集器

并行收集器设置 

+ -XX:ParallelGCThreads=n:设置并行收集器收集时使用的CPU数。并行收集线程数 
+ -XX:MaxGCPauseMillis=n:设置并行收集最大的暂停时间（如果到这个时间了， 垃圾回收器依然没有回收完，也会停止回收） 
+ -XX:GCTimeRatio=n:设置垃圾回收时间占程序运行时间的百分比。公式为： 1/(1+n) 
+ -XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况 
+ -XX:ParallelGCThreads=n:设置并发收集器年轻代手机方式为并行收集时，使用 的CPU数。并行收集线程数

打印GC回收的过程日志信息 

+ -XX:+PrintGC 
+ -XX:+PrintGCDetails 
+ -XX:+PrintGCTimeStamps 
+ -Xloggc:filename

#### 4.5.4 线上服务CPU占用过高怎么排查？

其实主要是通过在服务器上操作，定位我们问题代码的位置：

1、所以先需要找出那个进程占用CPU高。 

+ top 列出系统各个进程的资源占用情况。 

2、然后根据找到对应进行里哪个线程占用CPU高。 

+ top -Hp 进程ID 列出对应进程里面的线程占用资源情况 

3、找到对应线程ID后，再打印出对应线程的堆栈信息 

+ printf "%x\n" PID 把线程ID转换为16进制。 
+ jstack PID 打印出进程的所有线程信息，从打印出来的线程信息中找到上一步转 换为16进制的线程ID对应的线程信息。 

4、最后根据线程的堆栈信息定位到具体业务方法,从代码逻辑中找到问题所在。 

+ 查看是否有线程长时间的watting 或blocked，如果线程长期处于watting状态下， 关注 watting on xxxxxx，说明线程在等待这把锁，然后根据锁的地址找到持有锁的线程。

#### 4.5.5 内存飙高问题怎么排查？

内存飚高如果是发生在java进程上，有两种可能：

1. 创建了大量对象所导致，持续飚高说明垃圾回收跟不上对象创建的速度
2. 内存泄露导致对象无法回收。

首先定位问题原因：

1、先观察垃圾回收的情况 

+ jstat -gc PID 1000 查看GC次数，时间等信息，每隔一秒打印一次。 
+ jmap -histo PID | head -20 查看堆内存占用空间最大的前20个对象类型,可初步查 看是哪个对象占用了内存。 

如果每次GC次数频繁，而且每次回收的内存空间也正常，那说明是因为对象创建速度快导致内存一直占用很高；如果每次回收的内存非常少，那么很可能是因为内存泄露导致内存一直无法被回收。 

2、导出堆内存文件快照 

+ jmap -dump:live,format=b,file=/home/myheapdump.hprof PID dump堆内存信息到 文件。 

3、使用visualVM对dump文件进行离线分析，找到占用内存高的对象，再找到创建该对象的业务代码位置，从代码和业务场景中定位具体问题。

#### 4.5.6 频繁 minor gc 怎么办？

优化Minor GC频繁问题：通常情况下，由于新生代空间较小，Eden区很快被填满， 就会导致频繁Minor GC，因此可以通过增大新生代空间 -Xmn 来降低Minor GC的频 率。

#### 4.5.7 频繁Full GC怎么办？

Full GC的排查思路大概如下： 

1. 清楚从程序角度，有哪些原因导致FGC？ 
+ 大对象 ：系统频繁的加载大对象（比如SQL查询未做分页），导致大对象频繁进入了老年代。 从而老年代空间不足，频繁 FULLGC。
+ 内存泄漏 ：频繁创建了大量对象，但是无法被回收，先引发FGC，最后导致OOM. 
+ 程序频繁生成一些长生命周期的对象 ，当这些对象的存活年龄超过分代年龄时便会进入老年代，最后引发FGC.  
+ 代码中显式调用了system.gc 方法。 
+ JVM参数设置问题：包括总内存大小、新生代和老年代的大小、Eden区和S区的 大小、元空间大小、垃圾回收算法等等。 

2. 清楚排查问题时能使用哪些工具 

+ 公司的监控系统：大部分公司都会有，可全方位监控JVM的各项指标。 
+ JDK的自带工具，包括jmap、jstat等常用命令：

```bash
# 查看堆内存各区域的使用率以及GC情况
jstat -gcutil -h20 pid 1000
# 查看堆内存中的存活对象，并按空间排序
jmap -histo pid | head -n20
# dump堆内存文件
jmap -dump:format=b,file=heap pid
```

3. 排查指南 

+ 查看监控，以了解出现问题的时间点以及当前FGC的频率（可对比正常情况看频 率是否正常） 
+ 了解JVM的参数设置，包括：堆空间各个区域的大小设置，新生代和老年代分别 采用了哪些垃圾收集器，然后分析JVM参数设置是否合理。 
+ 再对步骤1中列出的可能原因做排除法，其中内存泄漏、代码显式调用gc方法比较容易排查。 
+ 针对大对象或者长生命周期对象导致的FGC，可通过 jmap -histo 命令并结合 dump堆内存文件作进一步分析，需要先定位到可疑对象。 
+ 通过可疑对象定位到具体代码再次分析，这时候要结合GC原理和JVM参数设 置，弄清楚可疑对象是否满足了进入到老年代的条件才能下结论。

#### 4.5.8 有没有处理过内存泄漏问题？是如何定位的？

内存泄漏是内在病源，外在病症表现可能有： 

+ 应用程序长时间连续运行时性能严重下降 
+ CPU 使用率飙升，甚至到 100% 
+ 频繁 Full GC，各种报警，例如接口超时报警等 
+ 应用程序抛出 OutOfMemoryError 错误 

严重内存泄漏往往伴随频繁的 Full GC，所以分析排查内存泄漏问题首先还得从查 看 Full GC 入手。主要有以下操作步骤： 

1. 使用 top  查看进程使用 CPU 和 MEM 的情况 
2. 使用 top -Hp [pid] 查看进程下的所有线程占 CPU 和 MEM 的情况 
3. 将线程 ID 转换为 16 进制： printf "%x\n" [pid] ，输出的值就是线程栈信息中的 nid。 例如： printf "%x\n" 29471 ，换行输出 731f。 
4. 抓取线程栈： jstack 29452 > 29452.txt ，可以多抓几次做个对比。 在线程栈信息中找到对应线程号的 16 进制值。
5. 使用 jstat -gcutil [pid] 5000 10 每隔 5 秒输出 GC 信息，输出 10 次， 查看 YGC 和 Full GC 次数。通常会出现 YGC 不增加或增加缓慢，而 Full GC 增加很快。
6. 如果发现 Full GC 次数太多，就很大概率存在内存泄漏了 
7. 使用 jmap -histo:live [pid] 输出每个类的对象数量，内存大小(字节单位) 及全限定类名。 
8. 生成 dump 文件，借助工具分析哪 个对象非常多，基本就能定位到问题在那了 使用 jmap 生成 dump 文件：

```bash
# jmap -dump:live,format=b,file=29471.dump 29471
Dumping heap to /root/dump ...
Heap dump file created
```

9. 通常使用图形化工具分析，如 JDK 自带的 jvisualvm。 或使用第三方式具分析的，如 JProfiler 也是个图形化工具，GCViewer 工具。 Eclipse 或以使用 MAT 工具查看。或使用在线分析平台 GCEasy。 注意：如果 dump 文件较大的话，分析会占比较大的内存。 
10. 在 dump 文析结果中查找存在大量的对象，再查对其的引用。 基本上就可以定位到代码层的逻辑了。
