# java



### 红黑树、B树和B+树

AVL树：平衡二叉树

BST树：二叉查找树

#### 红黑树

##### 来源

其实红黑树是 2-3-4树（也可以叫做 2-4 树）的等价实现，因为2-3-4树有完美的自平衡性，它的所有操作在最坏的情况下复杂度也是 O(log n) 所以2-3-4树的查找、插入和删除的效率都很高。

但是由于2-3-4树按照它最初的定义来实现的话，不仅需要大量的代码，而且它们所产生的额外开销可能会使算法比标准的二叉查找树更慢。所以产生了红黑树，红黑树的红黑，其实值得是连接当前节点的链接的属性，因为每个节点都只有一个指向它的链接所以用节点的属性代替链接的属性。红色链接 指的就是 红色链接两端的节点，其实可以转化为2-3-4中的一个3节点或者4节点。2-3-4树的到达每一个空链接的路径长相等性质，也就转化为红黑树的到叶子节点的黑色节点数量一致的性质。

> 其实最早的完美平衡查找树为 2-3 树，它对应的二叉树实现为左偏红黑树。

##### 性质

1. **根节点是黑色的**： 第一个性质要求根节点始终是黑色的，这确保了树的整体结构保持平衡。
2. **红色子节点性质**： 不能有两个相连的红色节点。这意味着从任意节点到其子节点的路径上不能出现连续的红色节点，以避免出现不平衡情况。
3. **黑高度平衡性质**： 从任意节点出发，到达其每个叶子节点的路径上的黑色节点数量必须相同。这确保了树的高度始终保持在一个合理的范围内，从而保证了高效的查找操作。
4. **红黑性质的维护**： 在执行插入和删除操作后，红黑树需要通过旋转和颜色调整来保持这些性质，从而恢复平衡。这些操作保证了在更新操作之后，树仍然是一颗满足红黑性质的树。
5. **空节点的处理**： 空节点（NIL节点）被认为是黑色的。这样可以确保每个路径上的黑色节点数量相等，即使是经过了空节点的路径。

##### 对比AVL树

+ 平衡性：
  + 红黑树：红黑树保证了一种弱平衡，即树的高度最多是2倍的对数级别。这使得红黑树在插入和删除操作时具有更高的灵活性，但可能导致一些操作稍微不如AVL树高效。
  + AVL树：AVL树是一种严格的平衡树，保证任何节点的左子树和右子树的高度差（平衡因子）不超过1。这确保了AVL树在平衡方面表现更好，但在插入和删除操作时可能需要更多的旋转来维持平衡。
+ 插入和删除操作的性能：
  + 红黑树：由于红黑树的平衡性要求相对较弱，插入和删除操作通常需要更少的旋转操作，因此在这些操作上性能可能比AVL树更好。
  + AVL树：AVL树的严格平衡性可能导致插入和删除操作需要更频繁的旋转操作，因此在这些操作上可能比红黑树略逊一筹。


##### 插入

当在红黑树中执行插入操作时，需要考虑两个主要方面：保持二叉搜索树性质和保持红黑性质。以下是插入操作的详细步骤，包括可能的旋转操作和颜色调整。

插入操作的基本步骤：

1. 将新节点插入到BST中： 首先，将新节点插入到红黑树中，就像在普通的二叉搜索树中一样。新节点会被标记为红色，因为它可能会破坏红黑性质的第一个性质（根节点必须是黑色）。

2. 检查红黑性质： 插入新节点后，可能会破坏红黑性质。需要通过一系列的操作来调整以确保所有的红黑性质得到满足。

颜色调整： 在进行旋转操作之前，需要进行颜色调整以满足红黑性质。以下是颜色调整的可能情况：

1. 父节点为黑色： 如果插入的节点的父节点是黑色的，那么树的结构没有破坏，不需要进一步的调整。

2. 父节点为红色： 如果插入的节点的父节点是红色的，那么可能会破坏红黑性质的第二个性质（不能有两个相连的红色节点）。在这种情况下，需要考虑插入节点的叔叔节点（父节点的兄弟节点）的颜色。

a. 叔叔节点是红色： 如果叔叔节点是红色的，可以通过改变父节点和叔叔节点的颜色，然后将问题向上移动到父节点。这样可以保持黑高度平衡性质。

b. 叔叔节点是黑色或缺失： 如果叔叔节点是黑色的（包括叔叔节点为NIL节点），需要通过旋转来修复这种情况。

**情况一：如果关注节点是 a，它的叔叔节点 d 是红色**

![img](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202404221734309.png)


具体操作为：将关注节点 a 的父节点 b、叔叔节点 d 的颜色都设置成黑色；将关注节点 a 的祖父节点 c 的颜色设置成红色；关注节点变成 a 的祖父节点 c；跳到情况二或者情况三。

**情况二：如果关注节点是 a，它的叔叔节点 d 是黑色，关注节点 a 是其父节点 b 的右子节点**

![img](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202404221734603.png)

具体操作为：关注节点变成节点 a 的父节点 b；围绕新的关注节点b 左旋；跳到情况三。

**情况三：如果关注节点是 a，它的叔叔节点 d 是黑色，关注节点 a 是其父节点 b 的左子节点**

![img](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202404221735941.png)

具体操作为：围绕关注节点 a 的祖父节点 c 右旋；将关注节点 a 的父节点 b、兄弟节点 c 的颜色互换，调整结束。

##### 删除

删除操作比较复杂，其实贱但来说就是通过，旋转和调整颜色，分情况处理使删除后的红黑树依然符合红黑树的性质。



#### B树

##### 简介

首先 B树 和 B-树 是同一种数据结构。在计算机科学中，B树是一种自平衡的树，能够保持数据有序。这种数据结构能够让查找数据、顺序访问、插入数据及删除的动作，都在对数量级的时间复杂度内完成。B树，其实是一颗特殊的二叉查找树（binary search tree），可以拥有多于2个子节点。与自平衡二叉查找树不同，B树为系统大块数据的读写操作做了优化。B树减少定位记录时所经历的中间过程，从而加快存取速度，其实B树主要解决的就是数据IO的问题。B树这种数据结构可以用来描述外部存储。这种数据结构常被应用在数据库和文件系统的实现上。

##### 性质

首先介绍一下一棵 m 阶的 B 树的特性。m表示这个树的每一个节点最多可以拥有的子节点个数。一棵 m 阶的 B 树满足的性质如下：

1. 每个节点最多有 m 个子节点。
2. 每一个非叶子节点（除根节点）最少有 $ \left \lceil m/2 \right \rceil $ 个子节点。
3. 如果根节点不是叶子节点，那么它至少有两个子节点。
4. 有 k 个子节点的非叶子节点拥有 k-1 个键，且升序排列，满足 k[i] < k[i+1]。
6. 所有的叶子节点都在同一层。

##### 优势

之前已经介绍过二叉查找树。但是这类型数据结构的问题在于，由于每个节点只能容纳一个数据，导致树的高度很高，逻辑上挨着的节点数据可能离得很远。

考虑在磁盘中存储数据的情况，与内存相比，读写磁盘有以下不同点：

1. 读写磁盘的速度相比内存读写慢很多。
2. 每次读写磁盘的单位要比读写内存的最小单位大很多。

由于读写磁盘的这个特点，因此对应的数据结构应该尽量的满足「局部性原理」：「当一个数据被用到时，其附近的数据也通常会马上被使用」，为了满足局部性原理， 所以应该将逻辑上相邻的数据在物理上也尽量存储在一起。这样才能减少读写磁盘的数量。

所以，对比起一个节点只能存储一个数据的 BST 类数据结构来，要求这种数据结构在形状上更「胖」、更加「扁平」，即：每个节点能容纳更多的数据， 这样就能降低树的高度，同时让逻辑上相邻的数据都能尽量存储在物理上也相邻的硬盘空间上，减少磁盘读写。



#### B+树

##### 介绍

B+ 树是 [B 树](https://oi-wiki.org/ds/b-tree/) 的一个升级，它比 B 树更适合实际应用中操作系统的文件索引和数据库索引。目前现代关系型数据库最广泛的支持索引结构就是 B+ 树。

##### 性质

B+树是B树的变种，但不同资料中B+树的定义各有不同，其差异在于节点中关键字个数和孩子节点个数。一种是节点中关键字个数和孩子个数相同，另一种是关键字个数比孩子节点个数小1，这种方式是和B树基本相同。

1. B+树包含2种类型的节点：内部节点（也称索引节点）和叶子节点。根节点本身即可以是内部节点，也可以是叶子节点。根节点的关键字key个数最少可以只有1个；
2. B+树与B树最大的不同是内部节点不保存数据，只用于索引，所有数据（或者说记录）都保存在叶子节点中；
3. m阶B+树表示了内部节点最多有m-1个关键字（或者说内部节点最多有m个子树，和B树相同），阶数m同时限制了叶子节点最多存储m-1个记录；
4. 内部节点中的key都按照从小到大的顺序排列，对于内部节点中的一个key，左树中的所有key都小于它，右子树中的key都大于等于它。叶子节点中的记录也按照key的大小排列；
5. 每个叶子节点都存有相邻叶子节点的指针，叶子节点本身依关键字的大小自小而大顺序链接；

##### 优势

由于索引节点上只有索引而没有数据，所以索引节点上能存储比 B 树更多的索引，这样树的高度就会更矮。树的高度越矮，磁盘寻道的次数就会越少。

因为数据都集中在叶子节点，而所有叶子节点的高度相同，那么可以在叶子节点中增加前后指针，指向同一个父节点的相邻兄弟节点，这样可以更好地支持查询一个值的前驱或后继，使连续访问更容易实现。

比如这样的 SQL 语句：`select * from tbl where t > 10`，如果使用 B+ 树存储数据的话，可以首先定位到数据为 10 的节点，再沿着它的 `next` 指针一路找到所有在该叶子节点右边的叶子节点，返回这些节点包含的数据。

而如果使用 B 树结构，由于数据既可以存储在内部节点也可以存储在叶子节点，连续访问的实现会更加繁琐（需要在树的内部结构中进行移动）。

> 由上边的 二叉查找树 引出数据库引擎。
>
> 像这种二叉树结构比较常见的使用场景是 Mysql 两种引擎，Myisam 使用的是 B 树，InnoDB 使用的是 B+树







## 集合

### Map 底层原理

#### Map内部的存储结构：

+ Map存放数据的 key-value 示意图，一对 k-v 是放在一个HashMap$Node中的，因为Node接口实现了Entry接口，所以有的地方也说一对 k-v就是一个Entry。
+ 每一个k-v还被存储在EntrySet的集合中，便于遍历。并且所有的key也被单独存储在KeySet的集合中，所有的value也被存储在Values集合中

![image-20240423110957002](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202404231109209.png)

#### HashMap 源码剖析（与HashSet相同）

+ 与HashSet一样，不保证映射的顺序，因为底层是以hash表的方式来存储的. (jdk8的
  hashMap 底层数组+链表+红黑树)

+ HashMap底层维护了Node类型的数组table,默认为null
+ 当创建对象时，将加载因子(loadfactor)初始化为0.75.
+ 当添加key-val时，通过key的哈希值得到在table的索引。 然后判断该索引处是否有元素，
  如果没有元素直接添加。如果该索引处有元素，继续判断该元素的key和准备加入的key相
  是否等，如果相等，则直接替换val;如果不相等需要判断是树结构还是链表结构，做出相
  应处理。如果添加时发现容量不够，则需要扩容。
+ 第1次添加，则需要扩容table容量为16,临界值(threshold)为12 (16*0.75)
+ 以后再扩容，则需要扩容table容量为原来的2倍(32),临界值为原来的2倍,即24,依次类推
+ 在Java8中，如果一条链表的元素个数超过TREEIFY THRESHOLD(默认是8)，并且
  table的大小>= MIN TREEIFY CAPACITY(默认64),就会进行树化(红黑树)。因为对于搜索，插入，删除操作多的情 况下，使用红黑树的效率要高一些

#### Map 的线程安全问题

+ HashMap 是线程不安全的，在多线程环境下，使用 Hashmap 进行 put 操作会引起死循环， 导致 CPU 利用率接近 100%，而且会抛出并发修改异常，导致原因是并发争取线程资源，修 改数据导致的，一个线程正在写，一个线程过来争抢，导致线程写的过程被其他线程打断， 导致数据不一致。 
+ HashTable 是线程安全的，只不过实现代价却太大了，简单粗暴，get/put 所有相关操作都是 synchronized 的，这相当于给整个哈希表加了一把大锁。多线程访问时候，只要有一个线程 访问或操作该对象，那其他线程只能阻塞，相当于将所有的操作串行化，在竞争激烈的并发 场景中性能就会非常差。 
+ 为了应对 hashmap 在并发环境下的不安全问题，ConcurrentHashMap 大量的利用了 volatile，CAS 等技术来减少锁竞争对于性能的影响。 
+ 在 JDK1.7 版本中 ConcurrentHashMap 避免了对全局加锁，改成了局部加锁（分段锁），分 段锁技术，将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访 问其中一个段数据的时候，其他段的数据也能被其他线程访问，能够实现真正的并发访问。 不过这种结构的带来的副作用是 Hash 的过程要比普通的 HashMap 要长。 
+ 所以在 JDK1.8 版本中 CurrentHashMap 内部中的 value 使用 volatile 修饰，保证并发的可见性 以及禁止指令重排，只不过 volatile 不保证原子性，使用为了确保原子性，采用 CAS（比较 交换）这种乐观锁来解决。

#### LinkedHashMap

LinkedHashMap 是 Java 中的一种特殊的 Map 实现，它继承自 HashMap 类，并且保留了插入顺序。在 LinkedHashMap 中==，每个条目（键值对）都保留了一个指向其前一个条目和后一个条目的指针，这样就形成了一个双向链表==。这个双向链表可以确保元素在迭代时按照插入顺序进行访问。

LinkedHashMap 与普通的 HashMap 相比，多了一个特性就是它保留了插入顺序。这意味着当你迭代一个 LinkedHashMap 时，你会按照元素插入的顺序来获取元素，而不是按照键的哈希值顺序或其他顺序。这种特性在某些场景下非常有用，例如需要维护一个键值对的顺序，或者需要实现 LRU（Least Recently Used）缓存等。



## 多线程

### 悲观锁 乐观锁

如果将悲观锁（Pessimistic Lock）和乐观锁（PessimisticLock 或 OptimisticLock）对应到现实生活中来。悲观锁有点像是一位比较悲观（也可以说是未雨绸缪）的人，总是会假设最坏的情况，避免出现问题。乐观锁有点像是一位比较乐观的人，总是会假设最好的情况，在要出现问题之前快速解决问题。

在程序世界中，乐观锁和悲观锁的最终目的都是为了保证线程安全，避免在并发场景下的资源竞争问题。但是，相比于乐观锁，悲观锁对性能的影响更大！

![image-20240426194924044](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202404261949209.png)

#### 悲观锁

悲观锁总是假设最坏的情况，认为共享资源每次被访问的时候就会出现问题(比如共享数据被修改)，所以每次在获取资源操作的时候都会上锁，这样其他线程想拿到这个资源就会阻塞直到锁被上一个持有者释放。也就是说，**共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程**。

像 Java 中`synchronized`和`ReentrantLock`等独占锁就是悲观锁思想的实现。



```java
public void performSynchronisedTask() {
    synchronized (this) {
        // 需要同步的操作
    }
}

private Lock lock = new ReentrantLock();
lock.lock();
try {
   // 需要同步的操作
} finally {
    lock.unlock();
}
```

高并发的场景下，激烈的锁竞争会造成线程阻塞，大量阻塞线程会导致系统的上下文切换，增加系统的性能开销。并且，悲观锁还可能会存在死锁问题，影响代码的正常运行。



#### 乐观锁

乐观锁总是假设最好的情况，认为共享资源每次被访问的时候不会出现问题，线程可以不停地执行，无需加锁也无需等待，只是在提交修改的时候去验证对应的资源（也就是数据）是否被其它线程修改了（具体方法可以使用版本号机制或 CAS 算法）。

像 Java 中`java.util.concurrent.atomic`包下面的原子变量类（比如`AtomicInteger`、`LongAdder`）就是使用了乐观锁的一种实现方式 **CAS** 实现的。

![JUC原子类概览](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202404262117286.png)

```java
// LongAdder 在高并发场景下会比 AtomicInteger 和 AtomicLong 的性能更好
// 代价就是会消耗更多的内存空间（空间换时间）
LongAdder longAdder = new LongAdder();
// 自增
longAdder.increment();
// 获取结果
longAdder.sum();
```

高并发的场景下，乐观锁相比悲观锁来说，不存在锁竞争造成线程阻塞，也不会有死锁的问题，在性能上往往会更胜一筹。但是，如果冲突频繁发生（写占比非常多的情况），会频繁失败和重试（悲观锁的开销是固定的），这样同样会非常影响性能，导致 CPU 飙升。

不过，大量失败重试的问题也是可以解决的，像我们前面提到的 `LongAdder`以空间换时间的方式就解决了这个问题。

理论上来说：

+ 悲观锁通常多用于写比较多的情况下（多写场景，竞争激烈），这样可以避免频繁失败和重试影响性能，悲观锁的开销是固定的。不过，如果乐观锁解决了频繁失败和重试这个问题的话（比如`LongAdder`），也是可以考虑使用乐观锁的，要视实际情况而定。
+ 乐观锁通常多于写比较少的情况下（多读场景，竞争较少），这样可以避免频繁加锁影响性能。不过，乐观锁主要针对的对象是单个共享变量（参考`java.util.concurrent.atomic`包下面的原子变量类）。



### 可重入锁 不可重入锁

可重入锁（Reentrant Lock），也称为递归锁，是一种特殊的锁机制，允许同一个线程多次获取同一个锁而不会被阻塞。当一个线程获得了锁之后，如果再次尝试获取同一个锁时，可重入锁会允许该线程继续获取锁，而不是让线程等待锁的释放。这种机制使得线程在执行过程中可以多次进入由同一个锁保护的代码块，从而能够处理如递归调用或嵌套代码等场景。

在可重入锁的实现中，通常会记录持有锁的线程和持有锁的次数。每次线程进入锁保护的代码块时，计数器会自增；而在退出代码块时，计数器会自减。只有当计数器为0时，锁才会被释放。

可重入锁的主要目的是解决在递归调用或嵌套代码中的锁定问题。如果没有可重入锁的支持，线程在递归调用时可能会因为无法再次获得同一个锁而陷入死锁状态。而可重入锁则允许线程在递归调用时继续执行，从而避免了死锁问题。

在Java中，ReentrantLock类是可重入锁的一种实现方式。此外，synchronized关键字在Java中也具有可重入的特性。通过合理使用可重入锁，可以提高程序的并发性能和可靠性。



## 三、java并发



### 3.1 多线程基础

#### 3.1.1 线程的生命周期和状态

![image-20240711154740546](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407111547752.png)

分别是

* NEW：当一个线程对象被创建，但还未调用 start 方法时处于**新建**状态
* RUNNABLE：调用了 start 方法，就会由**新建**进入**可运行**
* TERMINATED：线程内代码已经执行完毕，由**可运行**进入**终结**
* BLOCKED：当获取锁失败后，由**可运行**进入**阻塞**状态，等待其他线程释放锁
* WAITING：成功获取锁的线程，由于调用了 wait() 或者别的方法（join()方法，park()方法），此时从**可运行**状态进入等待状态，等待其他线程的特定操作。
* TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样⼀直等待

#### 3.1.2 run() 和 start() 的区别

调用start()方法的作用是启动线程，让线程状态由 new 变为 runnable 表示线程准备就绪可以运行了，而调用 run() 方法表示 并不把它当作多线程方法调用，而是非多线程的正常方法调用。

#### 3.1.3 wait()方法 和 sleep()方法 有什么区别

共同点：

+ 两个方法都可以暂停当前线程的执行。不过 sleep() 方法 和 带参数的 wait(long) 方法是让线程进入 TIMED_WAITING 状态，而 不带参数的 wait() 方法是让线程进入 WAITING 状态。

不同点：

根本上的不同：wait() 通常被用于线程间交互/通信， sleep() 通常被用于暂停执行

+ sleep() 是 Thread 的静态方法，而 wait() 是 Object 的成员方法
+ wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象的 notify() 或者 notifyAll() 方法。带参数的 wait 方法 和 sleep 方法会在等待响应的时间后自动唤醒。
+ wait 方法的调用必须先获取 wait 对象的锁，wait 方法执行后会释放对象锁，允许其它线程获得该对象锁，而 sleep 如果在 synchronized 代码块中执行，并不会释放对象锁



### 3.2 多线程安全

#### 3.2.1 CAS

CAS 就是 **Compare And Swap（比较与交换）** ，用于实现乐观锁。CAS 的思想很简单，就是用一个预期值和要更新的变量值进行比较，两值相等才会进行更新。

CAS 涉及到三个操作数：

- **V**：要更新的变量值(Var)
- **E**：预期值(Expected)
- **N**：拟写入的新值(New)

当且仅当 V 的值等于 E 时，CAS 通过原子方式用新值 N 来更新 V 的值。如果不等，说明已经有其它线程更新了 V，则当前线程放弃更新。

当多个线程同时使用 CAS 操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。

> Java 语言并没有直接实现 CAS，CAS 相关的实现是通过 C++ 内联汇编的形式实现的（JNI 调用）。因此， CAS 的具体实现和操作系统以及 CPU 都有关系。

>  `sun.misc`包下的`Unsafe`类提供了`compareAndSwapObject`、`compareAndSwapInt`、`compareAndSwapLong`方法来实现的对`Object`、`int`、`long`类型的 CAS 操作。

**CAS 存在的问题：**

1. ABA问题：

   一个值初次读取的时候是 V，赋值的时候还是 V，并不能说明它没有改变过。可能修改了两次又变回了原值。解决方法： **加上版本号**

2. 循环时间长开销大：

   CAS 经常会用到自旋操作来进行重试，也就是不成功就一直循环执行直到成功。如果长时间不成功，会给 CPU 带来非常大的执行开销。



#### 3.2.2 synchronized

synchronized 主要解决的是多个线程之间访问资源的同步性，可以保 证被它修饰的方法或者代码块在任意时刻只能有⼀个线程执行。 在 Java 早期版本中， synchronized 属于 重量级锁，效率低下。 因为监视器锁（monitor）是依赖于 底层的操作系统的互斥锁 来实现的，需要频繁的内核态和用户态的转换。

 不过，在 Java 6 之后，Java 官方对从 JVM 层面对 synchronized 优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6 对锁的实现引⼊了大量的优化，如自旋锁、适应性 自旋锁、偏向锁、轻量级锁等技术来减少锁操作的开销。

##### 3.2.2.1 synchronized的使用

+ 修饰实例方法 （锁当前对象实例）
+ 修饰静态方法 （锁当前类）
+ 修饰代码块 （锁指定对象/类）

##### 3.2.2.2 synchronized 重量级锁（monitor） 底层原理

重量级锁的底层由monitor实现的，线程获得锁需要使用对象（锁）关联monitor，在monitor内部有三个属性，分别是owner、entrylist、waitset。其中owner是关联的获得锁的线程，并且只能关联一个线程；entrylist关联的是处于阻塞状态的线程；waitset关联的是处于Waiting状态的线程。monitor指令的执行是JVM通过调用操作系统的互斥原语mutex来实现，被阻塞的线程会被挂起、等待重新调度，会导致“用户态和内核态”两个态之间来回切换，对性能有较大影响。

##### 3.2.2.3 锁升级

JDK1.6之后的 Java中的synchronized有无锁、偏向锁、轻量级锁、重量级锁四种形式，且四种状态会随着竞争的情况逐渐升级，而且是不可逆的过程。

![output](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202407112215282.png)

##### 匿名偏向

在程序启动一段时间（可以通过 JVM 参数配置）之后，新建的对象的对象空间的对象头中（markword）都会被设置为偏向锁的类型，不过因为还没有线程占用它，所以markword中的 threadId 先为空，所以称为匿名偏向。在这段时间之前创建的的对象markword为无锁的状态。

##### 偏向锁

当执行到synchronized代码块时，无锁状态的对象会变成偏向锁，匿名偏向也会被赋值threadId，当然偏向锁可以通过 JVM 配置关闭，如果关闭就直接成为轻量级锁。或者当前对象执行过 hashcode 方法，也会禁用偏向锁，因为 非偏向锁的类型，在 markword 部分会保存一个hashcode字段，这个字段初始化为 空，执行完 hashcode 会被赋值，一旦被赋值就会禁用 偏向锁，因为偏向锁的 markword 部分没有 hashcode 字段。

当一个线程访问同步代码块并获取锁时，会在 Mark Word 里存储锁偏向的线程 ID。在线程进入和退出同步块时不再通过 CAS 操作来加锁和解锁，而是检测 Mark Word 里是否存储着指向当前线程的偏向锁。轻量级锁的获取及释放依赖多次 CAS 原子指令，而偏向锁只需要在置换 ThreadID 的时候依赖一次 CAS 原子指令即可。这也是为什么轻量级锁比偏向锁的级别更高。

偏向锁只适用于只有一个线程执行同步代码块的情况，一旦有第二个线程进入，偏向锁就会升级为轻量级锁。 

##### 轻量级锁（自旋锁）

轻量级锁的实现和偏向锁的差别不大，都是在线程栈中创建一个 Lock Record 对象，只不过偏向锁是在 markword 字段存储偏向锁的线程 id ，而轻量级锁的 markword 是存储 lock Record 的地址，所以这也导致了 轻量级锁的 每次重入 都要进行一次 CAS 操作。

在轻量级锁状态下继续锁竞争，没有抢到锁的线程将自旋，进入忙等状态。此忙等是有限度的（有个计数器记录自旋次数，默认允许循环10次，可以通过虚拟机参数更改）。如果锁竞争情况严重，某个达到最大自旋次数的线程，会将轻量级锁升级为重量级锁。当后续线程尝试获取锁时，发现被占用的锁是重量级锁，则直接将自己挂起（而不是忙等），等待将来被唤醒。

重量级锁是指当有一个线程获取锁之后，其余所有等待获取该锁的线程都会处于阻塞状态。简言之，就是所有的控制权都交给了操作系统，由操作系统来负责线程间的调度和线程的状态变更。而这样会出现频繁地对线程运行状态的切换，线程的挂起和唤醒，从而消耗大量的系统资。

