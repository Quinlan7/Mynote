### 项目中的技术应用

#### 1. 自己项目中的 AOP

在我们所开发的所有项目中，都是使用aop来记录系统的操作日志的，还有统计接口访问情况。主要是为了我们系统出现错误的时候快速定位，以及记录不同部门对我们服务的访问情况。

主要思路是这样的，我们是自定义了日志注解，然后使用aop中的环绕通知，对使用我们这个注解的所有方法做增强，我们通过环绕通知记录了接口响应时间、访问接口的ip、请求时间等，获取到这些参数以后，保存到数据库。



#### 2. Redis GEO

当时我们的业务需求是根据地道的坐标来查找地道附近的两条车道的交通状况，用以判断是否因为地道水位上涨导致交通堵塞。因为这个功能和经纬度的坐标有关系，一开始我们是直接每次请求那个地道的时候我们就计算所有路段和它的距离，但是这样计算速度有点慢，然后我们优化的时候，选择使用redis的GEO数据结构来实现，GEO底层使用的就是 Zset 的结构存储的，它把经纬度经过它的 GEOhash 算法计算为一个得分，作为 zset 的排序依据，然后由于这个算法的特性呢，地理位置距离近的元素排序总是接近的。所以它获取某个经纬度的临近数据就很快，当时我们是先把所有路段的经纬度和路段id存储了redis中，每当请求某个地道的时候，我们就直接用REDIS的GEO Search 去找离他最近的两个路段，然后用路段 id 再去找交通量。

#### 3 我的项目中的线程池使用

超限治理系统中：因为一超四罚（驾驶员、车辆、车辆所属企业、订单委托企业）政策的存在，所以治超系统大屏需要一个联动效果，左边展示了所有的超限车辆名单（车牌，时间，地点），点击某辆车的信息，右侧要展示 一超四罚的信息（人、车辆、车辆所属企业），所有信息都要使用大件运输许可的接口数据排除。

人和车辆的超限信息在我们单位的治超部门的数据库中，企业信息是在执法大队的数据库中，驾驶人黑名单是在我们自己的数据库中（因为这是我们自己定义的标准，不是官方的标准，当一个司机上个月超限超过三次加入黑名单），还有一个大件运输许可的接口数据。

原本的串行获取数据，再计算逻辑接口时间基本在两秒多，使用线程池和Future类来并行获取每个线程数据，接口速度优化到几百毫秒。具体实现就是定义了一个ExecutorService的Bean，使用线程池的submit方法来提交任务，然后用Future接收返回值，用Future的get方法获取结果。后面再进行逻辑处理。

##### 3.1 具体要获取那些信息呢

具体来说就是这个驾驶员 本月的的超限次数，平均超限百分比，联系方式，是否为黑名单成员；
车辆的超限次数，平均超限的百分比，车辆允许最大载重，实际承载最大重量；
车辆所属企业的，超限次数，拥有车辆数，联系人方式（企业重点关注的是超限车次占拥有车辆的百分比）；

##### 3.2 涉及哪些数据库，为什么不在一个数据库中

本接口涉及了，三个数据库，一个接口信息，我们单位治超部门的数据库，我们信息中心的数据库，执法大队的数据库，大件运输许可的接口。因为公路局的治超部门的主要任务是防止超重车辆压坏道路、桥梁这种道路基础设施，治超的执法权并不在公路局。所以我们的治超部门只有基本的超限信息，而执法大队则包含着比较全面的信息，包括物流企业的信息。使用了我们自己的数据库是因为这个黑名单的功能是我们自己设计的，不是官方标准，就用了自己的数据库存储。大件运输许可这个我也不清楚，我只知道他们那边这个数据只有接口提供。

##### 3.3 线程池的参数如何设计的

在接口中，用了线程池进行优化
主要的参数：

- 核心线程数选择的128，最大线程数选择的128（因为项目部署的服务器的64核的，然后处理的任务是获取不同数据源数据，本质是网络IO。所以选择了经验值2 * 8。）
- 阻塞队列选择的是链表阻塞队列，大小1024，这个是经验值。
- 拒绝策略选择是任务调用线程去执行。



#### 4 你们的数据量那么大，有没有分库分表

我们的业务时存在水平分表的，比如我们的ETC或者MTC数据，大约数据量一天在 20 到 40万之间，我们对这个数据的处理就是水平分表，因为它一个月的数据在一千万左右，我们当时是按照它的年月来分表的，一张表一个月的数据，表名中会带有年月，我们在代码中，或者数据同步中，都是用年月拼接表名，访问对应的数据。

还有一个数据就是 门架数据，这个数据量大概一天在四百万左右，这个表我们的处理方式是只保留一天的数据，每天凌晨之后首先用 oracle的 定时任务 完成对于这个表的清洗，先确保数据的正确性，因为我们的数据是接口数据，那边接口是每次只提供了五分钟的数据，并且可能会出现多提供了几十秒，或者少提供了几十秒的情况 ，可能出现重复数据。所以我们凌晨之后先oracle定时任务清洗数据，然后用springboot的定时任务，进行数据计算，包括计算每天的进津车流量，出津车流量，域内流量，每小时流量等，以提供给我们的业务功能使用。然后利用 dataX-Web 的定时任务将前一天的数据全部写到我们的hadoop的hdfs中，最后我们再删除表中前一天的所有数据。



> 服务器相关信息：
>
> + oracle数据库的硬盘空间：挂载的空间一共19T
> + hadoop集群空间： 一共十二台服务器，每个挂载空间都在5T
>
> oracle 存储信息：
>
> + 我们为每个业务都建立了独立的表空间，开启了分区机制（按天分区），并且开启了自动扩容机制
> + ETC和MTC的每月数据量：1-2GB
> + 门架数据每月数据量：15-20GB





#### 5 oracle 物化视图

**P：**这个是在我们接手的地道项目中遇到的问题，当时的一个大屏的展示功能接口，基本是在五分钟左右才会有响应，当时是要求我们优化这个接口的响应速度。

**A：**

+ **定位**：我们定位到了这个接口中的两个sql执行很慢基本在两三分钟。这两个sql都是查询的一张表，一个是设备在线的数据，一个是设备不在线的数据。我在 navicat 中执行对应的sql，发现很慢。
+ **解决：**
  + 首先，我先看了下数据量，是由三千多万的数据，并且没有主键，我觉得可能是数据量太大了，这种情况加索引也是很费时间的，我通过几个列查了一下发现有两千多万的重复的数据，这是因为这个表是记录地道水位高度的，传感器的更新频率并不稳定，有的一分多有的两分钟更新一次，然后我们的定时任务是一分钟一执行的，所以我先写了个循环删除数据的sql，一次50w然后commit，删除完数据之后，通过oracle Scheduler写了个定时任务，定时删除重复的数据。可以sql执行时间还是不理想，所以应该不是数据量的问题。 
  + 然后想到的都是优化sql语句，可以它的sql语句并不复杂，没有联表，只是有个日期的where，和聚合函数。但是这个日期字段他是个String，它使用了toDate函数将所有日期转为Date类型判断的，我没有想到什么好的方法可以处理这个String的日期字段，然后我就先尝试优化这个聚合函数，我是把这个查询作为了子查询，把聚合函数提出到外层，进行尝试。第一次执行我发现就几百毫秒，很意外，我还以为优化很有效呢，但是我多尝试了几次就发现，这个sql的执行时间是不稳定的，它大多数时间还是要三分钟才能执行完毕。然后我就觉得可能主要问题是锁，可能是每分钟的定时任务插入数据的时候都上了行锁，然后sql查询的也是最新的一段时间的数据，可能导致了慢sql。
  + 然后我使用了物化视图（使用中，我发现只有对应模式的用户可以创建物化视图，即使是管理员也没有权限，即使管理员给自己赋权也不能）使插入和检索分离开，并且将String类型的日期在物化视图中改为Date类型的，且只在物化视图中保留必要的字段，大大提高了检索速度，然后也是使用定时任务来更新物化视图。

**R：**优化之后整体接口的速度基本在五百毫秒左右，响应速度大幅提升，但是相应的实时性上要比之前差一点，因为是定时更新的物化视图嘛。





### 反问问题

#### 技术面

1. 我想了解一下咱们公司对于应届生的培养与管理时怎么样的
2. 咱们公司的晋升机制是怎么样的？多久考核一次？有没有量化指标？
3. 如果进入贵公司，我会进入那个部门，做什么样的业务，就是岗位职责是什么
4. 我们的对接人或者是客户是谁？是开发中间件还是面向用户



#### HR面

1. 您能介绍一下我们部门在整个业务环节中扮演的角色吗？
2. 新员工入职的培训流程/培养机制？
3. 团队总共有多少人？
4. 公司/部门的氛围如何？工作节奏怎么样？
5. 公司的薪资结构是什么样的，公积金的缴纳比例。
6. 能不能提前进入公司实习，实习期多长能转正