#### 1. 自己项目中的 AOP

在我们所开发的所有项目中，都是使用aop来记录系统的操作日志的，还有统计接口访问情况。主要是为了我们系统出现错误的时候快速定位，以及记录不同部门对我们服务的访问情况。

主要思路是这样的，我们是自定义了日志注解，然后使用aop中的环绕通知，对使用我们这个注解的所有方法做增强，我们通过环绕通知记录了接口响应时间、访问接口的ip、请求时间等，获取到这些参数以后，保存到数据库。



#### 2. Redis GEO

当时我们的业务需求是根据地道的坐标来查找地道附近的两条车道的交通状况，用以判断是否因为地道水位上涨导致交通堵塞。因为这个功能和经纬度的坐标有关系，一开始我们是直接每次请求那个地道的时候我们就计算所有路段和它的距离，但是这样计算速度有点慢，然后我们优化的时候，选择使用redis的GEO数据结构来实现，GEO底层使用的就是 Zset 的结构存储的，它把经纬度经过它的 GEOhash 算法计算为一个得分，作为 zset 的排序依据，然后由于这个算法的特性呢，地理位置距离近的元素排序总是接近的。所以它获取某个经纬度的临近数据就很快，当时我们是先把所有路段的经纬度和路段id存储了redis中，每当请求某个地道的时候，我们就直接用REDIS的GEO Search 去找离他最近的两个路段，然后用路段 id 再去找交通量。

#### 3 我的项目中的线程池使用

超限治理系统中：因为一超四罚（驾驶员、车辆、车辆所属企业、订单委托企业）政策的存在，所以治超系统大屏需要一个联动效果，左边展示了所有的超限车辆名单（车牌，时间，地点），点击某辆车的信息，右侧要展示 一超四罚的信息（人、车辆、车辆所属企业），所有信息都要使用大件运输许可的接口数据排除。

人和车辆的超限信息在我们单位的治超部门的数据库中，企业信息是在执法大队的数据库中，驾驶人黑名单是在我们自己的数据库中（因为这是我们自己定义的标准，不是官方的标准，当一个司机上个月超限超过三次加入黑名单），还有一个大件运输许可的接口数据。

原本的串行获取数据，再计算逻辑接口时间基本在两秒多，使用线程池和Future类来并行获取每个线程数据，接口速度优化到几百毫秒。具体实现就是定义了一个ExecutorService的Bean，使用线程池的submit方法来提交任务，然后用Future接收返回值，用Future的get方法获取结果。后面再进行逻辑处理。

##### 3.1 具体要获取那些信息呢

具体来说就是这个驾驶员 本月的的超限次数，平均超限百分比，联系方式，是否为黑名单成员；
车辆的超限次数，平均超限的百分比，车辆允许最大载重，实际承载最大重量；
车辆所属企业的，超限次数，拥有车辆数，联系人方式（企业重点关注的是超限车次占拥有车辆的百分比）；

##### 3.2 涉及哪些数据库，为什么不在一个数据库中

本接口涉及了，三个数据库，一个接口信息，我们单位治超部门的数据库，我们信息中心的数据库，执法大队的数据库，大件运输许可的接口。因为公路局的治超部门的主要任务是防止超重车辆压坏道路、桥梁这种道路基础设施，治超的执法权并不在公路局。所以我们的治超部门只有基本的超限信息，而执法大队则包含着比较全面的信息，包括物流企业的信息。使用了我们自己的数据库是因为这个黑名单的功能是我们自己设计的，不是官方标准，就用了自己的数据库存储。大件运输许可这个我也不清楚，我只知道他们那边这个数据只有接口提供。

##### 3.3 线程池的参数如何设计的

在接口中，用了线程池进行优化
主要的参数：

- 核心线程数选择的128，最大线程数选择的128（因为项目部署的服务器的64核的，然后处理的任务是获取不同数据源数据，本质是网络IO。所以选择了经验值2 * 8。）
- 阻塞队列选择的是链表阻塞队列，大小1024，这个是经验值。
- 拒绝策略选择是任务调用线程去执行。



#### 4 你们的数据量那么大，有没有分库分表

我们的业务时存在水平分表的，比如我们的ETC或者MTC数据，大约数据量一天在 20 到 40万之间，我们对这个数据的处理就是水平分表，因为它一个月的数据在一千万左右，我们当时是按照它的年月来分表的，一张表一个月的数据，表名中会带有年月，我们在代码中，或者数据同步中，都是用年月拼接表名，访问对应的数据。

还有一个数据就是 门架数据，这个数据量大概一天在四百万左右，这个表我们的处理方式是只保留一天的数据，每天凌晨之后首先用 oracle的 定时任务 完成对于这个表的清洗，先确保数据的正确性，因为我们的数据是接口数据，那边接口是每次只提供了五分钟的数据，并且可能会出现多提供了几十秒，或者少提供了几十秒的情况 ，可能出现重复数据。所以我们凌晨之后先oracle定时任务清洗数据，然后用springboot的定时任务，进行数据计算，包括计算每天的进津车流量，出津车流量，域内流量，每小时流量等，以提供给我们的业务功能使用。然后利用 dataX-Web 的定时任务将前一天的数据全部写到我们的hadoop的hdfs中，最后我们再删除表中前一天的所有数据。



> 服务器相关信息：
>
> + oracle数据库的硬盘空间：挂载的空间一共19T
> + hadoop集群空间： 一共十二台服务器，每个挂载空间都在5T
>
> oracle 存储信息：
>
> + 我们为每个业务都建立了独立的表空间，开启了分区机制（按天分区），并且开启了自动扩容机制
> + ETC和MTC的每月数据量：1-2GB
> + 门架数据每月数据量：15-20GB





#### 5 oracle 物化视图