# MQ

[TOC]

## 一、MQ 基础

### 1.1 为什么使用消息队列

**三大作用**

+ 解耦：传统的软件开发模式，各个模块之间相互调用，数据共享，每个模块都要时刻关注其他模块的是否更改或者是否挂掉等等，使用消息队列，可以避免模块之间直接调用，将所需共享的数据放在消息队列中，对于新增业务模块，只要对该类消息感兴趣，即可订阅该类消息，对原有系统和业务没有任何影响，降低了系统各个模块的耦合度，提高了系统的可扩展性。
+ 异步：消息的发送和接收可以在不同的时间发生，而不需要立即同步。这有助于提升系统的响应速度和处理能力。例如，用户提交一个订单后，系统可以将订单信息放入消息队列中，然后由后台服务异步处理订单，而不必让用户等待订单处理完成。
+ 削峰：削峰指的是通过将请求或任务平滑地分布到一段时间内来避免瞬时负载过高。消息队列可以将瞬时的高负载任务放入队列中，并按照一定的速度逐步处理这些任务。这样，可以减少系统在高负载情况下的压力，保持系统的稳定性和性能。例如，在电商促销期间，高并发的订单请求可以通过消息队列逐步处理，从而避免系统的瞬时过载。

**我的项目：**

主要是实现一个延时发布的功能，其实是让业务实现了异步。使用了 direct 模式，用 TTL 和 死信队列实现 延迟上线的功能。



### 1.2 技术选型

选择中间件的可以从这些维度来考虑：可靠性，性能，功能，可运维行，可拓展 性，社区活跃度。目前常用的几个中间件，ActiveMQ作为“老古董”，市面上用的已 经不多，其它几种： 

RabbitMQ： 

+ 优点：轻量，迅捷，容易部署和使用，拥有灵活的路由配置 
+ 缺点：吞吐量不太理想，不易进行二次开发 

RocketMQ： 

+ 优点：性能好，高吞吐量，稳定可靠，有活跃的中文社区 
+ 缺点：兼容性上不是太好 

Kafka： 

+ 优点：拥有强大的性能及吞吐量，兼容性很好 
+ 缺点：响应延迟比较高 

因为 RabbitMQ 的社区活跃度 比较高，我们有什么问题比较好找到解决方案，所以选用了 Rabbit MQ。

![image-20240912101923685](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202409121019892.png)



![image-20241010201833033](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202410102018172.png)



**总结：**

- ActiveMQ 的社区算是比较成熟，但是较目前来说，ActiveMQ 的性能比较差，而且版本迭代很慢，不推荐使用。
- RabbitMQ 在吞吐量方面虽然稍逊于 Kafka 和 RocketMQ ，但是由于它基于 erlang 开发，所以并发能力很强，性能极其好，延时很低，达到微秒级。但是也因为 RabbitMQ 基于 erlang 开发，所以国内很少有公司有实力做 erlang 源码级别的研究和定制。如果业务场景对并发量要求不是太高（十万级、百万级），那这四种消息队列中，RabbitMQ 一定是你的首选。如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。
- RocketMQ 阿里出品，Java 系开源项目，源代码我们可以直接阅读，然后可以定制自己公司的 MQ，并且 RocketMQ 有阿里巴巴的实际业务场景的实战考验。RocketMQ 社区活跃度相对较为一般，不过也还可以，文档相对来说简单一些，然后接口这块不是按照标准 JMS 规范走的有些系统要迁移需要修改大量代码。还有就是阿里出台的技术，你得做好这个技术万一被抛弃，社区黄掉的风险，那如果你们公司有技术实力我觉得用 RocketMQ 挺好的
- Kafka 的特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms 级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展。同时 kafka 最好是支撑较少的 topic 数量即可，保证其超高吞吐量。kafka 唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略这个特性天然适合大数据实时计算以及日志收集。





## 二、Rabbit MQ

### 2.1 如何保证消息不丢失

RabbitMQ丢失消息分为如下几种情况：

1. **生产者丢消息**：

   生产者将数据发送到RabbitMQ的时候，可能在传输过程中因为网络等问题而将数据弄丢了。

2. **RabbitMQ自己丢消息**：

   Rabbit MQ 是基于内存的，和 Redis 一样，如果 Rabbit MQ 宕机，则消息队列里的所有数据都会丢失。

3. **消费端丢消息**：

   主要是因为消费者消费时，如果出现异常，比如消费者重启了，RabbitMQ就认为你已经消费过了，然后就丢了数据。

针对上述三种情况，RabbitMQ可以采用如下方式避免消息丢失：

1. 生产者丢消息：

   - 可以选择使用RabbitMQ提供是事务功能，就是生产者在发送数据之前开启事务，然后发送消息，如果消息没有成功被RabbitMQ接收到，那么生产者会受到异常报错，这时就可以回滚事务，然后尝试重新发送。如果收到了消息，那么就可以提交事务。这种方式有明显的缺点，即RabbitMQ事务开启后，就会变为同步阻塞操作，生产者会阻塞等待是否发送成功，太耗性能会造成吞吐量的下降。
   - 可以开启confirm模式。在生产者那里设置开启了confirm模式之后，每次写的消息都会分配一个唯一的id，然后如果写入了RabbitMQ之中，RabbitMQ会给你回传一个ack消息，告诉你这个消息发送OK了。如果RabbitMQ没能处理这个消息，会回调一个nack接口，通知这个消息丢失了，可以进行重试。

   事务机制是同步的，你提交了一个事物之后会阻塞住，但是confirm机制是异步的，发送消息之后可以接着发送下一个消息，然后RabbitMQ会回调告知成功与否。 一般在生产者这块避免丢失，都是用confirm机制。

2. RabbitMQ自己丢消息：

   要想确保消息在RabbitMQ中安全保存，必须开启消息持久化机制。

   - 交换机持久化
   - 队列持久化
   - 消息持久化：利用SpringAMQP发送消息时，可以设置消息的属性，指定delivery-mode（默认就是持久化的）：
     - 1：非持久化
     - 2：持久化

3. 消费端丢消息：

   RabbitMQ是通过消费者回执来确认消费者是否成功处理消息的：消费者获取消息后，应该向RabbitMQ发送ACK回执，表明自己已经处理消息。而SpringAMQP则允许配置三种确认模式：

   + manual：手动ack，需要在业务代码结束后，调用api发送ack。

   + auto：自动ack，由spring监测listener代码是否出现异常，没有异常则返回ack；抛出异常则返回nack

   + none：关闭ack，MQ假定消费者获取消息后会成功处理，因此消息投递后立即被删除

   当消费者出现异常后，消息会不断requeue（重入队）到队列，再重新发送给消费者，然后再次异常，再次requeue，无限循环，导致mq的消息处理飙升，带来不必要的压力。这时候我们可以使用**消费失败重试机制**，利用Spring的retry机制，在消费者出现异常时利用本地重试，当重试了几次都是失败后，就会按我们配置的失败策略执行。消息失败，会通过MessageRecovery接口来处理，它包含三种不同的实现：失败策略：

   - RejectAndDontRequeueRecoverer：重试耗尽后，直接reject，丢弃消息。默认就是这种方式

   - ImmediateRequeueMessageRecoverer：重试耗尽后，返回nack，消息重新入队

   - RepublishMessageRecoverer：重试耗尽后，将失败消息投递到指定的交换机


#### 2.1.1 为什么不对所有的message都持久化

首先，是因为持久化必然导致性能的下降，因为写磁盘比写内存慢的多，message 的吞吐量可能有很多倍的差距。 

所以，是否要对 message 进行持久化，需要综合考虑性能需要，以及可能遇到的服务宕机问题。另外一种处理原则是： 仅对关键消息作持久化处理（根据业务重要程度），且应该保证关键消息的量不会导致性能瓶颈。

### 2.2 如何保证顺序消费

首先呢，顺序消费的业务需求一般是出现在针对某条数据，或者某个人的数据需要保证顺序修改，防止数据异常。并且我们的 MQ 的架构呢，一般是一个 queue 对应多个 consumer。

所以对应的解决方案一般分为两种，不过这两种的共同点是都是一个 queue 对应一个 consumer：

+ 我们可以根据业务将 queue 划分为多个 queue，每个队列对应一个 consumer，每个队列单独处理需要顺序消费的业务数据，
+ 我们也可以只使用一个 queue，但是也是对应一个 consumer，然后我们在这个 consumer 业务内部，依然通过不同的业务规则，为每组需要顺序消费的业务划分一个队列，然后多线程去消费不同的队列，这样我们有顺序依赖的业务可以保证顺序消费。没有顺序依赖的业务可以并行。



### 2.3 RabbitMQ消息的重复消费问题如何解决的

首先在正常情况下，因为有消息确认机制，一般是不会出现重复消费的问题的，但是如果由于网络等问题导致 确认消息已消费的 ACK 没有发送到 消息队列，那么消息队列就会再次发送消息，导致重复消费。  

其实这个问题的解决思路主要就是保证消息消费的幂等性，具体的实现思路有很多种，比如：把写入消息队列的数据做唯一标示，消费消息时，我们可以通过redis等中间件记录已经被消费的消息id，根据唯一标识判断是否消费过；或者通过我们的具体业务保证幂等性，比如如果我们的消费者业务是插入数据，那么我们就可以通过实体的唯一id，来保证不插入重复数据。或者如果是redis的消费业务，redis天然就是幂等性的，因为set操作无论多少次都没有影响。



### 2.4 消息积压的处理

其实消息积压的问题根源就在于 消费者消费的速度跟不上生产者的生产速度，导致队列堆积很长，把服务器内存耗尽，导致RabbitMQ的处理能力低下。

+ 如果是经常发生的情况，说明我们的消费者就是跟不上生产速度了，其实根源性的解决方案就是增加消费者实例，也就是增加机器。
+ 如果只是偶尔一次，或者可预见性的业务热点时间段（比如双十一），我们可以通过临时上线更多的消费者，并且可以专门增加一些消费者，不做业务处理，只把消息记录到数据库中，等待业务热度下来，再离线处理。

我看有一种说法是使用 惰性队列，就是把MQ的消息全部保存在磁盘中，其实我认为这样做的效果一般，因为使用惰性队列就一定会影响消费者的消费速度，因为磁盘的速度一定比内存慢的多，消息积压的问题根据就是消费者的消费速度，使用惰性队列又降低了消费速度，所以我认为不如在消费者中将消息存数据库。惰性队列应该是用于在MQ服务容易宕机的情形下使用吧。



### 2.5 死信交换机 （延迟队列）

我们当时的三全育人项目有一个活动延时上线的业务，需要用到延迟队列，其中就是使用RabbitMQ来实现的。

延迟队列就是用到了死信交换机和TTL（消息存活时间）实现的。

如果消息超时未消费就会变成死信，在RabbitMQ中如果消息成为死信，队列可以绑定一个死信交换机，在死信交换机上可以绑定其他队列，在我们发消息的时候可以按照需求指定TTL的时间，这样就实现了我们需要的延迟队列的功能。并且我们实现的时候是简单的在数据库中使用了一个是否上线的字段，我们消费消息的时候直接把对应id的活动字段直接置为1即可。

我知道RabbitMQ还有一种方式可以实现延迟队列，在RabbitMQ中安装一个延时交换机插件（DelayExchange），这样更方便一些，我们只需要在声明交互机的时候，指定delayed属性为true即可，然后在发送消息的时候直接指定超时时间就行了，相对于死信交换机+TTL要省略了一些步骤



### 2.6 RabbitMQ的高可用机制

因为使用惰性队列来保证消息队列中消息的可靠性，会产生较大的性能问题，所以 RabbitMQ提供了高可用的集群架构来保证队列中消息的可靠性。

RabbitMQ 有两种集群模式：普通集群模式、镜像集群模式。 

+ 普通集群模式：你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某 个 queue 的读写操作。 
+ 镜像集群模式：这种模式，才是所谓的 RabbitMQ 的高可用模式。在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存 在于多个实例上。我们可以配置镜像集群的策略，可以让数据同步到所有节点，也可以同步到指定数量的节点。这样的话，可以保证 MQ 中消息的可靠性。坏处在于性能开销很大，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！



### 2.7 仲裁队列

基于 Raft 协议的分布式队列。Quorum是基于Raft一致性协议实现的一种新型的分布式消息队列。简单理解就是quorum队列中的消息需要有集群中多半节点同意确认后，才会写入到队列中。这种方式可以保证消息在集群内部不会丢失。同时，Quorum是以牺牲很多高级队列特性为代价，来进一步保证消息在分布式环境下的高可靠。从整体功能上来说，Quorum队列是在Classic经典队列的基础上做减法，因此对于RabbitMQ的长期使用者而言，其实是会影响使用体验的。



