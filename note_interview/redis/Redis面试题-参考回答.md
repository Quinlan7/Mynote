# Redis相关面试题

[TOC]

### 一、什么是缓存穿透 ? 怎么解决 ?

**候选人**：

嗯~~，我想一下

缓存穿透是指查询一个一定**不存在**的数据，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到 DB 去查询，可能导致 DB 挂掉。这种情况大概率是遭到了攻击。

解决方案的话，在我们的项目中都是用缓存空对象解决的，当然也可以用布隆过滤器解决，因为我们的项目都是公司内网的服务，一般不会被攻击，所以就使用了较为简单的缓存null值来解决了。当然这样的方式也有一定的缺点，因为这样会带来额外的内存的消耗。

**面试官**：好的，你能介绍一下布隆过滤器吗？

**候选人**：

嗯，是这样~

布隆过滤器主要是用于检索一个元素是否在一个集合中。可以直接使用redisson实现的布隆过滤器。

它的底层主要是先去初始化一个比较大数组，里面存放的二进制0或1。在一开始都是0，当一个key来了之后经过3次hash计算，模于数组长度找到数据的下标然后把数组中原来的0改为1，这样的话，三个数组的位置就能标明一个key的存在。查找的过程也是一样的。

当然是有缺点的，布隆过滤器有可能会产生一定的误判，我们一般可以设置这个误判率，大概不会超过5%，其实这个误判是必然存在的，因为布隆过滤器的实现就是基于哈希的，哈希算法一定会带来哈希碰撞的问题。5%以内的误判率一般的项目也能接受，不至于高并发下压倒数据库。



### 二、什么是缓存击穿 ? 怎么解决 ?

**候选人**：

嗯！！

缓存击穿的意思是一个被高并发访问并且缓存重建业务较复杂的key，缓存在某个时间点过期的时候，恰好这时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期，一般都会从后端 DB 加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把 DB 压垮。

解决方案有两种方式：

+ 第一可以使用互斥锁：

因为锁能实现互斥性。假设线程过来，只能一个人一个人的来访问数据库，从而避免对于数据库访问压力过大，但这也会影响查询的性能，因为此时会让查询的性能从并行变成了串行，我们可以采用==tryLock方法==来解决这样的问题。

假设现在线程1过来访问，他查询缓存没有命中，但是此时他获得到了锁的资源，那么线程1就会一个人去访问数据库并且重建缓存，假设现在线程2过来，线程2在执行过程中，并没法获得到锁，那么线程2就可以进行到休眠，然后重试访问缓存请求数据。

![image-20240622162800930](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202406221628022.png)

+ 第二种方案可以设置当前key逻辑过期，大概是思路如下：

①：在设置key的时候，设置一个过期时间字段一块存入缓存中，不给当前key设置过期时间

②：当查询的时候，从redis取出数据后判断时间是否过期

③：如果过期则开通另外一个线程进行数据同步，当前线程正常返回数据，这个数据不是最新

![image-20240622162937481](https://raw.githubusercontent.com/Quinlan7/pic_cloud/main/img/202406221629601.png)

当然两种方案各有利弊：

**互斥锁方案：（强一致性、低性能）**由于保证了互斥性，所以数据一致，且实现简单，因为仅仅只需要加一把锁而已，也没其他的事情需要操心，所以没有额外的内存消耗，缺点在于有锁就有死锁问题的发生，且只能串行执行性能肯定受到影响

**逻辑过期方案：（高可用，高性能，存在短期数据不一致性）** 线程读取过程中不需要等待，性能好，有一个额外的线程持有锁去进行重构数据，但是在重构数据完成前，其他的线程只能返回之前的数据，且实现起来麻烦





### 三、什么是缓存雪崩 ? 怎么解决 ?

**候选人**：

嗯！！

缓存雪崩是指在同一时段大量的缓存key同时失效或者Redis服务宕机，导致大量请求到达数据库，带来巨大压力。

> 同一时间大量key失效，可能是因为缓存预热时，大量key同时加载并且TTL相同

解决方案：

* 给不同的Key的TTL添加随机值
* 利用Redis集群提高服务的可用性
* 给缓存业务添加降级限流策略（快速失败，限流）
* 给业务添加多级缓存 （Nginx，Lua，Caffine）





### 四、redis做为缓存，mysql的数据如何与redis进行同步呢？（双写一致性）

**回答**：嗯！在我之前的项目，里面有缓存热点数据的功能，因为热点数据并不要求强一致性，可以存在短暂的数据不一致，所以我们选择了比较简单的解决方案：**先更新数据库，再删除缓存**，如果是写操作，我们先更新数据库，最后再删除缓存中的数据。



**问题：你听说过延时双删吗？为什么不用它呢？**

**回答**：延迟双删，最主要要解决的问题是在**读写分离+主从库延迟**的情况下产生的问题，如果不是这种情况的话，延迟双删要解决的问题的前置条件其实是：一个线程 读数据库+写缓存的时间 大于 一个线程 写数据库 + 删缓存的时间，这种情况乱在 非数据库集群（主从库数据更新没有延迟）的情况下很难发生，因为写数据库要加锁，一般写数据库时间都是比都数据库时间长的。所以由于我们的数据库并非主从库所以没有选择这种解决方案。



**问题**：**谈谈强一致性场景的双写一致性问题**

**回答**：如果是需要保持强一致性的场景下，可以采用的读写锁保证的强一致性。

可以采用redisson实现的读写锁，在读的时候添加共享锁，可以保证读读不互斥，读写互斥。当我们更新数据的时候，添加排他锁，读写，读读都互斥，这样就能保证在写数据的同时是不会让其他线程读数据的，避免了脏数据。只不过这样做的话，性能会比较低。



**问题：其他的非强一致性场景下的解决方案，异步方案**

**回答**：可以采用的阿里的**canal**组件实现数据同步：不需要更改业务代码，部署一个canal服务。canal服务把自己伪装成mysql的一个从节点，当mysql数据更新以后，canal会读取binlog数据，然后在通过canal的客户端获取到数据，更新缓存即可，这样可以作到对代码的零侵入。

或者可以使用 **MQ** 异步更新数据库：更新玩缓存之后，给MQ发消息，让别的服务去更新数据库，其可靠性由消息队列保证。





### 五、redis做为缓存，数据的持久化是怎么做的？

**回答**：在Redis中提供了三种数据持久化的方式：1、RDB   2、AOF  3、RDB-AOF混合持久化



**问题：详细介绍一下RDB持久化**

RDB是一个快照文件，它是把redis内存存储的数据写到磁盘上，当redis实例宕机恢复数据的时候，直接从RDB的快照文件中恢复数据，这样恢复数据属于比较快的方式，因为RDB文件是经过压缩的二进制文件，但是也会存在一些问题，因为自保存快照的时间到redis宕机的时间 之间的数据会丢失，会有数据不一致问题。



**问题：RDB的copy on write 机制了解吗**

copy on write机制是在RDB持久化执行 bgsave 命令时的一种机制。当redis执行bgsave命令时会先执行 fork 命令，创建子进程。然后由子进程执行 bgsave 命令，由于子进程和父进程都是访问内存中的redis数据，当主进程执行读操作时，会共享内存。当主进程执行写操作时，由于子进程在执行读操作，会出现读脏数据问题，所以主进程会在执行写操作时，先 copy 一个数据的副本，对副本进行写操作，这就是 copy on write。



**问题：详细介绍一下AOF持久化**

AOF的含义是追加文件，当redis操作写命令的时候，都会存储在 AOF 文件中，当redis实例宕机恢复数据的时候，会从这个文件中再次执行一遍命令来恢复数据。这种方式的优点就是数据一致性比 RDB 要好很多，并且通过配置 appendfsync 选项可以控制对AOF文件执行一次写操作的机制，可以是每条命令都写一次，或者一秒写一次，或者由操作系统决定写的时机。但是缺点是使用AOF文件恢复时，执行速度很慢，而且AOF文件体积较大，因为存储的是协议文本。



**问题：AOF 重写机制了解吗**

AOF重写是因为AOF中许多命令都会冗余，因为对同一个变量的两次写，互让上一次写操作失效，所以有了AOF重写来减小AOF文件的大小。AOF 重写可以产生⼀个新的 AOF 文件，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库数据一样，但体积更小。这个功能是通过读取数据库中的键值对来实现的，程序无须对现有  AOF 文件进行任何操作。 在执行  BGREWRITEAOF 命令时，Redis 服务器会维护⼀个 AOF 重写缓冲区，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令。当子进程完成创建新 AOF 文件的工作之 后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新的 AOF 文件保存的数 据库状态与现有的数据库状态⼀致。最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完 成 AOF 文件重写操作。



**问题：Redis 4.0 对于持久化机制做了什么优化？**

Redis从4.0开始引入RDB-AOF混合持久化模式。Redis服务器在执行AOF重写操作时，会按照如下原则处理数据：

- 像执行BGSAVE命令一样，根据数据库当前的状态生成相应的RDB数据，并将其写入AOF文件中；
- 对于重写之后执行的Redis命令，则以协议文本的方式追加到AOF文件的末尾，即RDB数据之后。

通过使用RDB-AOF混合持久化，用户可以同时获得RDB持久化和AOF持久化的优点，服务器既可以通过AOF文件包含的RDB数据来实现快速的数据恢复操作，又可以通过AOF文件包含的AOF数据来将丢失数据的时间窗口限制在1s之内。







### 六、Redis的数据过期策略有哪些 ? 

**回答**：

嗯~，在redis中提供了两种数据过期删除策略

**第一种是 惰性删除**：在设置该key过期时间后，我们不去管它，当访问该key时，我们检查其是否过期，如果过期，我们就删掉它。这种方式的优点是每次访问的时候才会检查key是否过期，对cpu友好，不怎么消耗cpu资源，但同样的缺点就是对于内存不友好。

**第二种是 定期删除**：就是说每隔一段时间，我们就对**一部分**key（最多20个，因为可能带有过期时间的key不足20个）进行检查，删除里面过期的key。如果过期key的比例超过某一阈值，则redis会进行循环继续选取一部分key进行删除，该阈值可以配置。并且这种策略有两种模式，一种slow，一种fast模式，顾名思义一个频率快一个频率慢，并且每次删除任务的执行时长有上限，防止占用过多的cpu资源。这种策略对内存友好，对cpu不友好。

Redis的过期删除策略：**惰性删除 + 定期删除**两种策略进行配合使用。

>  定期清理的两种模式：
>
> + SLOW模式是定时任务，执行频率默认为10hz，每次不超过25ms，以通过修改配置文件redis.conf 的 **hz** 选项来调整这个次数
> + FAST模式执行频率不固定，每次事件循环会尝试执行，但两次间隔不低于2ms，每次耗时不超过1ms

> 另外，为避免主线程长时间阻塞，提供了两个主要条件限制：
>
> + timelimit：`时间限制`。不管是快删除还是慢删除，都会计算一个合理的删除时间上限，避免删除时间过长，这是全局限制。
> + config_cycle_acceptable_stale：`过期 key 占比限制`。计算当前 DB 过期 key 的比例 p ，当 p > config_cycle_acceptable_stale 则继续循环定期删除。该参数可配置。

 





### 七、Redis的数据淘汰策略有哪些 ? 

**回答**：

嗯，redis共有八种数据淘汰策略，默认是noeviction，不删除任何数据，内部不足直接报错。数据淘汰策略可以在redis的配置文件中进行设置的。

数据淘汰策略还有volatile-ttl：从已设置过期时间的数据集中挑选最快要过期的数据淘汰。

还有 allkeys-random 和 volatile-random ：allkeys就表示在所有的键中，volatile就表示在设有过期时间的键中，random表示随机淘汰，这种策略可能会删除热点数据，所以一般不使用。

还有 allkeys-lru 和 volatile-lru ：同样lru表示最近最少使用策略，优先淘汰最近最少使用的，这种策略使用较多，因为可以保留热点数据。

还有 allkeys-lfu 和 volatile-lfu：这是Redis4.0新增加的策略，lfu就表示最近使用频率最少的优先淘汰。



**问题：数据库有1000万数据 ,Redis只能缓存20w数据, 如何保证Redis中的数据都是热点数据 ?**

可以使用 allkeys-lru 淘汰策略，那留下来的都是经常访问的热点数据

> 1. volatile-lru：从已设置过期时间的数据集中挑 选最近最少使用的数据淘汰 
>
> 2. volatile-ttl：从已设置过期时间的数据集中挑选最快要过期的数据淘汰 
>
> 3. volatile-random：从已设置过期时间的数据集中任意选择数据淘汰 
>
> 4. allkeys-lru：在所有键中，移除最近最少使用的 key（这个是最常⽤的） 
>
> 5. allkeys-random：从数据集中任意选择数据淘汰 
>
> 6. no-eviction：禁⽌驱逐数据，也就是说当内存不⾜以容纳新写⼊数据时，新写入操作会报错。  
>
>    **4.0 版本后增加以下两种：** 
>
> 7. volatile-lfu：从已设置过期时间的数据集中挑选最不经常使用的数据淘汰 
>
> 8. allkeys-lfu：在所有键中，移除最不经常使用的 key





### 八、Redis分布式锁如何实现 ? 

**回答**：

原生的实现分布式锁的方式是，在使用 redis 中提供的一个命令setnx(SET if not exists)，设置完锁之后，相当于获取了锁，在没有过期或删除key的时候是其他客户端是不能获取这个锁的。

但是这种实现方式其实有很多问题，比如（**四大问题：重入问题、不可重试、超时释放、主从一致性**）为了防止死锁问题，我们都会给锁设置过期时间，可是这个过期时间很难把握，万一进程还没有释放锁，但是过期时间已经到了，就会产生很多问题，所以我们一般直接使用 redisson 实现的锁。



**问题： Redisson实现的分布式锁如何解决超时释放问题的呢？**

**回答**：

在redisson中引入了一个看门狗机制，其实就是使用另一个线程监控当前线程，每隔一段时间（默认10s，releaseTime/3）就检查当前业务是否还持有锁，如果持有就刷新锁的持续时间，当业务执行完成之后释放锁就可以了。如果业务宕机了，看门狗的线程也宕机，锁就会在规定时间解锁。



**问题： Redisson实现的分布式锁如何解决不可重试问题的呢？**

**回答**：

redisson的锁重试机制利用了redis 的发布订阅模式 和 信号量，而非一直while循环可以有效降低cpu资源的使用，当发现锁被占用后 会先等待，当检测到我们要获取的锁被释放了之后才会继续后边的逻辑。第一次获取锁失败会用redis订阅当前锁，而锁在释放时也会发布消息，虽然在锁释放后才重试，但是可能等待的进程同时有很多，也可能抢不到锁，所以如果再次发现锁被占用就会利用信号量的机制等待锁释放，后面都是循环利用信号量机制等待，知道获取到锁，或者达到最大等待时间。



**问题：redisson实现的分布式锁如何解决重入问题？**

**回答**：

redisson在存储数据的时候采用的hash结构，外层key可以按照自己的业务进行定制，内层key是当前线程的唯一标识，value是当前线程重入的次数。重入其实就是在内部判断是否是当前线程持有的锁，如果是当前线程持有的锁就会计数加一，如果释放锁就会在计算上减一。



**问题：redisson实现的分布式锁能解决主从一致性的问题吗**

**回答**：

可以的，但是要使用红锁或者联锁，主从一致性问题就是：当线程1加锁成功后，master节点数据会异步复制到slave节点，此时当前持有Redis锁的master节点宕机，slave节点被提升为新的master节点，假如现在来了一个线程2，再次加锁，会在新的master节点上加锁成功，这个时候就会出现两个节点同时持有一把锁的问题。

我们可以利用redisson提供的红锁来解决这个问题，它的主要作用是，不能只在一个redis实例上创建锁，应该是在多个redis实例上创建锁，并且要求在大多数redis节点上都成功创建锁，红锁中要求是redis的节点数量要过半。而联锁是要求在所有的节点都成功创建锁。这样就能避免线程1加锁成功后master节点宕机导致线程2成功加锁到新的master节点上的问题了。

但是，如果使用了红锁或者联锁，因为需要同时在多个节点上都添加锁，性能就变的很低了，并且运维维护成本也非常高。



**问题：如果业务非要保证数据的强一致性，这个该怎么解决呢？**

**回答：**

如果有强一致性要求高的业务，建议使用zookeeper实现的分布式锁，它是可以保证强一致性的。









### 九、Redis集群有哪些方案, 知道嘛 ? （了解，偏运维）

**回答**：

在Redis中提供的集群方案总共有三种：主从模式、哨兵模式、Redis分片集群。

**主从模式**：单节点Redis的并发能力是有上限的，要进一步提高Redis的并发能力，可以搭建主从集群，实现读写分离。一般都是一主多从，主节点负责写数据，从节点负责读数据，主节点写入数据之后，需要把数据同步到从节点中。

**哨兵模式：**为了应对单点故障问题，实现主从集群的自动故障恢复，redis提供了哨兵模式。可以使用几个节点作为哨兵来监控集群状态。

**分片集群：**为了应对海量数据问题，redis提供了分片集群，一种无中心的结构，包含多个master节点，每个master又包含多个slaver节点。master之间通过ping监测彼此健康状态，相当于哨兵节点。每个master保存不同的数据，根据每个master所映射的插槽的标号。





**问题：能说一下，主从同步数据的流程**

**回答**：

主从同步分为了两个阶段，一个是**全量同步**，一个是**增量同步**

**全量同步**：当从节点第一次连接到主节点时，会做全量同步，通过replication_id来判断是不是第一次连接，如果一样就不是第一次，做增量同步。如果不一致就是第一次，做全量同步。全量同步就是主节点执行bgsave，然后把rdb文件发送给从节点。

**增量同步**：指的是除了第一次的全量同步之外基本都做增量同步，slave提交自己的offset到master，master获取repl_baklog日志文件中从offset之后的命令给slave



**问题：怎么保证Redis的高并发高可用**

**回答**：

首先可以搭建主从集群，再加上使用redis中的哨兵机制，哨兵模式可以实现主从集群的自动故障恢复，保证了高可用；主从集群，主节点用于写数据，从节点用于读数据就保证了高并发。



**问题：你们使用redis是单点还是集群，哪种集群**

**回答**：

我们当时使用的是主从（1主2从）加哨兵。并没有做分片集群。因为集群维护起来比较麻烦，并且集群之间的心跳检测和数据通信会消耗大量的网络带宽，也没有办法使用lua脚本和事务



**问题：redis集群脑裂，该怎么解决呢？**

**回答**：

有的时候由于网络等原因可能会出现脑裂的情况，就是说，由于redis master节点和redis salve节点和sentinel之间网络出现问题，使得sentinel没有能够心跳感知到master，所以通过选举的方式提升了一个salve为master，这样就存在了两个master，就像大脑分裂了一样，这样会导致客户端还在old master那里写入数据，新节点无法同步数据，当网络恢复后，sentinel会将old master降为salve，这时再从新master同步数据，这会导致old master中的大量数据丢失。

关于解决的话，我记得在redis的配置中可以设置：第一可以设置最少的salve节点个数，比如设置至少要有一个从节点才能同步数据，第二个可以设置主从数据复制和同步的延迟时间，达不到要求就拒绝请求，就可以避免大量的数据丢失









>**面试官**：Redis是单线程的，但是为什么还那么快？
>
>**候选人**：
>
>嗯，这个有几个原因吧~~~
>
>1、完全基于内存的，C语言编写
>
>2、采用单线程，避免不必要的上下文切换可竞争条件
>
>3、使用多路I/O复用模型，非阻塞IO
>
>例如：bgsave 和 bgrewriteaof  都是在**后台**执行操作，不影响主线程的正常使用，不会产生阻塞
>
>**面试官**：能解释一下I/O多路复用模型？
>
>**候选人**：嗯~~，I/O多路复用是指利用单个线程来同时监听多个Socket ，并在某个Socket可读、可写时得到通知，从而避免无效的等待，充分利用CPU资源。目前的I/O多路复用都是采用的epoll模式实现，它会在通知用户进程Socket就绪的同时，把已就绪的Socket写入用户空间，不需要挨个遍历Socket来判断是否就绪，提升了性能。
>
>其中Redis的网络模型就是使用I/O多路复用结合事件的处理器来应对多个Socket请求，比如，提供了连接应答处理器、命令回复处理器，命令请求处理器；
>
>在Redis6.0之后，为了提升更好的性能，在命令回复处理器使用了多线程来处理回复事件，在命令请求处理器中，将命令的转换使用了多线程，增加命令转换速度，在命令执行的时候，依然是单线程
