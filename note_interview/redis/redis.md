# Redis相关面试题

[TOC]

### 一、缓存穿透

#### 1.1 缓存穿透是什么？怎么解决？

缓存穿透是指查询一个一定**不存在**的数据，如果从数据库查不到数据则不写入缓存，这将导致每次请求都要到 DB 去查询，如果同一时间出现大量这种请求，可能导致 DB 挂掉，这种情况大概率是遭到了攻击。

首先呢，我们可以通过使用一些安全组件防止大量异常流量进入我们的缓存和数据库，例如很多安全工具的黑名单机制，还可以使用例如 Sentinel 这样的组件来进行流量控制和熔断降级。

解决方案的话，主要有两种：1. 缓存空对象   2. 布隆过滤器解决，我们在项目中使用的是缓存空对象，因为我们的项目都是内网的服务，一般不会被攻击，所以就使用了较为简单的缓存null值来解决了。当然这样的方式也有一定的缺点，因为这样会带来额外的内存的消耗。

其实还有很多解决的办法可以组合使用，比如我们的 ID 可以存在一定的设计规则，符合某种范式，这样我们就可以在应用层对其进行检查，防止非法请求到达我们的缓存中间件和数据库。



#### 1.2 介绍一下布隆过滤器吗？

布隆过滤器主要是用于检索一个元素是否在一个集合中，有很多的应用场景除了防止缓存穿透，还有比如黑名单功能，用于验证一个ip是否在黑名单中。一般可以直接使用 redisson 实现的布隆过滤器。

它的底层主要是先去初始化一个比较大数组，里面存放的二进制0或1。在一开始都是0，当一个key来了之后经过n次hash计算，模于数组长度找到数据的下标然后把数组中原来的0改为1，这样的话，n个数组的位置就能标明一个key的存在。查找的过程也是一样的。

当然这种方法是有缺点的，布隆过滤器有可能会产生一定的误判，因为布隆过滤器的实现是基于哈希算法的，哈希算法一定会存在误判的问题，当然可以设置这个误判率。较低的误判率一般的项目也能接受，不会高并发下压倒数据库。



### 二、缓存击穿 

#### 2.1 缓存击穿是什么? 怎么解决 ?

缓存击穿就是指热点数据的缓存过期了，恰好这时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期，就会直接访问数据库，这个时候大并发的请求可能会瞬间把 DB 压垮。

解决方案有两种方式：

+ 第一可以使用互斥锁：

因为锁能实现互斥性。假设线程过来，只能一个人一个人的来访问数据库，从而避免对于数据库访问压力过大，其他线程可以休眠一会重新请求缓存，但这也会影响查询的性能，因为此时会让查询的性能从并行变成了串行。

+ 第二种方案可以设置热点数据为逻辑过期，也会存在数据的短期不一致性。

①：在设置key的时候，设置一个过期时间字段一块存入缓存中，不给当前key设置过期时间

②：当查询的时候，从redis取出数据后判断时间是否过期

③：如果过期则开通另外一个线程进行数据同步，当前线程正常返回数据，这个数据不是最新





### 三、缓存雪崩 ?

#### 3.1 缓存雪崩是什么？怎么解决？

缓存雪崩是指在同一时段大量的缓存key同时失效或者Redis服务宕机，导致大量请求到达数据库，带来巨大压力。

> 同一时间大量key失效，可能是因为缓存预热时，大量key同时加载并且TTL相同

解决方案：

* 给不同的Key的TTL添加随机值
* 利用Redis集群提高服务的可用性
* 给缓存业务添加降级限流策略（快速失败，限流）
* 给业务添加多级缓存 （Nginx，Lua，Caffine）





### 四、双写一致性

#### 4.1 redis做为缓存，mysql的数据如何与redis进行同步呢？（双写一致性）

一般呢，在我们通常使用的 Cahce Aside 模式下，有写请求时，我们都是采用先更新数据库然后删除缓存的策略，来保证最终一致性。当然这种方式无法保证强一致性，在更新数据库后删除缓存前，可能有别的线程会读取到缓存中的脏数据，出现数据不一致的问题。如果我们的业务场景需要保证强一致性的话，我们可以使用读写锁来保证强一致性，但同样的性能也会下降，我们需要根据具体的业务要求来做抉择。在不要求强一致性的场景下先更新数据库后删除缓存这种策略基本可以满足业务需求了。

**如果问我们的业务场景：**

在我们之前的业务中 有一部分是要加载热点活动数据，因为有一些活动上线的时候，这个活动的访问量会突然增大，我们为了增强系统的稳定性和对应接口的性能，在活动通过审批之后会自动的将对应的活动加入到 缓存中，因为这个业务的数据一致性要求不强，因为主要动态的变化信息就是参与活动人数，所以我们就使用了 先更新数据库后删除缓存的策略。



#### 4.2 经典缓存模型

+ **Cache-Aside Pattern(旁路缓存)**：
  + 读的时候，先读缓存，缓存命中的话，直接返回数据
  + 缓存没有命中的话，就去读数据库，从数据库取出数据，放入缓存后，同时返回响应。
  + 更新的时候，先**更新数据库，然后再删除缓存**。
+ **Read/Write Through(读写穿透)**：在这种模式下，所有的数据读取和写入操作都由**抽象缓存层**负责，应用程序不直接与数据库交互。
+ **Write behind （异步缓存写入）**：**Write behind**跟**Read-Through/Write-Through**有相似的地方，都是由抽象缓存层来负责缓存和数据库的读写。它两又有个很大的不同：**Read/Write Through**是同步更新缓存和数据库的，**Write Behind**则是只更新缓存，不直接更新数据库，通过**批量异步**的方式来更新数据库。



#### 4.3 延时双删

延迟双删，就是在更新数据库 删除缓存 之后，线程睡眠一段时间，或者使用延迟队列等待一段时间，然后再次删除缓存。

延迟双删，在先更新数据库后删除缓存这种策略下，延时双删最主要要解决的问题是在**读写分离+主从库延迟**的情况下产生的问题，在一个线程A更新完主库并且删除缓存之后，B线程读取还未同步的从库脏数据，并且写入缓存，这样后面的线程就只能读取到脏数据了。这时候就需要延时双删，防止长期的不一致性。如果只是单节点的数据库其实不需要使用延时双删，因为 使用先更新数据库 后 删除缓存的策略 只会有短期的数据不一致。



#### 4.4 如果是热点数据不能删除缓存怎么办？

可以采用的阿里的**canal**组件实现数据同步：不需要更改业务代码，部署一个canal服务。canal服务把自己伪装成mysql的一个从节点，当mysql数据更新以后，canal会读取binlog数据，然后在通过canal的客户端获取到数据，更新缓存即可，这样可以作到对代码的零侵入。

或者可以使用 **MQ** 异步更新数据库：更新玩缓存之后，给MQ发消息，让别的服务去更新数据库，其可靠性由消息队列保证。





### 五、持久化

#### 5.1 redis的持久化机制

在Redis中提供了三种数据持久化的方式：1、RDB   2、AOF  3、RDB-AOF混合持久化

1. RDB 就是将 redis 存储的数据快照写在磁盘上，优点是 恢复快，缺点是 会有数不一致的问题。
2. AOF 就是将 redis 执行的写命令都存储起来，恢复的时候要每条命令都在执行一遍，优点是 数据一致性好，缺点是 恢复慢，而且文件体积大。

#### 5.2 RDB持久化

RDB是一个快照文件，它是把redis内存存储的数据写到磁盘上，当redis实例宕机恢复数据的时候，直接从RDB的快照文件中恢复数据，这样恢复数据属于比较快的方式，因为RDB文件是经过压缩的二进制文件，但是也会存在一些问题，因为自保存快照的时间到redis宕机的时间 之间的数据会丢失，会有数据不一致问题。可以通过在 redis配置文件中 配置触发RDB的条件。



#### 5.3 RDB的copy on write 机制

copy on write机制是在RDB持久化执行 bgsave 命令时的一种机制。当redis执行bgsave命令时会先执行 fork 命令，创建子进程。然后由子进程执行 bgsave 命令，由于子进程和父进程都是访问内存中的redis数据，当主进程执行读操作时，会共享内存。当主进程执行写操作时，由于子进程在执行读操作，会出现读脏数据问题，所以主进程会在执行写操作时，先 copy 一个数据的副本，对副本进行写操作，这就是 copy on write。



#### 5.4 AOF持久化

AOF的含义是追加文件，当redis操作写命令的时候，都会存储在 AOF 文件中，当redis实例宕机恢复数据的时候，会从这个文件中再次执行一遍命令来恢复数据。这种方式的优点就是数据一致性比 RDB 要好很多，并且通过配置 appendfsync 选项可以控制对AOF文件执行一次写操作的机制，可以是每条命令都写一次，或者一秒写一次，或者由操作系统决定写的时机。但是缺点是使用AOF文件恢复时，执行速度很慢，而且AOF文件体积较大，因为存储的是协议文本。



#### 5.5 AOF 重写机制

AOF重写是因为AOF中许多命令都会冗余，因为对同一个变量的两次写，互让上一次写操作失效，所以有了AOF重写来减小AOF文件的大小。AOF 重写可以产生⼀个新的 AOF 文件，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库数据一样，但体积更小。这个功能是通过读取数据库中的键值对来实现的，**程序无须对现有  AOF 文件进行任何操作**。 在执行  BGREWRITEAOF 命令时，Redis 服务器会维护⼀个 AOF 重写缓冲区，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令。当子进程完成创建新 AOF 文件的工作之 后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新的 AOF 文件保存的数 据库状态与现有的数据库状态⼀致。最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完 成 AOF 文件重写操作。



#### 5.6 RDB + AOF（Redis 4.0 对于持久化机制做了什么优化？）

Redis从4.0开始引入RDB-AOF混合持久化模式。Redis服务器在执行AOF重写操作时，会按照如下原则处理数据：

- 像执行BGSAVE命令一样，根据数据库当前的状态生成相应的RDB数据，并将其写入AOF文件中；
- 对于重写之后执行的Redis命令，则以协议文本的方式追加到AOF文件的末尾，即RDB数据之后。

通过使用RDB-AOF混合持久化，用户可以同时获得RDB持久化和AOF持久化的优点，服务器既可以通过AOF文件包含的RDB数据来实现快速的数据恢复操作，又可以通过AOF文件包含的AOF数据来将丢失数据的时间窗口限制在1s之内。







### 六、Redis的数据过期策略

在redis中使用的是两种数据过期删除策略：惰性删除 + 定期删除

**第一种是 惰性删除**：在设置该key过期时间后，我们不去管它，当访问该key时，我们检查其是否过期，如果过期，我们就删掉它。这种方式的优点是每次访问的时候才会检查key是否过期，对cpu友好，不怎么消耗cpu资源，但同样的缺点就是对于内存不友好。

**第二种是 定期删除**：就是说每隔一段时间，我们就对**一部分**key（最多20个，因为可能带有过期时间的key不足20个）进行检查，删除里面过期的key。如果过期key的比例超过某一阈值，则redis会进行循环继续选取一部分key进行删除，该阈值可以配置。并且这种策略有两种模式，一种slow，一种fast模式，顾名思义一个频率快一个频率慢，并且每次删除任务的执行时长有上限，防止占用过多的cpu资源。这种策略对内存友好，对cpu不友好。

Redis的过期删除策略：**惰性删除 + 定期删除**两种策略进行配合使用。

>  定期清理的两种模式：
>
> + SLOW模式是定时任务，执行频率默认为10hz，每次不超过25ms，以通过修改配置文件redis.conf 的 **hz** 选项来调整这个次数
> + FAST模式执行频率不固定，每次事件循环会尝试执行，但两次间隔不低于2ms，每次耗时不超过1ms

> 另外，为避免主线程长时间阻塞，提供了两个主要条件限制：
>
> + timelimit：`时间限制`。不管是快删除还是慢删除，都会计算一个合理的删除时间上限，避免删除时间过长，这是全局限制。
> + config_cycle_acceptable_stale：`过期 key 占比限制`。计算当前 DB 过期 key 的比例 p ，当 p > config_cycle_acceptable_stale 则继续循环定期删除。该参数可配置。

 





### 七、Redis的数据淘汰策略

#### 7.1 八种数据淘汰策略

redis共有八种数据淘汰策略，默认是noeviction，不删除任何数据，内部不足直接报错。数据淘汰策略可以在redis的配置文件中进行设置的。

数据淘汰策略还有volatile-ttl：从已设置过期时间的数据集中挑选最快要过期的数据淘汰。

还有 allkeys-random 和 volatile-random ：allkeys就表示在所有的键中，volatile就表示在设有过期时间的键中，random表示随机淘汰，这种策略可能会删除热点数据，所以一般不使用。

还有 allkeys-lru 和 volatile-lru ：同样lru表示最近最少使用策略，优先淘汰最近最少使用的，这种策略使用较多，因为可以保留热点数据。

还有 allkeys-lfu 和 volatile-lfu：这是Redis4.0新增加的策略，lfu就表示最近使用频率最少的优先淘汰。



#### 7.2 数据库有1000万数据 ,Redis只能缓存20w数据, 如何保证Redis中都是热点数据 ?

可以使用 allkeys-lru 淘汰策略，那留下来的都是经常访问的热点数据

> 1. volatile-lru：从已设置过期时间的数据集中挑 选最近最少使用的数据淘汰 
>
> 2. volatile-ttl：从已设置过期时间的数据集中挑选最快要过期的数据淘汰 
>
> 3. volatile-random：从已设置过期时间的数据集中任意选择数据淘汰 
>
> 4. allkeys-lru：在所有键中，移除最近最少使用的 key（这个是最常⽤的） 
>
> 5. allkeys-random：从数据集中任意选择数据淘汰 
>
> 6. no-eviction：禁⽌驱逐数据，也就是说当内存不⾜以容纳新写⼊数据时，新写入操作会报错。  
>
>    **4.0 版本后增加以下两种：** 
>
> 7. volatile-lfu：从已设置过期时间的数据集中挑选最不经常使用的数据淘汰 
>
> 8. allkeys-lfu：在所有键中，移除最不经常使用的 key





### 八、Redis分布式锁

#### 8.1 如何实现redis分布式锁

原生的实现分布式锁的方式是，在使用 redis 中提供的一个命令setnx(SET if not exists)，设置完锁之后，相当于获取了锁，在没有过期或删除key的时候是其他客户端是不能获取这个锁的。

但是这种实现方式其实有很多问题，比如（**四大问题：重入问题、不可重试、超时释放、主从一致性**）为了防止死锁问题，我们都会给锁设置过期时间，可是这个过期时间很难把握，万一进程还没有释放锁，但是过期时间已经到了，就会产生很多问题，所以我们一般直接使用 redisson 实现的锁。



#### 8.2 Redisson实现的分布式锁如何解决超时释放问题的呢？

在redisson中引入了一个看门狗机制，其实就是使用另一个线程监控当前线程，每隔一段时间（默认10s，releaseTime/3）就检查当前业务是否还持有锁，如果持有就刷新锁的持续时间，当业务执行完成之后释放锁就可以了。如果业务宕机了，看门狗的线程也宕机，锁就会在规定时间解锁。



#### 8.3 Redisson实现的分布式锁如何解决不可重试问题的呢？

redisson的锁重试机制利用了redis 的发布订阅模式 和 信号量，而非一直while循环可以有效降低cpu资源的使用，当发现锁被占用后 会先等待，当检测到我们要获取的锁被释放了之后才会继续后边的逻辑。第一次获取锁失败会用redis订阅当前锁，而锁在释放时也会发布消息，虽然在锁释放后才重试，但是可能等待的进程同时有很多，也可能抢不到锁，所以如果再次发现锁被占用就会利用信号量的机制等待锁释放，后面都是循环利用信号量机制等待，直到获取到锁，或者达到最大等待时间。



#### 8.4 redisson实现的分布式锁如何解决重入问题？

redisson在存储数据的时候采用的hash结构，外层key可以按照自己的业务进行定制，内层key是当前线程的唯一标识，value是当前线程重入的次数。重入其实就是在内部判断是否是当前线程持有的锁，如果是当前线程持有的锁就会计数加一，如果释放锁就会在计算上减一。



#### 8.5 redisson实现的分布式锁能解决主从一致性的问题吗？

可以的，但是要使用红锁或者联锁，主从一致性问题就是：当线程1加锁成功后，master节点数据会异步复制到slave节点，此时当前持有Redis锁的master节点宕机，slave节点被提升为新的master节点，假如现在来了一个线程2，再次加锁，会在新的master节点上加锁成功，这个时候就会出现两个节点同时持有一把锁的问题。

我们可以利用redisson提供的红锁来解决这个问题，它的主要作用是，不能只在一个redis实例上创建锁，应该是在多个redis实例上创建锁，并且要求在大多数redis节点上都成功创建锁，红锁中要求是redis的节点数量要过半。而联锁是要求在所有的节点都成功创建锁。这样就能避免线程1加锁成功后master节点宕机导致线程2成功加锁到新的master节点上的问题了。

但是，如果使用了红锁或者联锁，因为需要同时在多个节点上都添加锁，性能就变的很低了，并且运维维护成本也非常高。



#### 8.6 如果业务非要保证数据的强一致性，这个该怎么解决呢？

如果有强一致性要求高的业务，建议使用zookeeper实现的分布式锁，它是可以保证强一致性的。





### 九、Redis集群

#### 9.1 Redis集群有哪些方案, 知道嘛 ? 

在Redis中提供的集群方案总共有三种：主从模式、哨兵模式、Redis分片集群。

**主从模式**：单节点Redis的并发能力是有上限的，要进一步提高Redis的并发能力，可以搭建主从集群，实现读写分离。一般都是一主多从，主节点负责写数据，从节点负责读数据，主节点写入数据之后，需要把数据同步到从节点中。

**哨兵模式：**为了应对单点故障问题，实现主从集群的自动故障恢复，redis提供了哨兵模式。可以使用几个节点作为哨兵来监控集群状态。当主节点宕机时，会自动选举新的主节点，继续提供服务。

**分片集群：**为了应对海量数据问题，redis提供了分片集群，一种无中心的结构，包含多个master节点，每个master又包含多个slaver节点。master之间通过ping监测彼此健康状态，相当于哨兵节点。每个master保存不同的数据，根据每个master所映射的插槽的标号。



#### 9.2 主从同步数据的流程

主从同步分为了两个阶段，一个是**全量同步**，一个是**增量同步**

**全量同步**：当从节点第一次连接到主节点时，会做全量同步，通过replication_id来判断是不是第一次连接，如果一样就不是第一次，做增量同步。如果不一致就是第一次，做全量同步。全量同步就是主节点执行bgsave，然后把rdb文件发送给从节点。

**增量同步**：指的是除了第一次的全量同步之外基本都做增量同步，slave提交自己的offset到master，master获取repl_baklog日志文件中从offset之后的命令给slave



#### 9.3 怎么保证Redis的高并发高可用

首先可以搭建主从集群，再加上使用redis中的哨兵机制，哨兵模式可以实现主从集群的自动故障恢复，保证了高可用；主从集群，主节点用于写数据，从节点用于读数据就保证了高并发。



#### 9.4 你们使用redis是单点还是集群，哪种集群

我们当时使用的是主从（1主2从）加哨兵。并没有做分片集群。因为集群维护起来比较麻烦，并且集群之间的心跳检测和数据通信会消耗大量的网络带宽，也没有办法使用lua脚本和事务



#### 9.5 redis集群脑裂，该怎么解决呢？

有的时候由于网络等原因可能会出现脑裂的情况，就是说，由于redis master节点和redis salve节点和sentinel之间网络出现问题，使得sentinel没有能够心跳感知到master，所以通过选举的方式提升了一个salve为master，这样就存在了两个master，就像大脑分裂了一样，这样会导致客户端还在old master那里写入数据，新节点无法同步数据，当网络恢复后，sentinel会将old master降为salve，这时再从新master同步数据，这会导致old master中的大量数据丢失。

关于解决的话，我记得在redis的配置中可以设置：第一可以设置最少的salve节点个数，比如设置至少要有一个从节点才能同步数据，第二个可以设置主从数据复制和同步的延迟时间，达不到要求就拒绝请求，就可以避免大量的数据丢失





### 十、Redis是单线程的，但是为什么还那么快？

1、首先最重要的原因是因为redis完全基于内存的，并且 redis 的性能瓶颈主要是在内存与网络，单线程与多线程影响的是 cpu，对于redis性能影响不大。

2、而且采用单线程，可以避免不必要的上下文切换带来的开销，并且引入多线程会带来线程安全问题，必然会引入线程锁这样的技术，实现复杂度增高，性能也会降低。

3、并且redis使用了I/O多路复用模型与事件派发机制，来优化他的网络IO效率。

例如：bgsave 和 bgrewriteaof  都是在**后台**执行操作，不影响主进程的正常使用，不会产生阻塞



#### 10.1 能解释一下I/O多路复用模型？

I/O多路复用是指利用单个线程来同时监听多个Socket ，并在某个Socket可读、可写时得到通知，从而避免无效的等待，充分利用CPU资源。目前的I/O多路复用都是采用的epoll模式实现，它会在通知用户进程Socket就绪的同时，把已就绪的Socket写入用户空间，不需要挨个遍历Socket来判断是否就绪，提升了性能。

其中Redis的网络模型就是使用I/O多路复用结合事件处理器来应对多个Socket请求，比如，提供了连接应答处理器、命令回复处理器，命令请求处理器；

在Redis6.0之后，为了提升网络IO的性能，在命令回复处理器使用了多线程来处理回复事件，在命令请求处理器中，将命令的转换使用了多线程，增加命令转换速度，在命令执行的时候，依然是单线程。



#### 10.2 IO多路复用的三种模式

select模式：

* 用1024个比特位来记录监听的FD（文件描述符），能监听的FD最大不超过1024
* 每次select都需要把所有要监听的FD都拷贝到内核空间，并且有FD就绪的时候，再次把所有的FD拷贝回用户空间
* 每次都要遍历所有FD来判断就绪状态

poll模式的问题：

* poll利用链表解决了select中监听FD上限的问题，但依然要遍历所有FD，如果监听较多，性能会下降

epoll模式中如何解决这些问题的？

* 基于epoll实例中的红黑树保存要监听的FD，理论上无上限，而且增删改查效率都非常高
* 每个FD只需要执行一次添加到内核空间的红黑树，无需重复拷贝FD到内核空间
* 当FD就绪直接存入链表，无需遍历所有FD，因此性能不会随监听的FD数量增多而下降





### 十一、redis的数据类型

1. String：数字型，字符串，二进制。主要有用来缓存，计数。
2. hash：value本身又是一个key，value类型。存储对象。
3. list：存储字符串，可以重复，字符串有顺序。做消息队列。
4. set：存储字符串，不可以重复，无序。共同好友。
5. Zset：比zet多了一个排序功能，可以指定一个排序的量。
6. Redis还提供了Bitmap、HyperLogLog、Geo类型，但这些类型都是基于上述核心数据类型实现的；
7. Redis在5.0新增加了Streams数据类型，它是一个功能强大的、支持多播的、可持久化的消息队列。



#### 11.1 你的项目中提到了你使用了GEO，详细说说

当时我们的业务需求是根据地道的坐标来查找地道附近的两条车道的交通状况，用以判断是否因为地道水位上涨导致交通堵塞。因为这个功能和经纬度的坐标有关系，一开始我们是直接每次请求那个地道的时候我们就计算所有路段和它的距离，但是这样计算速度有点慢，然后我们优化的时候，选择使用redis的GEO数据结构来实现，GEO底层使用的就是 Zset 的结构存储的，它把经纬度经过它的 GEOhash 算法计算为一个得分，作为 zset 的排序依据，然后由于这个算法的特性呢，地理位置距离近的元素排序总是接近的。所以它获取某个经纬度的临近数据就很快，当时我们是先把所有路段的经纬度和路段id存储了redis中，每当请求某个地道的时候，我们就直接用REDIS的GEO Search 去找离他最近的两个路段，然后用路段 id 再去找交通量。



#### 11.2 zset的底层数据结构

zset 集合对象有2种编码方案，ziplist 和 skiplist与dict相结合的两种方式，当同时满足以下条件时，集合对象采用ziplist编码，否则采用skiplist编码：

- 有序集合保存的元素数量不超过128个；
- 有序集合保存的所有元素的成员长度都小于64字节。

因为当元素数量不多时，dict 和 SkipList 的优势不明显，而且更耗内存。因此zset会采用ZipList结构来节省内存，ziplist本身没有排序功能，而且没有键值对的概念，因此需要有zset通过编码实现：

* ZipList是连续内存，因此score和element是紧挨在一起的两个entry， element在前，score在后
* score越小越接近队首，score越大越接近队尾，按照score值升序排列

skiplist 加 dict 的实现 是因为 dict 只能提供键值存储，**还有根据member来查找score**，但是没法排序所以使用 skiplist 来实现对zset的排序，这种方案相当于所有数据存储两次，非常消耗内存，所以有了ziplist的方案。



#### 11.3 hash的底层数据结构

hash结构底层有两种实现方式：压缩列表ziplist 或者 字典dict。和zset差不多
当Hash中数据项比较少的情况下，Hash底层用压缩列表ziplist进行存储数据，随着数据的增加，底层的ziplist就可能会转成dict，具体配置如下：

+ 元素个数小于 hash-max-ziplist-entries 512

+ 所有元素的长度都小于 hash-max-ziplist-value 64 字节

当不满足上面两个条件其中之⼀的时候，Redis就使用dict字典来实现hash。
Redis的hash之所以这样设计，是因为当ziplist变得很大的时候，它有如下缺点：

* 当ziplist数据项过多的时候，在它上面查找指定的数据项就会性能变得很低，因为ziplist上的查找需要进行遍历。

而当数据量很小的时候使用dict和ziplist的查找效率相差不大，但是由于dict存储了很多的指针对于内存的浪费比较多，所以数据量小的时候使用ziplist。



#### 11.4 String 还是 Hash 存储对象数据更好呢

+ String 存储的是序列化后的对象数据，存放的是整个对象。Hash 是对对象的每个字段单独存 储，可以获取部分字段的信息，也可以修改或者添加部分字段，节省⽹络流量。如果对象中某些 字段需要经常变动或者经常需要单独查询对象中的个别字段信息，Hash 就⾮常适合。 
+ String 存储相对来说更加节省内存，缓存相同数量的对象数据，String 消耗的内存约是 Hash 的 ⼀半。并且，存储具有多层嵌套的对象时也⽅便很多。如果系统对性能和资源消耗⾮常敏感的 话，String 就⾮常适合。 在绝⼤部分情况，我们建议使⽤ String 来存储对象数据即可！







### 十二、bigkey

value占用内存较大，string类型可能是value本身过大；set，zset，hash等集合类型中含有的值过多。

**问题**：

> 1. 客户端的阻塞。
> 2. 网络传输的延迟：传输大key会占用多带宽
> 3. 占用更多的内存：如果是做了集群可能会导致数据倾斜，某个节点上内存占用过大
> 4. 造成redis请求阻塞：对大key的处理需要更多的时间，redis是单线程处理命令，所以会导致其他请求不能及时处理

**解决：**

> **检测：**
>
> 1. 改写redis业务端，客户端，代理端做埋点，实时上报给redis大key检测平台。
> 2. 自带的命令，如bigkeys，**scan**等。
> 3. 第三方工具，比如go语言编写的rdb_bigkey或者python编写的**rdb_tools**，利用分析RDB快照文件的工具。
> 4. 借助公有云的 Redis 分析服务。
>
> **整改大key**
>
> 1. 压缩，序列化操作，这会带来额外操作，得到键值对后要进行解压缩操作
> 2. 根据具体的业务场景进行数据拆分和迁移。
> 3. 利用合适的数据结构进行存储（文件二进制数据不使用 String 保存）。
>
> **删除原来大key**
>
> 1. 不能使用del，会造成阻塞。redis是单线程，会影响其他操作。
> 2. 版本小于4.0可以用`scan`+`del`做分批次先改名再删除
> 3. redis版本大于4.0可以用`unlink`进行异步删除，不会阻塞主线程。





### 十三、一致性哈希

[Redis用哈希槽，而不是一致性哈希，为什么](https://www.cnblogs.com/crazymakercircle/p/18018466)
